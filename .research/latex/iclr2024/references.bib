@misc{airas2025,
  author    = {Toma Tanaka and Takumi Matsuzawa and Yuki Yoshino and Ilya Horiguchi and Shiro Takagi and Ryutaro Yamauchi and Wataru Kumagai},
  title     = {{AIRAS}},
  year      = {2025},
  publisher = {GitHub},
  url       = {https://github.com/airas-org/airas}
}

% ===========================================
% REQUIRED CITATIONS
% These papers must be cited in the manuscript
% ===========================================

@article{alfarra-2023-evaluation,
 abstract = {This paper proposes a novel online evaluation protocol for Test Time
Adaptation (TTA) methods, which penalizes slower methods by providing them with
fewer samples for adaptation. TTA methods leverage unlabeled data at test time
to adapt to distribution shifts. Although many effective methods have been
proposed, their impressive performance usually comes at the cost of
significantly increased computation budgets. Current evaluation protocols
overlook the effect of this extra computation cost, affecting their real-world
applicability. To address this issue, we propose a more realistic evaluation
protocol for TTA methods, where data is received in an online fashion from a
constant-speed data stream, thereby accounting for the method's adaptation
speed. We apply our proposed protocol to benchmark several TTA methods on
multiple datasets and scenarios. Extensive experiments show that, when
accounting for inference speed, simple and fast approaches can outperform more
sophisticated but slower methods. For example, SHOT from 2020, outperforms the
state-of-the-art method SAR from 2023 in this setting. Our results reveal the
importance of developing practical TTA methods that are both accurate and
efficient.},
 arxiv_url = {https://arxiv.org/pdf/2304.04795v2.pdf},
 author = {Motasem Alfarra and Hani Itani and Alejandro Pardo and Shyma Alhuwaider and Merey Ramazanova and Juan C. Pérez and Zhipeng Cai and Matthias Müller and Bernard Ghanem},
 title = {Evaluation of Test-Time Adaptation Under Computational Time Constraints},
 year = {2023}
}

@article{author-year-bayesian,
 title = {Bayesian Meta Sampling for Fast Uncertainty Adaptation}
}

@article{author-year-estimation,
 title = {On Estimation in Latent Variable Models}
}

@article{author-year-leveraging,
 title = {Leveraging Proxy of Training Data for Test-Time Adaptation}
}

@article{author-year-test,
 title = {Test Time Adaptation With Regularized Loss for Weakly Supervised Salient Object Detection}
}

@article{author-year-tta,
 title = {L-TTA: Lightweight Test-Time Adaptation Using a Versatile Stem Layer}
}

@article{author-year-ttt,
 title = {TTT++: When Does Self-Supervised Test-Time Training Fail or Thrive?}
}

@article{chen-2023-improved,
 abstract = {The main challenge in domain generalization (DG) is to handle the
distribution shift problem that lies between the training and test data. Recent
studies suggest that test-time training (TTT), which adapts the learned model
with test data, might be a promising solution to the problem. Generally, a TTT
strategy hinges its performance on two main factors: selecting an appropriate
auxiliary TTT task for updating and identifying reliable parameters to update
during the test phase. Both previous arts and our experiments indicate that TTT
may not improve but be detrimental to the learned model if those two factors
are not properly considered. This work addresses those two factors by proposing
an Improved Test-Time Adaptation (ITTA) method. First, instead of heuristically
defining an auxiliary objective, we propose a learnable consistency loss for
the TTT task, which contains learnable parameters that can be adjusted toward
better alignment between our TTT task and the main prediction task. Second, we
introduce additional adaptive parameters for the trained model, and we suggest
only updating the adaptive parameters during the test phase. Through extensive
experiments, we show that the proposed two strategies are beneficial for the
learned model (see Figure 1), and ITTA could achieve superior performance to
the current state-of-the-art methods on several DG benchmarks. Code is
available at https://github.com/liangchen527/ITTA.},
 arxiv_url = {https://arxiv.org/pdf/2304.04494v2.pdf},
 author = {Liang Chen and Yong Zhang and Yibing Song and Ying Shan and Lingqiao Liu},
 github_url = {https://github.com/liangchen527/ITTA},
 title = {Improved Test-Time Adaptation for Domain Generalization},
 year = {2023}
}

@article{flennerhag-2023-optimistic,
 abstract = {We study the connection between gradient-based meta-learning and convex
op-timisation. We observe that gradient descent with momentum is a special case
of meta-gradients, and building on recent results in optimisation, we prove
convergence rates for meta-learning in the single task setting. While a
meta-learned update rule can yield faster convergence up to constant factor, it
is not sufficient for acceleration. Instead, some form of optimism is required.
We show that optimism in meta-learning can be captured through Bootstrapped
Meta-Gradients (Flennerhag et al., 2022), providing deeper insight into its
underlying mechanics.},
 arxiv_url = {https://arxiv.org/pdf/2301.03236v1.pdf},
 author = {Sebastian Flennerhag and Tom Zahavy and Brendan O'Donoghue and Hado van Hasselt and András György and Satinder Singh},
 title = {Optimistic Meta-Gradients},
 year = {2023}
}

@article{goyal-2022-test,
 abstract = {Test-time adaptation (TTA) refers to adapting neural networks to distribution
shifts, with access to only the unlabeled test samples from the new domain at
test-time. Prior TTA methods optimize over unsupervised objectives such as the
entropy of model predictions in TENT [Wang et al., 2021], but it is unclear
what exactly makes a good TTA loss. In this paper, we start by presenting a
surprising phenomenon: if we attempt to meta-learn the best possible TTA loss
over a wide class of functions, then we recover a function that is remarkably
similar to (a temperature-scaled version of) the softmax-entropy employed by
TENT. This only holds, however, if the classifier we are adapting is trained
via cross-entropy; if trained via squared loss, a different best TTA loss
emerges. To explain this phenomenon, we analyze TTA through the lens of the
training losses's convex conjugate. We show that under natural conditions, this
(unsupervised) conjugate function can be viewed as a good local approximation
to the original supervised loss and indeed, it recovers the best losses found
by meta-learning. This leads to a generic recipe that can be used to find a
good TTA loss for any given supervised training loss function of a general
class. Empirically, our approach consistently dominates other baselines over a
wide range of benchmarks. Our approach is particularly of interest when applied
to classifiers trained with novel loss functions, e.g., the recently-proposed
PolyLoss, where it differs substantially from (and outperforms) an
entropy-based loss. Further, we show that our approach can also be interpreted
as a kind of self-training using a very specific soft label, which we refer to
as the conjugate pseudolabel. Overall, our method provides a broad framework
for better understanding and improving test-time adaptation. Code is available
at https://github.com/locuslab/tta_conjugate.},
 arxiv_url = {https://arxiv.org/pdf/2207.09640v2.pdf},
 author = {Sachin Goyal and Mingjie Sun and Aditi Raghunathan and Zico Kolter},
 title = {Test Time Adaptation via Conjugate Pseudo-labels},
 year = {2022}
}

@article{gui-2024-active,
 abstract = {Test-time adaptation (TTA) addresses distribution shifts for streaming test
data in unsupervised settings. Currently, most TTA methods can only deal with
minor shifts and rely heavily on heuristic and empirical studies.
  To advance TTA under domain shifts, we propose the novel problem setting of
active test-time adaptation (ATTA) that integrates active learning within the
fully TTA setting.
  We provide a learning theory analysis, demonstrating that incorporating
limited labeled test instances enhances overall performances across test
domains with a theoretical guarantee. We also present a sample entropy
balancing for implementing ATTA while avoiding catastrophic forgetting (CF). We
introduce a simple yet effective ATTA algorithm, known as SimATTA, using
real-time sample selection techniques. Extensive experimental results confirm
consistency with our theoretical analyses and show that the proposed ATTA
method yields substantial performance improvements over TTA methods while
maintaining efficiency and shares similar effectiveness to the more demanding
active domain adaptation (ADA) methods. Our code is available at
https://github.com/divelab/ATTA},
 arxiv_url = {https://arxiv.org/pdf/2404.05094v1.pdf},
 author = {Shurui Gui and Xiner Li and Shuiwang Ji},
 github_url = {https://github.com/divelab/ATTA},
 title = {Active Test-Time Adaptation: Theoretical Analyses and An Algorithm},
 year = {2024}
}

@article{gupta-2020-look,
 abstract = {The continual learning problem involves training models with limited capacity
to perform well on a set of an unknown number of sequentially arriving tasks.
While meta-learning shows great potential for reducing interference between old
and new tasks, the current training procedures tend to be either slow or
offline, and sensitive to many hyper-parameters. In this work, we propose
Look-ahead MAML (La-MAML), a fast optimisation-based meta-learning algorithm
for online-continual learning, aided by a small episodic memory. Our proposed
modulation of per-parameter learning rates in our meta-learning update allows
us to draw connections to prior work on hypergradients and meta-descent. This
provides a more flexible and efficient way to mitigate catastrophic forgetting
compared to conventional prior-based methods. La-MAML achieves performance
superior to other replay-based, prior-based and meta-learning based approaches
for continual learning on real-world visual classification benchmarks. Source
code can be found here: https://github.com/montrealrobotics/La-MAML},
 arxiv_url = {https://arxiv.org/pdf/2007.13904v2.pdf},
 author = {Gunshi Gupta and Karmesh Yadav and Liam Paull},
 github_url = {https://github.com/montrealrobotics/La-MAML},
 title = {Look-ahead Meta Learning for Continual Learning},
 year = {2020}
}

@article{harrison-2019-continuous,
 abstract = {Meta-learning is a promising strategy for learning to efficiently learn
within new tasks, using data gathered from a distribution of tasks. However,
the meta-learning literature thus far has focused on the task segmented
setting, where at train-time, offline data is assumed to be split according to
the underlying task, and at test-time, the algorithms are optimized to learn in
a single task. In this work, we enable the application of generic meta-learning
algorithms to settings where this task segmentation is unavailable, such as
continual online learning with a time-varying task. We present meta-learning
via online changepoint analysis (MOCA), an approach which augments a
meta-learning algorithm with a differentiable Bayesian changepoint detection
scheme. The framework allows both training and testing directly on time series
data without segmenting it into discrete tasks. We demonstrate the utility of
this approach on a nonlinear meta-regression benchmark as well as two
meta-image-classification benchmarks.},
 arxiv_url = {https://arxiv.org/pdf/1912.08866v2.pdf},
 author = {James Harrison and Apoorva Sharma and Chelsea Finn and Marco Pavone},
 github_url = {https://github.com/StanfordASL/moca},
 title = {Continuous Meta-Learning without Tasks},
 year = {2019}
}

@article{hoang-2023-persistent,
 abstract = {Current test-time adaptation (TTA) approaches aim to adapt a machine learning
model to environments that change continuously. Yet, it is unclear whether TTA
methods can maintain their adaptability over prolonged periods. To answer this
question, we introduce a diagnostic setting - recurring TTA where environments
not only change but also recur over time, creating an extensive data stream.
This setting allows us to examine the error accumulation of TTA models, in the
most basic scenario, when they are regularly exposed to previous testing
environments. Furthermore, we simulate a TTA process on a simple yet
representative $\epsilon$-perturbed Gaussian Mixture Model Classifier, deriving
theoretical insights into the dataset- and algorithm-dependent factors
contributing to gradual performance degradation. Our investigation leads us to
propose persistent TTA (PeTTA), which senses when the model is diverging
towards collapse and adjusts the adaptation strategy, striking a balance
between the dual objectives of adaptation and model collapse prevention. The
supreme stability of PeTTA over existing approaches, in the face of lifelong
TTA scenarios, has been demonstrated over comprehensive experiments on various
benchmarks. Our project page is available at https://hthieu166.github.io/petta.},
 arxiv_url = {https://arxiv.org/pdf/2311.18193v4.pdf},
 author = {Trung-Hieu Hoang and Duc Minh Vo and Minh N. Do},
 github_url = {https://github.com/BIT-DA/RoTTA},
 title = {Persistent Test-time Adaptation in Recurring Testing Scenarios},
 year = {2023}
}

@article{khan-2021-knowledge,
 abstract = {Humans and animals have a natural ability to quickly adapt to their
surroundings, but machine-learning models, when subjected to changes, often
require a complete retraining from scratch. We present Knowledge-adaptation
priors (K-priors) to reduce the cost of retraining by enabling quick and
accurate adaptation for a wide-variety of tasks and models. This is made
possible by a combination of weight and function-space priors to reconstruct
the gradients of the past, which recovers and generalizes many existing, but
seemingly-unrelated, adaptation strategies. Training with simple first-order
gradient methods can often recover the exact retrained model to an arbitrary
accuracy by choosing a sufficiently large memory of the past data. Empirical
results show that adaptation with K-priors achieves performance similar to full
retraining, but only requires training on a handful of past examples.},
 arxiv_url = {https://arxiv.org/pdf/2106.08769v2.pdf},
 author = {Mohammad Emtiyaz Khan and Siddharth Swaroop},
 github_url = {https://github.com/team-approx-bayes/kpriors},
 title = {Knowledge-Adaptation Priors},
 year = {2021}
}

@article{lee-2024-aetta,
 abstract = {Test-time adaptation (TTA) has emerged as a viable solution to adapt
pre-trained models to domain shifts using unlabeled test data. However, TTA
faces challenges of adaptation failures due to its reliance on blind adaptation
to unknown test samples in dynamic scenarios. Traditional methods for
out-of-distribution performance estimation are limited by unrealistic
assumptions in the TTA context, such as requiring labeled data or re-training
models. To address this issue, we propose AETTA, a label-free accuracy
estimation algorithm for TTA. We propose the prediction disagreement as the
accuracy estimate, calculated by comparing the target model prediction with
dropout inferences. We then improve the prediction disagreement to extend the
applicability of AETTA under adaptation failures. Our extensive evaluation with
four baselines and six TTA methods demonstrates that AETTA shows an average of
19.8%p more accurate estimation compared with the baselines. We further
demonstrate the effectiveness of accuracy estimation with a model recovery case
study, showcasing the practicality of our model recovery based on accuracy
estimation. The source code is available at https://github.com/taeckyung/AETTA.},
 arxiv_url = {https://arxiv.org/pdf/2404.01351v1.pdf},
 author = {Taeckyung Lee and Sorn Chottananurak and Taesik Gong and Sung-Ju Lee},
 github_url = {https://github.com/taeckyung/AETTA},
 title = {AETTA: Label-Free Accuracy Estimation for Test-Time Adaptation},
 year = {2024}
}

@article{li-2023-alternating,
 abstract = {Tensor network (TN) is a powerful framework in machine learning, but
selecting a good TN model, known as TN structure search (TN-SS), is a
challenging and computationally intensive task. The recent approach
TNLS~\cite{li2022permutation} showed promising results for this task, however,
its computational efficiency is still unaffordable, requiring too many
evaluations of the objective function. We propose TnALE, a new algorithm that
updates each structure-related variable alternately by local enumeration,
\emph{greatly} reducing the number of evaluations compared to TNLS. We
theoretically investigate the descent steps for TNLS and TnALE, proving that
both algorithms can achieve linear convergence up to a constant if a sufficient
reduction of the objective is \emph{reached} in each neighborhood. We also
compare the evaluation efficiency of TNLS and TnALE, revealing that
$\Omega(2^N)$ evaluations are typically required in TNLS for \emph{reaching}
the objective reduction in the neighborhood, while ideally $O(N^2R)$
evaluations are sufficient in TnALE, where $N$ denotes the tensor order and $R$
reflects the \emph{``low-rankness''} of the neighborhood. Experimental results
verify that TnALE can find practically good TN-ranks and permutations with
vastly fewer evaluations than the state-of-the-art algorithms.},
 arxiv_url = {https://arxiv.org/pdf/2304.12875v3.pdf},
 author = {Chao Li and Junhua Zeng and Chunmei Li and Cesar Caiafa and Qibin Zhao},
 github_url = {https://github.com/oscarmickelin/tensor-ring-decomposition},
 title = {Alternating Local Enumeration (TnALE): Solving Tensor Network Structure Search with Fewer Evaluations},
 year = {2023}
}

@article{lyle-2020-bayesian,
 abstract = {We take a Bayesian perspective to illustrate a connection between training
speed and the marginal likelihood in linear models. This provides two major
insights: first, that a measure of a model's training speed can be used to
estimate its marginal likelihood. Second, that this measure, under certain
conditions, predicts the relative weighting of models in linear model
combinations trained to minimize a regression loss. We verify our results in
model selection tasks for linear models and for the infinite-width limit of
deep neural networks. We further provide encouraging empirical evidence that
the intuition developed in these settings also holds for deep neural networks
trained with stochastic gradient descent. Our results suggest a promising new
direction towards explaining why neural networks trained with stochastic
gradient descent are biased towards functions that generalize well.},
 arxiv_url = {https://arxiv.org/pdf/2010.14499v1.pdf},
 author = {Clare Lyle and Lisa Schut and Binxin Ru and Yarin Gal and Mark van der Wilk},
 title = {A Bayesian Perspective on Training Speed and Model Selection},
 year = {2020}
}

@article{mannelli-2021-analytical,
 abstract = {The optimization step in many machine learning problems rarely relies on
vanilla gradient descent but it is common practice to use momentum-based
accelerated methods. Despite these algorithms being widely applied to arbitrary
loss functions, their behaviour in generically non-convex, high dimensional
landscapes is poorly understood. In this work, we use dynamical mean field
theory techniques to describe analytically the average dynamics of these
methods in a prototypical non-convex model: the (spiked) matrix-tensor model.
We derive a closed set of equations that describe the behaviour of heavy-ball
momentum and Nesterov acceleration in the infinite dimensional limit. By
numerical integration of these equations, we observe that these methods speed
up the dynamics but do not improve the algorithmic threshold with respect to
gradient descent in the spiked model.},
 arxiv_url = {https://arxiv.org/pdf/2102.11755v4.pdf},
 author = {Stefano Sarao Mannelli and Pierfrancesco Urbani},
 title = {Analytical Study of Momentum-Based Acceleration Methods in Paradigmatic High-Dimensional Non-Convex Problems},
 year = {2021}
}

@article{mishkin-2024-directional,
 abstract = {We develop new sub-optimality bounds for gradient descent (GD) that depend on
the conditioning of the objective along the path of optimization rather than on
global, worst-case constants. Key to our proofs is directional smoothness, a
measure of gradient variation that we use to develop upper-bounds on the
objective. Minimizing these upper-bounds requires solving implicit equations to
obtain a sequence of strongly adapted step-sizes; we show that these equations
are straightforward to solve for convex quadratics and lead to new guarantees
for two classical step-sizes. For general functions, we prove that the Polyak
step-size and normalized GD obtain fast, path-dependent rates despite using no
knowledge of the directional smoothness. Experiments on logistic regression
show our convergence guarantees are tighter than the classical theory based on
$L$-smoothness.},
 arxiv_url = {https://arxiv.org/pdf/2403.04081v2.pdf},
 author = {Aaron Mishkin and Ahmed Khaled and Yuanhao Wang and Aaron Defazio and Robert M. Gower},
 title = {Directional Smoothness and Gradient Methods: Convergence and Adaptivity},
 year = {2024}
}

@article{mousavihosseini-2023-gradient,
 abstract = {Recent works have demonstrated that the sample complexity of gradient-based
learning of single index models, i.e. functions that depend on a 1-dimensional
projection of the input data, is governed by their information exponent.
However, these results are only concerned with isotropic data, while in
practice the input often contains additional structure which can implicitly
guide the algorithm. In this work, we investigate the effect of a spiked
covariance structure and reveal several interesting phenomena. First, we show
that in the anisotropic setting, the commonly used spherical gradient dynamics
may fail to recover the true direction, even when the spike is perfectly
aligned with the target direction. Next, we show that appropriate weight
normalization that is reminiscent of batch normalization can alleviate this
issue. Further, by exploiting the alignment between the (spiked) input
covariance and the target, we obtain improved sample complexity compared to the
isotropic case. In particular, under the spiked model with a suitably large
spike, the sample complexity of gradient-based training can be made independent
of the information exponent while also outperforming lower bounds for
rotationally invariant kernel methods.},
 arxiv_url = {https://arxiv.org/pdf/2309.03843v1.pdf},
 author = {Alireza Mousavi-Hosseini and Denny Wu and Taiji Suzuki and Murat A. Erdogdu},
 title = {Gradient-Based Feature Learning under Structured Data},
 year = {2023}
}

@article{niu-2023-towards,
 abstract = {Test-time adaptation (TTA) has shown to be effective at tackling distribution
shifts between training and testing data by adapting a given model on test
samples. However, the online model updating of TTA may be unstable and this is
often a key obstacle preventing existing TTA methods from being deployed in the
real world. Specifically, TTA may fail to improve or even harm the model
performance when test data have: 1) mixed distribution shifts, 2) small batch
sizes, and 3) online imbalanced label distribution shifts, which are quite
common in practice. In this paper, we investigate the unstable reasons and find
that the batch norm layer is a crucial factor hindering TTA stability.
Conversely, TTA can perform more stably with batch-agnostic norm layers, \ie,
group or layer norm. However, we observe that TTA with group and layer norms
does not always succeed and still suffers many failure cases. By digging into
the failure cases, we find that certain noisy test samples with large gradients
may disturb the model adaption and result in collapsed trivial solutions, \ie,
assigning the same class label for all samples. To address the above collapse
issue, we propose a sharpness-aware and reliable entropy minimization method,
called SAR, for further stabilizing TTA from two aspects: 1) remove partial
noisy samples with large gradients, 2) encourage model weights to go to a flat
minimum so that the model is robust to the remaining noisy samples. Promising
results demonstrate that SAR performs more stably over prior methods and is
computationally efficient under the above wild test scenarios.},
 arxiv_url = {https://arxiv.org/pdf/2302.12400v1.pdf},
 author = {Shuaicheng Niu and Jiaxiang Wu and Yifan Zhang and Zhiquan Wen and Yaofo Chen and Peilin Zhao and Mingkui Tan},
 title = {Towards Stable Test-time Adaptation in Dynamic Wild World},
 year = {2023}
}

@article{ren-2021-tensor,
 abstract = {Despite the predominant use of first-order methods for training deep learning
models, second-order methods, and in particular, natural gradient methods,
remain of interest because of their potential for accelerating training through
the use of curvature information. Several methods with non-diagonal
preconditioning matrices, including KFAC, Shampoo, and K-BFGS, have been
proposed and shown to be effective. Based on the so-called tensor normal (TN)
distribution, we propose and analyze a brand new approximate natural gradient
method, Tensor Normal Training (TNT), which like Shampoo, only requires
knowledge of the shape of the training parameters. By approximating the
probabilistically based Fisher matrix, as opposed to the empirical Fisher
matrix, our method uses the block-wise covariance of the sampling based
gradient as the pre-conditioning matrix. Moreover, the assumption that the
sampling-based (tensor) gradient follows a TN distribution, ensures that its
covariance has a Kronecker separable structure, which leads to a tractable
approximation to the Fisher matrix. Consequently, TNT's memory requirements and
per-iteration computational costs are only slightly higher than those for
first-order methods. In our experiments, TNT exhibited superior optimization
performance to state-of-the-art first-order methods, and comparable
optimization performance to the state-of-the-art second-order methods KFAC and
Shampoo. Moreover, TNT demonstrated its ability to generalize as well as
first-order methods, while using fewer epochs.},
 arxiv_url = {https://arxiv.org/pdf/2106.02925v3.pdf},
 author = {Yi Ren and Donald Goldfarb},
 github_url = {https://github.com/renyiryry/tnt_neurips_2021},
 title = {Tensor Normal Training for Deep Learning Models},
 year = {2021}
}

@article{sankararaman-2019-the,
 abstract = {This paper studies how neural network architecture affects the speed of
training. We introduce a simple concept called gradient confusion to help
formally analyze this. When gradient confusion is high, stochastic gradients
produced by different data samples may be negatively correlated, slowing down
convergence. But when gradient confusion is low, data samples interact
harmoniously, and training proceeds quickly. Through theoretical and
experimental results, we demonstrate how the neural network architecture
affects gradient confusion, and thus the efficiency of training. Our results
show that, for popular initialization techniques, increasing the width of
neural networks leads to lower gradient confusion, and thus faster model
training. On the other hand, increasing the depth of neural networks has the
opposite effect. Our results indicate that alternate initialization techniques
or networks using both batch normalization and skip connections help reduce the
training burden of very deep networks.},
 arxiv_url = {https://arxiv.org/pdf/1904.06963v5.pdf},
 author = {Karthik A. Sankararaman and Soham De and Zheng Xu and W. Ronny Huang and Tom Goldstein},
 title = {The Impact of Neural Network Overparameterization on Gradient Confusion and Stochastic Gradient Descent},
 year = {2019}
}

@article{schneider-2024-identifying,
 abstract = {Policy gradient methods hold great potential for solving complex continuous
control tasks. Still, their training efficiency can be improved by exploiting
structure within the optimization problem. Recent work indicates that
supervised learning can be accelerated by leveraging the fact that gradients
lie in a low-dimensional and slowly-changing subspace. In this paper, we
conduct a thorough evaluation of this phenomenon for two popular deep policy
gradient methods on various simulated benchmark tasks. Our results demonstrate
the existence of such gradient subspaces despite the continuously changing data
distribution inherent to reinforcement learning. These findings reveal
promising directions for future work on more efficient reinforcement learning,
e.g., through improving parameter-space exploration or enabling second-order
optimization.},
 arxiv_url = {https://arxiv.org/pdf/2401.06604v3.pdf},
 author = {Jan Schneider and Pierre Schumacher and Simon Guist and Le Chen and Daniel Häufle and Bernhard Schölkopf and Dieter Büchler},
 title = {Identifying Policy Gradient Subspaces},
 year = {2024}
}

@article{sozykin-2022-ttopt,
 abstract = {We present a novel procedure for optimization based on the combination of
efficient quantized tensor train representation and a generalized maximum
matrix volume principle. We demonstrate the applicability of the new Tensor
Train Optimizer (TTOpt) method for various tasks, ranging from minimization of
multidimensional functions to reinforcement learning. Our algorithm compares
favorably to popular evolutionary-based methods and outperforms them by the
number of function evaluations or execution time, often by a significant
margin.},
 arxiv_url = {https://arxiv.org/pdf/2205.00293v2.pdf},
 author = {Konstantin Sozykin and Andrei Chertkov and Roman Schutski and Anh-Huy Phan and Andrzej Cichocki and Ivan Oseledets},
 github_url = {https://github.com/AndreiChertkov/ttopt},
 title = {TTOpt: A Maximum Volume Quantized Tensor Train-based Optimization and its Application to Reinforcement Learning},
 year = {2022}
}

@article{su-2022-revisiting,
 abstract = {Deploying models on target domain data subject to distribution shift requires
adaptation. Test-time training (TTT) emerges as a solution to this adaptation
under a realistic scenario where access to full source domain data is not
available and instant inference on target domain is required. Despite many
efforts into TTT, there is a confusion over the experimental settings, thus
leading to unfair comparisons. In this work, we first revisit TTT assumptions
and categorize TTT protocols by two key factors. Among the multiple protocols,
we adopt a realistic sequential test-time training (sTTT) protocol, under which
we further develop a test-time anchored clustering (TTAC) approach to enable
stronger test-time feature learning. TTAC discovers clusters in both source and
target domain and match the target clusters to the source ones to improve
generalization. Pseudo label filtering and iterative updating are developed to
improve the effectiveness and efficiency of anchored clustering. We demonstrate
that under all TTT protocols TTAC consistently outperforms the state-of-the-art
methods on six TTT datasets. We hope this work will provide a fair benchmarking
of TTT methods and future research should be compared within respective
protocols. A demo code is available at
https://github.com/Gorilla-Lab-SCUT/TTAC.},
 arxiv_url = {https://arxiv.org/pdf/2206.02721v2.pdf},
 author = {Yongyi Su and Xun Xu and Kui Jia},
 github_url = {https://github.com/Gorilla-Lab-SCUT/TTAC},
 title = {Revisiting Realistic Test-Time Training: Sequential Inference and Adaptation by Anchored Clustering},
 year = {2022}
}

@article{sun-2019-test,
 abstract = {In this paper, we propose Test-Time Training, a general approach for
improving the performance of predictive models when training and test data come
from different distributions. We turn a single unlabeled test sample into a
self-supervised learning problem, on which we update the model parameters
before making a prediction. This also extends naturally to data in an online
stream. Our simple approach leads to improvements on diverse image
classification benchmarks aimed at evaluating robustness to distribution
shifts.},
 arxiv_url = {https://arxiv.org/pdf/1909.13231v3.pdf},
 author = {Yu Sun and Xiaolong Wang and Zhuang Liu and John Miller and Alexei A. Efros and Moritz Hardt},
 title = {Test-Time Training with Self-Supervision for Generalization under Distribution Shifts},
 year = {2019}
}

@article{wang-2020-tent,
 abstract = {A model must adapt itself to generalize to new and different data during
testing. In this setting of fully test-time adaptation the model has only the
test data and its own parameters. We propose to adapt by test entropy
minimization (tent): we optimize the model for confidence as measured by the
entropy of its predictions. Our method estimates normalization statistics and
optimizes channel-wise affine transformations to update online on each batch.
Tent reduces generalization error for image classification on corrupted
ImageNet and CIFAR-10/100 and reaches a new state-of-the-art error on
ImageNet-C. Tent handles source-free domain adaptation on digit recognition
from SVHN to MNIST/MNIST-M/USPS, on semantic segmentation from GTA to
Cityscapes, and on the VisDA-C benchmark. These results are achieved in one
epoch of test-time optimization without altering training.},
 arxiv_url = {https://arxiv.org/pdf/2006.10726v3.pdf},
 author = {Dequan Wang and Evan Shelhamer and Shaoteng Liu and Bruno Olshausen and Trevor Darrell},
 github_url = {https://github.com/DequanWang/tent},
 title = {Tent: Fully Test-Time Adaptation by Entropy Minimization},
 year = {2020}
}

@article{wang-2022-accelerating,
 abstract = {Hamiltonian Monte Carlo (HMC) is a popular method in sampling. While there
are quite a few works of studying this method on various aspects, an
interesting question is how to choose its integration time to achieve
acceleration. In this work, we consider accelerating the process of sampling
from a distribution $\pi(x) \propto \exp(-f(x))$ via HMC via time-varying
integration time. When the potential $f$ is $L$-smooth and $m$-strongly convex,
i.e.\ for sampling from a log-smooth and strongly log-concave target
distribution $\pi$, it is known that under a constant integration time, the
number of iterations that ideal HMC takes to get an $\epsilon$ Wasserstein-2
distance to the target $\pi$ is $O( \kappa \log \frac{1}{\epsilon} )$, where
$\kappa := \frac{L}{m}$ is the condition number. We propose a scheme of
time-varying integration time based on the roots of Chebyshev polynomials. We
show that in the case of quadratic potential $f$, i.e., when the target $\pi$
is a Gaussian distribution, ideal HMC with this choice of integration time only
takes $O( \sqrt{\kappa} \log \frac{1}{\epsilon} )$ number of iterations to
reach Wasserstein-2 distance less than $\epsilon$; this improvement on the
dependence on condition number is akin to acceleration in optimization. The
design and analysis of HMC with the proposed integration time is built on the
tools of Chebyshev polynomials. Experiments find the advantage of adopting our
scheme of time-varying integration time even for sampling from distributions
with smooth strongly convex potentials that are not quadratic.},
 arxiv_url = {https://arxiv.org/pdf/2207.02189v2.pdf},
 author = {Jun-Kun Wang and Andre Wibisono},
 title = {Accelerating Hamiltonian Monte Carlo via Chebyshev Integration Time},
 year = {2022}
}

@article{yoo-2023-what,
 abstract = {It is a well-known fact that the performance of deep learning models
deteriorates when they encounter a distribution shift at test time. Test-time
adaptation (TTA) algorithms have been proposed to adapt the model online while
inferring test data. However, existing research predominantly focuses on
classification tasks through the optimization of batch normalization layers or
classification heads, but this approach limits its applicability to various
model architectures like Transformers and makes it challenging to apply to
other tasks, such as object detection. In this paper, we propose a novel online
adaption approach for object detection in continually changing test domains,
considering which part of the model to update, how to update it, and when to
perform the update. By introducing architecture-agnostic and lightweight
adaptor modules and only updating these while leaving the pre-trained backbone
unchanged, we can rapidly adapt to new test domains in an efficient way and
prevent catastrophic forgetting. Furthermore, we present a practical and
straightforward class-wise feature aligning method for object detection to
resolve domain shifts. Additionally, we enhance efficiency by determining when
the model is sufficiently adapted or when additional adaptation is needed due
to changes in the test distribution. Our approach surpasses baselines on widely
used benchmarks, achieving improvements of up to 4.9\%p and 7.9\%p in mAP for
COCO $\rightarrow$ COCO-corrupted and SHIFT, respectively, while maintaining
about 20 FPS or higher.},
 arxiv_url = {https://arxiv.org/pdf/2312.08875v1.pdf},
 author = {Jayeon Yoo and Dongkwan Lee and Inseop Chung and Donghyun Kim and Nojun Kwak},
 title = {What How and When Should Object Detectors Update in Continually Changing Test Domains?},
 year = {2023}
}

@article{yuan-2023-robust,
 abstract = {Test-time adaptation (TTA) intends to adapt the pretrained model to test
distributions with only unlabeled test data streams. Most of the previous TTA
methods have achieved great success on simple test data streams such as
independently sampled data from single or multiple distributions. However,
these attempts may fail in dynamic scenarios of real-world applications like
autonomous driving, where the environments gradually change and the test data
is sampled correlatively over time. In this work, we explore such practical
test data streams to deploy the model on the fly, namely practical test-time
adaptation (PTTA). To do so, we elaborate a Robust Test-Time Adaptation (RoTTA)
method against the complex data stream in PTTA. More specifically, we present a
robust batch normalization scheme to estimate the normalization statistics.
Meanwhile, a memory bank is utilized to sample category-balanced data with
consideration of timeliness and uncertainty. Further, to stabilize the training
procedure, we develop a time-aware reweighting strategy with a teacher-student
model. Extensive experiments prove that RoTTA enables continual testtime
adaptation on the correlatively sampled data streams. Our method is easy to
implement, making it a good choice for rapid deployment. The code is publicly
available at https://github.com/BIT-DA/RoTTA},
 arxiv_url = {https://arxiv.org/pdf/2303.13899v1.pdf},
 author = {Longhui Yuan and Binhui Xie and Shuang Li},
 github_url = {https://github.com/BIT-DA/RoTTA},
 title = {Robust Test-Time Adaptation in Dynamic Scenarios},
 year = {2023}
}

@article{zancato-2020-predicting,
 abstract = {We tackle the problem of predicting the number of optimization steps that a
pre-trained deep network needs to converge to a given value of the loss
function. To do so, we leverage the fact that the training dynamics of a deep
network during fine-tuning are well approximated by those of a linearized
model. This allows us to approximate the training loss and accuracy at any
point during training by solving a low-dimensional Stochastic Differential
Equation (SDE) in function space. Using this result, we are able to predict the
time it takes for Stochastic Gradient Descent (SGD) to fine-tune a model to a
given loss without having to perform any training. In our experiments, we are
able to predict training time of a ResNet within a 20% error margin on a
variety of datasets and hyper-parameters, at a 30 to 45-fold reduction in cost
compared to actual training. We also discuss how to further reduce the
computational and memory cost of our method, and in particular we show that by
exploiting the spectral properties of the gradients' matrix it is possible
predict training time on a large dataset while processing only a subset of the
samples.},
 arxiv_url = {https://arxiv.org/pdf/2008.12478v1.pdf},
 author = {Luca Zancato and Alessandro Achille and Avinash Ravichandran and Rahul Bhotika and Stefano Soatto},
 title = {Predicting Training Time Without Training },
 year = {2020}
}

@article{zhao-2023-delta,
 abstract = {Fully test-time adaptation aims at adapting a pre-trained model to the test
stream during real-time inference, which is urgently required when the test
distribution differs from the training distribution. Several efforts have been
devoted to improving adaptation performance. However, we find that two
unfavorable defects are concealed in the prevalent adaptation methodologies
like test-time batch normalization (BN) and self-learning. First, we reveal
that the normalization statistics in test-time BN are completely affected by
the currently received test samples, resulting in inaccurate estimates. Second,
we show that during test-time adaptation, the parameter update is biased
towards some dominant classes. In addition to the extensively studied test
stream with independent and class-balanced samples, we further observe that the
defects can be exacerbated in more complicated test environments, such as
(time) dependent or class-imbalanced data. We observe that previous approaches
work well in certain scenarios while show performance degradation in others due
to their faults. In this paper, we provide a plug-in solution called DELTA for
Degradation-freE fuLly Test-time Adaptation, which consists of two components:
(i) Test-time Batch Renormalization (TBR), introduced to improve the estimated
normalization statistics. (ii) Dynamic Online re-weighTing (DOT), designed to
address the class bias within optimization. We investigate various test-time
adaptation methods on three commonly used datasets with four scenarios, and a
newly introduced real-world dataset. DELTA can help them deal with all
scenarios simultaneously, leading to SOTA performance.},
 arxiv_url = {https://arxiv.org/pdf/2301.13018v1.pdf},
 author = {Bowen Zhao and Chen Chen and Shu-Tao Xia},
 title = {DELTA: DEGRADATION-FREE FULLY TEST-TIME ADAPTATION},
 year = {2023}
}

@article{zheng-2023-svdinstn,
 abstract = {Tensor network (TN) representation is a powerful technique for computer
vision and machine learning. TN structure search (TN-SS) aims to search for a
customized structure to achieve a compact representation, which is a
challenging NP-hard problem. Recent "sampling-evaluation"-based methods require
sampling an extensive collection of structures and evaluating them one by one,
resulting in prohibitively high computational costs. To address this issue, we
propose a novel TN paradigm, named SVD-inspired TN decomposition (SVDinsTN),
which allows us to efficiently solve the TN-SS problem from a regularized
modeling perspective, eliminating the repeated structure evaluations. To be
specific, by inserting a diagonal factor for each edge of the fully-connected
TN, SVDinsTN allows us to calculate TN cores and diagonal factors
simultaneously, with the factor sparsity revealing a compact TN structure. In
theory, we prove a convergence guarantee for the proposed method. Experimental
results demonstrate that the proposed method achieves approximately 100 to 1000
times acceleration compared to the state-of-the-art TN-SS methods while
maintaining a comparable level of representation ability.},
 arxiv_url = {https://arxiv.org/pdf/2305.14912v6.pdf},
 author = {Yu-Bang Zheng and Xi-Le Zhao and Junhua Zeng and Chao Li and Qibin Zhao and Heng-Chao Li and Ting-Zhu Huang},
 title = {SVDinsTN: A Tensor Network Paradigm for Efficient Structure Search from Regularized Modeling Perspective},
 year = {2023}
}

% ===========================================
% REFERENCE CANDIDATES
% Additional reference papers for context
% ===========================================

@article{bartler-2021-meta,
 abstract = {An unresolved problem in Deep Learning is the ability of neural networks to
cope with domain shifts during test-time, imposed by commonly fixing network
parameters after training. Our proposed method Meta Test-Time Training (MT3),
however, breaks this paradigm and enables adaption at test-time. We combine
meta-learning, self-supervision and test-time training to learn to adapt to
unseen test distributions. By minimizing the self-supervised loss, we learn
task-specific model parameters for different tasks. A meta-model is optimized
such that its adaption to the different task-specific models leads to higher
performance on those tasks. During test-time a single unlabeled image is
sufficient to adapt the meta-model parameters. This is achieved by minimizing
only the self-supervised loss component resulting in a better prediction for
that image. Our approach significantly improves the state-of-the-art results on
the CIFAR-10-Corrupted image classification benchmark. Our implementation is
available on GitHub.},
 arxiv_url = {https://arxiv.org/pdf/2103.16201v2.pdf},
 author = {Alexander Bartler and Andre Bühler and Felix Wiewel and Mario Döbler and Bin Yang},
 title = {Mt3: Meta test-time training for self-supervised test-time adaption},
 year = {2021}
}

@article{bartler-2022-ttaps,
 abstract = {Nowadays, deep neural networks outperform humans in many tasks. However, if
the input distribution drifts away from the one used in training, their
performance drops significantly. Recently published research has shown that
adapting the model parameters to the test sample can mitigate this performance
degradation. In this paper, we therefore propose a novel modification of the
self-supervised training algorithm SwAV that adds the ability to adapt to
single test samples. Using the provided prototypes of SwAV and our derived
test-time loss, we align the representation of unseen test samples with the
self-supervised learned prototypes. We show the success of our method on the
common benchmark dataset CIFAR10-C.},
 arxiv_url = {https://arxiv.org/pdf/2205.08731v1.pdf},
 author = {Alexander Bartler and Florian Bender and Felix Wiewel and Bin Yang},
 title = {Ttaps: Test-time adaption by aligning prototypes using self-supervision},
 year = {2022}
}