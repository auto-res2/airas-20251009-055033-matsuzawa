
Input:
You are a researcher with expertise in engineering in the field of machine learning.

# Instructions
- The content described in “Repository Content” corresponds to the GitHub repository of the method described in “Method.”
- Please extract the following two pieces of information from “Repository Content”:
    - experimental_code：Extract the implementation sections that are directly related to the method described in “Method.”
    - experimental_info：Extract and output the experimental settings related to the method described in “Method.”

# Method
AETTA's methodology is grounded in comparing a model's prediction with predictions from its dropout inferences, termed Prediction Disagreement with Dropouts (PDD). It assumes 'dropout independence' (dropout inferences simulate i.i.d. models) and 'confidence-prediction calibration' to theoretically approximate test error with PDD. To address adaptation failures, which often lead to over-confident incorrect predictions and violate standard calibration, AETTA proposes 'robust confidence-prediction calibration'. This is achieved by introducing a weighting constant 'b' that dynamically scales predicted probabilities. The constant 'b' is determined by the skewness of predicted outputs, specifically using the entropy of batch-aggregated softmax values from dropout inferences (Eavg), modeled as b = (Eavg / Emax)^(-α). The final accuracy estimation (Err) is approximated as ErrDT(h) ≈ b PDDDT(h), with C omitted due to lack of information. The process involves performing N dropout inferences, calculating PDD and Eavg, and then applying the scaling factor 'b' to estimate the error. Exponential moving average is applied for stable error estimation.

# Repository Content
File Path: conf.py
Content:

args = None

CIFAR10Opt = {
    'name': 'cifar10',
    'batch_size': 64, # 128

    'learning_rate': 0.1,  # initial learning rate
    'weight_decay': 0.0005,
    'momentum': 0.9,
    'img_size': 3072,

    'file_path': './dataset/CIFAR-10-C',
    'classes': ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'],
    'num_class': 10,
    'severity': 5,
    'domains': ["original",

                "test",

                "gaussian_noise-1", "gaussian_noise-2", "gaussian_noise-3", "gaussian_noise-4", "gaussian_noise-5",
                "gaussian_noise-all",

                "shot_noise-1", "shot_noise-2", "shot_noise-3", "shot_noise-4", "shot_noise-5", "shot_noise-all",

                "impulse_noise-1", "impulse_noise-2", "impulse_noise-3", "impulse_noise-4", "impulse_noise-5",
                "impulse_noise-all",

                "defocus_blur-1", "defocus_blur-2", "defocus_blur-3", "defocus_blur-4", "defocus_blur-5",
                "defocus_blur-all",

                "glass_blur-1", "glass_blur-2", "glass_blur-3", "glass_blur-4", "glass_blur-5", "glass_blur-all",

                "motion_blur-1", "motion_blur-2", "motion_blur-3", "motion_blur-4", "motion_blur-5", "motion_blur-all",

                "zoom_blur-1", "zoom_blur-2", "zoom_blur-3", "zoom_blur-4", "zoom_blur-5", "zoom_blur-all",

                "snow-1", "snow-2", "snow-3", "snow-4", "snow-5", "snow-all",

                "frost-1", "frost-2", "frost-3", "frost-4", "frost-5", "frost-all",

                "fog-1", "fog-2", "fog-3", "fog-4", "fog-5", "fog-all",

                "brightness-1", "brightness-2", "brightness-3", "brightness-4", "brightness-5", "brightness-all",

                "contrast-1", "contrast-2", "contrast-3", "contrast-4", "contrast-5", "contrast-all",

                "elastic_transform-1", "elastic_transform-2", "elastic_transform-3", "elastic_transform-4",
                "elastic_transform-5", "elastic_transform-all",

                "pixelate-1", "pixelate-2", "pixelate-3", "pixelate-4", "pixelate-5", "pixelate-all",

                "jpeg_compression-1", "jpeg_compression-2", "jpeg_compression-3", "jpeg_compression-4",
                "jpeg_compression-5", "jpeg_compression-all",
                ],
    'src_domains': ["original"],
    'tgt_domains': [
                    "gaussian_noise-5",
                    "shot_noise-5",
                    "impulse_noise-5",
                    "defocus_blur-5",
                    "glass_blur-5",
                    "motion_blur-5",
                    "zoom_blur-5",
                    "snow-5",
                    "frost-5",
                    "fog-5",
                    "brightness-5",
                    "contrast-5",
                    "elastic_transform-5",
                    "pixelate-5",
                    "jpeg_compression-5",

    ],
    
    'indices_in_1k' : None
}

CIFAR100Opt = {
    'name': 'cifar100',
    'batch_size': 128,

    'learning_rate': 0.1,  # initial learning rate
    'weight_decay': 0.0005,
    'momentum': 0.9,
    'img_size': 3072,

    'file_path': './dataset/CIFAR-100-C',
    'classes': ['beaver', 'dolphin', 'otter', 'seal', 'whale',
                'aquarium fish', 'flatfish', 'ray', 'shark', 'trout',
                'orchids', 'poppies', 'roses', 'sunflowers', 'tulips',
                'bottles', 'bowls', 'cans', 'cups', 'plates',
                'apples', 'mushrooms', 'oranges', 'pears', 'sweet peppers',
                'clock', 'computer keyboard', 'lamp', 'telephone', 'television',
                'bed', 'chair', 'couch', 'table', 'wardrobe',
                'bee', 'beetle', 'butterfly', 'caterpillar', 'cockroach',
                'bear', 'leopard', 'lion', 'tiger', 'wolf',
                'bridge', 'castle', 'house', 'road', 'skyscraper',
                'cloud', 'forest', 'mountain', 'plain', 'sea',
                'camel', 'cattle', 'chimpanzee', 'elephant', 'kangaroo',
                'fox', 'porcupine', 'possum', 'raccoon', 'skunk',
                'crab', 'lobster', 'snail', 'spider', 'worm',
                'baby', 'boy', 'girl', 'man', 'woman',
                'crocodile', 'dinosaur', 'lizard', 'snake', 'turtle',
                'hamster', 'mouse', 'rabbit', 'shrew', 'squirrel',
                'maple', 'oak', 'palm', 'pine', 'willow',
                'bicycle', 'bus', 'motorcycle', 'pickup truck', 'train',
                'lawn-mower', 'rocket', 'streetcar', 'tank', 'tractor'],
    'num_class': 100,
    'severity': 5,
    # 'corruptions': ["shot_noise", "motion_blur", "snow", "pixelate", "gaussian_noise", "defocus_blur",
    #                 "brightness", "fog", "zoom_blur", "frost", "glass_blur", "impulse_noise", "contrast",
    #                 "jpeg_compression", "elastic_transform"],
    'domains': ["original",

                "test",

                "gaussian_noise-1", "gaussian_noise-2", "gaussian_noise-3", "gaussian_noise-4", "gaussian_noise-5",
                "gaussian_noise-all",

                "shot_noise-1", "shot_noise-2", "shot_noise-3", "shot_noise-4", "shot_noise-5", "shot_noise-all",

                "impulse_noise-1", "impulse_noise-2", "impulse_noise-3", "impulse_noise-4", "impulse_noise-5",
                "impulse_noise-all",

                "defocus_blur-1", "defocus_blur-2", "defocus_blur-3", "defocus_blur-4", "defocus_blur-5",
                "defocus_blur-all",

                "glass_blur-1", "glass_blur-2", "glass_blur-3", "glass_blur-4", "glass_blur-5", "glass_blur-all",

                "motion_blur-1", "motion_blur-2", "motion_blur-3", "motion_blur-4", "motion_blur-5", "motion_blur-all",

                "zoom_blur-1", "zoom_blur-2", "zoom_blur-3", "zoom_blur-4", "zoom_blur-5", "zoom_blur-all",

                "snow-1", "snow-2", "snow-3", "snow-4", "snow-5", "snow-all",

                "frost-1", "frost-2", "frost-3", "frost-4", "frost-5", "frost-all",

                "fog-1", "fog-2", "fog-3", "fog-4", "fog-5", "fog-all",

                "brightness-1", "brightness-2", "brightness-3", "brightness-4", "brightness-5", "brightness-all",

                "contrast-1", "contrast-2", "contrast-3", "contrast-4", "contrast-5", "contrast-all",

                "elastic_transform-1", "elastic_transform-2", "elastic_transform-3", "elastic_transform-4",
                "elastic_transform-5", "elastic_transform-all",

                "pixelate-1", "pixelate-2", "pixelate-3", "pixelate-4", "pixelate-5", "pixelate-all",

                "jpeg_compression-1", "jpeg_compression-2", "jpeg_compression-3", "jpeg_compression-4",
                "jpeg_compression-5", "jpeg_compression-all",
                ],
    'src_domains': ["original"],
    'tgt_domains': [
        "gaussian_noise-5",
                    "shot_noise-5",
                    "impulse_noise-5",
                    "defocus_blur-5",
                    "glass_blur-5",
                    "motion_blur-5",
                    "zoom_blur-5",
                    "snow-5",
                    "frost-5",
                    "fog-5",
                    "brightness-5",
                    "contrast-5",
                    "elastic_transform-5",
                    "pixelate-5",
                    "jpeg_compression-5",

    ],
    
    'indices_in_1k' : None
}

IMAGENET_C = {
    # referred to for hyperparams: https://github.com/Lornatang/ResNet-PyTorch/blob/9e529757ce0607aafeae2ddd97142201b3d4cadd/examples/imagenet/main.py
    'name': 'imagenet',
    'batch_size': 256,
    'learning_rate': 0.001,
    'weight_decay': 0,
    'momentum': 0.9,
    'img_size': 3072,

    'file_path': './dataset/ImageNet-C',
    'num_class': 1000,
    'severity': 5,
    'domains': ["gaussian_noise-1", "gaussian_noise-2", "gaussian_noise-3", "gaussian_noise-4", "gaussian_noise-5",
                "gaussian_noise-all",

                "shot_noise-1", "shot_noise-2", "shot_noise-3", "shot_noise-4", "shot_noise-5", "shot_noise-all",

                "impulse_noise-1", "impulse_noise-2", "impulse_noise-3", "impulse_noise-4", "impulse_noise-5",
                "impulse_noise-all",

                "defocus_blur-1", "defocus_blur-2", "defocus_blur-3", "defocus_blur-4", "defocus_blur-5",
                "defocus_blur-all",

                "glass_blur-1", "glass_blur-2", "glass_blur-3", "glass_blur-4", "glass_blur-5", "glass_blur-all",

                "motion_blur-1", "motion_blur-2", "motion_blur-3", "motion_blur-4", "motion_blur-5", "motion_blur-all",

                "zoom_blur-1", "zoom_blur-2", "zoom_blur-3", "zoom_blur-4", "zoom_blur-5", "zoom_blur-all",

                "snow-1", "snow-2", "snow-3", "snow-4", "snow-5", "snow-all",

                "frost-1", "frost-2", "frost-3", "frost-4", "frost-5", "frost-all",

                "fog-1", "fog-2", "fog-3", "fog-4", "fog-5", "fog-all",

                "brightness-1", "brightness-2", "brightness-3", "brightness-4", "brightness-5", "brightness-all",

                "contrast-1", "contrast-2", "contrast-3", "contrast-4", "contrast-5", "contrast-all",

                "elastic_transform-1", "elastic_transform-2", "elastic_transform-3", "elastic_transform-4",
                "elastic_transform-5", "elastic_transform-all",

                "pixelate-1", "pixelate-2", "pixelate-3", "pixelate-4", "pixelate-5", "pixelate-all",

                "jpeg_compression-1", "jpeg_compression-2", "jpeg_compression-3", "jpeg_compression-4",
                "jpeg_compression-5", "jpeg_compression-all",
                ],

    'src_domains': ["original"],
    'tgt_domains': ["gaussian_noise-5",
                    "shot_noise-5",
                    "impulse_noise-5",
                    "defocus_blur-5",
                    "glass_blur-5",
                    "motion_blur-5",
                    "zoom_blur-5",
                    "snow-5",
                    "frost-5",
                    "fog-5",
                    "brightness-5",
                    "contrast-5",
                    "elastic_transform-5",
                    "pixelate-5",
                    "jpeg_compression-5",

    ],
    
    'indices_in_1k' : None
}

MNISTOpt = {
    'name': 'mnist',
    'batch_size': 128,

    'learning_rate': 0.1,  # initial learning rate
    'weight_decay': 0.0005,
    'momentum': 0.9,
    'img_size': 3072,

    'file_path': './dataset/MNIST-C',
    'classes': ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'],
    'num_class': 10,
    'domains': ["original",

                "test",

                "shot_noise",
                "impulse_noise",
                "glass_blur",
                "motion_blur",
                "shear",
                "scale",
                "rotate",
                "brightness",
                "translate",
                "stripe",
                "fog",
                "spatter",
                "dotted_line",
                "zigzag",
                "canny_edges",

                ],
    'src_domains': ["original"],
    'tgt_domains': [
        "shot_noise",
        "impulse_noise",
        "glass_blur",
        "motion_blur",
        "shear",
        "scale",
        "rotate",
        "brightness",
        "translate",
        "stripe",
        "fog",
        "spatter",
        "dotted_line",
        "zigzag",
        "canny_edges",
    
    ],
    
    'indices_in_1k' : None

}

CONT_SEQUENCE = {
    0 :  ["gaussian_noise-5", "shot_noise-5", "impulse_noise-5", "defocus_blur-5", "glass_blur-5", "motion_blur-5", "zoom_blur-5", "snow-5", "frost-5", "fog-5", "brightness-5", "contrast-5", "elastic_transform-5", "pixelate-5", "jpeg_compression-5"],
    1 :  ['brightness-5', 'pixelate-5', 'gaussian_noise-5', 'motion_blur-5', 'zoom_blur-5', 'glass_blur-5', 'impulse_noise-5', 'jpeg_compression-5', 'defocus_blur-5', 'elastic_transform-5', 'shot_noise-5', 'frost-5', 'snow-5', 'fog-5', 'contrast-5'],
    2  : ['jpeg_compression-5', 'shot_noise-5', 'zoom_blur-5', 'frost-5', 'contrast-5', 'fog-5', 'defocus_blur-5', 'elastic_transform-5', 'gaussian_noise-5', 'brightness-5', 'glass_blur-5', 'impulse_noise-5', 'pixelate-5', 'snow-5', 'motion_blur-5'],
    3  : ['contrast-5', 'defocus_blur-5', 'gaussian_noise-5', 'shot_noise-5', 'snow-5', 'frost-5', 'glass_blur-5', 'zoom_blur-5', 'elastic_transform-5', 'jpeg_compression-5', 'pixelate-5', 'brightness-5', 'impulse_noise-5', 'motion_blur-5', 'fog-5'],
    4  : ['shot_noise-5', 'fog-5', 'glass_blur-5', 'pixelate-5', 'snow-5', 'elastic_transform-5', 'brightness-5', 'impulse_noise-5', 'defocus_blur-5', 'frost-5', 'contrast-5', 'gaussian_noise-5', 'motion_blur-5', 'jpeg_compression-5', 'zoom_blur-5'],
    5  : ['pixelate-5', 'glass_blur-5', 'zoom_blur-5', 'snow-5', 'fog-5', 'impulse_noise-5', 'brightness-5', 'motion_blur-5', 'frost-5', 'jpeg_compression-5', 'gaussian_noise-5', 'shot_noise-5', 'contrast-5', 'defocus_blur-5', 'elastic_transform-5'],
    6  : ['motion_blur-5', 'snow-5', 'fog-5', 'shot_noise-5', 'defocus_blur-5', 'contrast-5', 'zoom_blur-5', 'brightness-5', 'frost-5', 'elastic_transform-5', 'glass_blur-5', 'gaussian_noise-5', 'pixelate-5', 'jpeg_compression-5', 'impulse_noise-5'],
    7  : ['frost-5', 'impulse_noise-5', 'jpeg_compression-5', 'contrast-5', 'zoom_blur-5', 'glass_blur-5', 'pixelate-5', 'snow-5', 'defocus_blur-5', 'motion_blur-5', 'brightness-5', 'elastic_transform-5', 'shot_noise-5', 'fog-5', 'gaussian_noise-5'],
    8  : ['defocus_blur-5', 'motion_blur-5', 'zoom_blur-5', 'shot_noise-5', 'gaussian_noise-5', 'glass_blur-5', 'jpeg_compression-5', 'fog-5', 'contrast-5', 'pixelate-5', 'frost-5', 'snow-5', 'brightness-5', 'elastic_transform-5', 'impulse_noise-5'],
    9  : ['glass_blur-5', 'zoom_blur-5', 'impulse_noise-5', 'fog-5', 'snow-5', 'jpeg_compression-5', 'gaussian_noise-5', 'frost-5', 'shot_noise-5', 'brightness-5', 'contrast-5', 'motion_blur-5', 'pixelate-5', 'defocus_blur-5', 'elastic_transform-5'],
    10  : ['contrast-5', 'gaussian_noise-5', 'defocus_blur-5', 'zoom_blur-5', 'frost-5', 'glass_blur-5', 'jpeg_compression-5', 'fog-5', 'pixelate-5', 'elastic_transform-5', 'shot_noise-5', 'impulse_noise-5', 'snow-5', 'motion_blur-5', 'brightness-5'],
    
    
    
}

IMAGENET_R = {
    # referred to for hyperparams: https://github.com/Lornatang/ResNet-PyTorch/blob/9e529757ce0607aafeae2ddd97142201b3d4cadd/examples/imagenet/main.py
    'name': 'imagenet-r',
    'batch_size': 256,
    'learning_rate': 0.001,
    'weight_decay': 0,
    'momentum': 0.9,
    'img_size': 3072,

    'file_path': './dataset/imagenet-r',
    'num_class': 200, # select 200 from 1000
    'severity': 5,

    'domains': ['original', 'corrupt'], 

    'src_domains': ["original"],
    'tgt_domains': ["corrupt"],
    
    'indices_in_1k' : [1, 2, 4, 6, 8, 9, 11, 13, 22, 23, 26, 29, 31, 39, 47, 63, 71, 76, 79, 84, 90, 94, 96, 97, 99, 100, 105, 107, 113, 122, 125, 130, 132, 144, 145, 147, 148, 150, 151, 155, 160, 161, 162, 163, 171, 172, 178, 187, 195, 199, 203, 207, 208, 219, 231, 232, 234, 235, 242, 245, 247, 250, 251, 254, 259, 260, 263, 265, 267, 269, 276, 277, 281, 288, 289, 291, 292, 293, 296, 299, 301, 308, 309, 310, 311, 314, 315, 319, 323, 327, 330, 334, 335, 337, 338, 340, 341, 344, 347, 353, 355, 361, 362, 365, 366, 367, 368, 372, 388, 390, 393, 397, 401, 407, 413, 414, 425, 428, 430, 435, 437, 441, 447, 448, 457, 462, 463, 469, 470, 471, 472, 476, 483, 487, 515, 546, 555, 558, 570, 579, 583, 587, 593, 594, 596, 609, 613, 617, 621, 629, 637, 657, 658, 701, 717, 724, 763, 768, 774, 776, 779, 780, 787, 805, 812, 815, 820, 824, 833, 847, 852, 866, 875, 883, 889, 895, 907, 928, 931, 932, 933, 934, 936, 937, 943, 945, 947, 948, 949, 951, 953, 954, 957, 963, 965, 967, 980, 981, 983, 988]

}



File Path: data_loader/CIFAR100Dataset.py
Content:
import os
import warnings
import torch.utils.data
import torchvision.datasets as datasets
import torchvision.transforms as transforms

import pandas as pd
import time
import numpy as np
import sys
import conf

opt = conf.CIFAR100Opt


class CIFAR100Dataset(torch.utils.data.Dataset):

    def __init__(self, file='../dataset/ichar/minmax_scaling_all.csv',
                 domains=None, activities=None,
                 max_source=100, transform='none'):
        st = time.time()
        self.domains = domains
        self.activity = activities
        self.max_source = max_source

        self.domains = domains

        self.img_shape = opt['img_size']
        self.features = None
        self.class_labels = None
        self.domain_labels = None
        self.file_path = opt['file_path']

        assert (len(domains) > 0)
        if domains[0].startswith('original'):
            self.sub_path1 = 'origin'
            self.sub_path2 = ''
            self.data_filename = 'original.npy'
            self.label_filename = 'labels.npy'
        elif domains[0].startswith('test'):
            self.sub_path1 = 'corrupted'
            self.sub_path2 = 'severity-1'  # all data are same in 1~5
            self.data_filename = 'test.npy'
            self.label_filename = 'labels.npy'
        elif domains[0].endswith('-1'):
            self.sub_path1 = 'corrupted'
            self.sub_path2 = 'severity-1'
            self.data_filename = domains[0].split('-')[0] + '.npy'
            self.label_filename = 'labels.npy'
        elif domains[0].endswith('-2'):
            self.sub_path1 = 'corrupted'
            self.sub_path2 = 'severity-2'
            self.data_filename = domains[0].split('-')[0] + '.npy'
            self.label_filename = 'labels.npy'
        elif domains[0].endswith('-3'):
            self.sub_path1 = 'corrupted'
            self.sub_path2 = 'severity-3'
            self.data_filename = domains[0].split('-')[0] + '.npy'
            self.label_filename = 'labels.npy'
        elif domains[0].endswith('-4'):
            self.sub_path1 = 'corrupted'
            self.sub_path2 = 'severity-4'
            self.data_filename = domains[0].split('-')[0] + '.npy'
            self.label_filename = 'labels.npy'
        elif domains[0].endswith('-5'):
            self.sub_path1 = 'corrupted'
            self.sub_path2 = 'severity-5'
            self.data_filename = domains[0].split('-')[0] + '.npy'
            self.label_filename = 'labels.npy'
        elif domains[0].endswith('-all'):
            self.sub_path1 = 'corrupted'
            self.sub_path2 = 'severity-all'
            self.data_filename = domains[0].split('-')[0] + '.npy'
            self.label_filename = 'labels.npy'

        if transform == 'src':
            self.transform = transforms.Compose(
                [
                    transforms.RandomCrop(32, padding=4),
                    transforms.RandomHorizontalFlip(),
                ])

        elif transform == 'val':
            self.transform = None
        else:
            raise NotImplementedError

        self.preprocessing()

    def preprocessing(self):

        path = f'{self.file_path}/{self.sub_path1}/{self.sub_path2}/'

        data = np.load(path + self.data_filename)
        # change NHWC to NCHW format
        data = np.transpose(data, (0, 3, 1, 2))
        # make it compatible with our models (normalize)
        data = data.astype(np.float32) / 255.0

        self.features = data
        self.class_labels = np.load(path + self.label_filename)
        # assume that single domain is passed as List
        self.domain_labels = np.array([0 for i in range(len(self.features))])

        self.dataset = torch.utils.data.TensorDataset(
            torch.from_numpy(self.features),  # resize for resnet
            torch.from_numpy(self.class_labels),
            torch.from_numpy(self.domain_labels))

    def __len__(self):
        return len(self.dataset)

    def get_num_domains(self):
        return len(self.domains)

    def get_datasets_per_domain(self):
        return self.datasets

    def __getitem__(self, idx):
        if isinstance(idx, torch.Tensor):
            idx = idx.item()
        img, cl, dl = self.dataset[idx]
        if self.transform:
            img = self.transform(img)
        return img, cl, dl


if __name__ == '__main__':
    pass

File Path: data_loader/CIFAR10Dataset.py
Content:
import os
import warnings
import torch.utils.data
import torchvision.datasets as datasets
import torchvision.transforms as transforms

import pandas as pd
import time
import numpy as np
import sys
import conf

opt = conf.CIFAR10Opt


class CIFAR10Dataset(torch.utils.data.Dataset):

    def __init__(self, file='../dataset/ichar/minmax_scaling_all.csv',
                 domains=None, activities=None,
                 max_source=100, transform='none'):
        st = time.time()
        self.domains = domains
        self.activity = activities
        self.max_source = max_source

        self.domains = domains

        self.img_shape = opt['img_size']
        self.features = None
        self.class_labels = None
        self.domain_labels = None
        self.file_path = opt['file_path']

        assert (len(domains) > 0)
        if domains[0].startswith('original'):
            self.sub_path1 = 'origin'
            self.sub_path2 = ''
            self.data_filename = 'original.npy'
            self.label_filename = 'labels.npy'
        elif domains[0].startswith('test'):
            self.sub_path1 = 'corrupted'
            self.sub_path2 = 'severity-1'  # all data are same in 1~5
            self.data_filename = 'test.npy'
            self.label_filename = 'labels.npy'
        elif domains[0].endswith('-1'):
            self.sub_path1 = 'corrupted'
            self.sub_path2 = 'severity-1'
            self.data_filename = domains[0].split('-')[0] + '.npy'
            self.label_filename = 'labels.npy'
        elif domains[0].endswith('-2'):
            self.sub_path1 = 'corrupted'
            self.sub_path2 = 'severity-2'
            self.data_filename = domains[0].split('-')[0] + '.npy'
            self.label_filename = 'labels.npy'
        elif domains[0].endswith('-3'):
            self.sub_path1 = 'corrupted'
            self.sub_path2 = 'severity-3'
            self.data_filename = domains[0].split('-')[0] + '.npy'
            self.label_filename = 'labels.npy'
        elif domains[0].endswith('-4'):
            self.sub_path1 = 'corrupted'
            self.sub_path2 = 'severity-4'
            self.data_filename = domains[0].split('-')[0] + '.npy'
            self.label_filename = 'labels.npy'
        elif domains[0].endswith('-5'):
            self.sub_path1 = 'corrupted'
            self.sub_path2 = 'severity-5'
            self.data_filename = domains[0].split('-')[0] + '.npy'
            self.label_filename = 'labels.npy'
        elif domains[0].endswith('_all'):
            self.sub_path1 = 'corrupted'
            self.sub_path2 = 'severity_all'
            self.data_filename = str(domains[0][:-4]) + '.npy'
            self.label_filename = 'labels.npy'

        if transform == 'src':
            self.transform = transforms.Compose(
                [
                    transforms.RandomCrop(32, padding=4),
                    transforms.RandomHorizontalFlip(),
                ])

        elif transform == 'val':
            self.transform = None
        else:
            raise NotImplementedError

        self.preprocessing()

    def preprocessing(self):

        path = f'{self.file_path}/{self.sub_path1}/{self.sub_path2}/'

        data = np.load(path + self.data_filename)
        # change NHWC to NCHW format
        data = np.transpose(data, (0, 3, 1, 2))
        # make it compatible with our models (normalize)
        data = data.astype(np.float32)/ 255.0
        self.features = data
        self.class_labels = np.load(path + self.label_filename)
        # assume that single domain is passed as List
        self.domain_labels = np.array([0 for i in range(len(self.features))])

        self.dataset = torch.utils.data.TensorDataset(
            torch.from_numpy(self.features),
            torch.from_numpy(self.class_labels),
            torch.from_numpy(self.domain_labels))

    def __len__(self):
        return len(self.dataset)

    def get_num_domains(self):
        return len(self.domains)

    def get_datasets_per_domain(self):
        return self.datasets

    def __getitem__(self, idx):
        if isinstance(idx, torch.Tensor):
            idx = idx.item()
        img, cl, dl = self.dataset[idx]
        if self.transform:
            img = self.transform(img)
        return img, cl, dl


if __name__ == '__main__':
    pass

File Path: data_loader/IMAGENETDataset.py
Content:
import os
import warnings
import torch.utils.data
import torchvision.datasets as datasets
import torchvision.transforms as transforms
from torchvision.datasets import MNIST, ImageFolder

from PIL import Image

import pandas as pd
import time
import numpy as np
import sys
import conf
import json
import tqdm as tqdm

opt = conf.IMAGENET_C


class ImageNetDataset(torch.utils.data.Dataset):

    def __init__(self, file='',
                 domain=None, activities=None,
                 max_source=100, transform='none'):
        st = time.time()
        self.domain = domain
        self.activity = activities
        self.max_source = max_source

        self.domain = domain
        self.features = None
        self.class_labels = None
        self.domain_labels = None
        self.file_path = opt['file_path']
        self.transform_type = transform

        assert (len(domain) > 0)
        if domain.startswith('original'):
            self.path = 'origin/Data/CLS-LOC/train/'
        elif domain.startswith('test'):
            self.path = 'origin/Data/CLS-LOC/val/'
        else:
            self.path = 'corrupted/'
            corruption, severity = domain.split('-')
            self.path += corruption + '/' + severity + '/'

        if transform == 'src':
            self.transform = transforms.Compose([
                transforms.RandomResizedCrop(224),
                transforms.RandomHorizontalFlip(),
                transforms.ToTensor()
            ])
        elif transform == 'val':
            if domain.startswith('original') or domain.startswith('test'):
                self.transform = transforms.Compose([
                    transforms.Resize(256),
                    transforms.CenterCrop(224),
                    transforms.ToTensor()
                ])
            else:
                self.transform = transforms.Compose([
                    transforms.CenterCrop(224),
                    transforms.ToTensor()
                ])
        else:
            raise NotImplementedError

        self.preprocessing()

    def preprocessing(self):

        path = self.file_path + '/' + self.path
        self.features = []
        self.class_labels = []
        self.domain_labels = []
        print('preprocessing images..')
        self.dataset = ImageFolder(path)

    def load_features(self):
        path = self.file_path + '/' + self.path
        dataset = ImageFolder(path, transform=self.transform)
        dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=False, pin_memory=False, drop_last=False)
        # transformed_dataset = []
        for b_i, data in enumerate(dataloader):  # must be loaded from dataloader, due to transform in the __getitem__()
            feat, cl = data
            # convert a batch of tensors to list, and then append to our list one by one
            feats = torch.unbind(feat, dim=0)
            cls = torch.unbind(cl, dim=0)
            for i in range(len(feats)):
                # transformed_dataset.append((feats[i], cls[i]))
                self.features.append(feats[i])
                self.class_labels.append(cls[i])
                self.domain_labels.append(0)
        self.features = np.stack(self.features)
        self.class_labels = np.stack(self.class_labels)
        self.domain_labels = np.stack(self.domain_labels)

    def __len__(self):
        return len(self.dataset)

    def get_num_domains(self):
        return 1

    def get_datasets_per_domain(self):
        return self.datasets

    def __getitem__(self, idx):
        if isinstance(idx, torch.Tensor):
            idx = idx.item()
        img, cl = self.dataset[idx]
        if self.transform:
            img = self.transform(img)
        return img, cl, torch.tensor(0)


if __name__ == '__main__':
    ### code for making imagenet validation data compatiable with ImageFolder!
    '''
    import os
    root = '/mnt/sting/tsgong/WWW/dataset/ImageNet-C/origin/Data/CLS-LOC/val/'
    f = open(root+'LOC_val_solution.csv', 'r')
    i=0
    for l in f:
        if i ==0: # ignore header
            i += 1
            continue
        filename=l.split(',')[0]
        label=l.split(',')[1].split(' ')[0]
        dir = root+label
        ### 1. make dir
        # if not os.path.exists(dir):
        #     os.makedirs(dir)
        # print(os.path.join(root,filename,'.JPEG'))
        ### 2. move files to dir
        print(label)
        if os.path.isfile(os.path.join(root, filename + '.JPEG')):
            os.rename(os.path.join(root, filename + '.JPEG'), os.path.join(dir, filename + '.JPEG'))
        i += 1
    print(i)
    '''

File Path: data_loader/IMAGENETRDataset.py
Content:
import os
import warnings
import torch.utils.data
import torchvision.datasets as datasets
import torchvision.transforms as transforms
from torchvision.datasets import MNIST, ImageFolder

from PIL import Image

import pandas as pd
import time
import numpy as np
import sys
import conf
import json
import tqdm as tqdm

opt = conf.IMAGENET_R


class ImageNetRDataset(torch.utils.data.Dataset):

    def __init__(self, file='',
                 domain=None, activities=None,
                 max_source=100, transform='none'):
        
        st = time.time()
        self.domain = domain
        self.activity = activities
        self.max_source = max_source

        self.domain = domain
        self.features = None
        self.class_labels = None
        self.domain_labels = None
        self.file_path = opt['file_path']
        self.transform_type = transform

        assert (len(domain) > 0)
        if domain.startswith('original'):
            self.path = 'dataset/Imagenet-C/origin/Data/CLS-LOC/train/'
        elif domain.startswith('test'):
            self.path = 'dataset/Imagenet-C/origin/Data/CLS-LOC/val/'
        elif domain == "corrupt":
            self.path = None
        else:
            raise NotImplementedError
            # self.path = 'corrupted/'
            # corruption, severity = domain.split('-')
            # self.path += corruption + '/' + severity + '/'
            
        if transform == 'src':
            self.transform = transforms.Compose([
                transforms.RandomResizedCrop(224),
                transforms.RandomHorizontalFlip(),
                transforms.ToTensor()
            ])
        elif transform == 'val':
            self.transform = transforms.Compose([
                transforms.Resize(256),
                transforms.CenterCrop(224),
                transforms.ToTensor()
            ])

        else:
            raise NotImplementedError

        self.preprocessing()

    def preprocessing(self):

        path = self.file_path if self.path == None else self.path
        self.features = []
        self.class_labels = []
        self.domain_labels = []
        print('preprocessing images..')
        self.dataset = ImageFolder(path)

    def load_features(self):
        path = self.file_path if self.path == None else self.path
        dataset = ImageFolder(path, transform=self.transform)
        dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=False, pin_memory=False, drop_last=False)
        # transformed_dataset = []
        for b_i, data in enumerate(dataloader):  # must be loaded from dataloader, due to transform in the __getitem__()
            feat, cl = data
            # convert a batch of tensors to list, and then append to our list one by one
            feats = torch.unbind(feat, dim=0)
            cls = torch.unbind(cl, dim=0)
            for i in range(len(feats)):
                # transformed_dataset.append((feats[i], cls[i]))
                self.features.append(feats[i])
                self.class_labels.append(cls[i])
                self.domain_labels.append(0)
        self.features = np.stack(self.features)
        self.class_labels = np.stack(self.class_labels)
        self.domain_labels = np.stack(self.domain_labels)

    def __len__(self):
        return len(self.dataset)

    def get_num_domains(self):
        return 1

    def get_datasets_per_domain(self):
        return self.datasets

    def __getitem__(self, idx):
        if isinstance(idx, torch.Tensor):
            idx = idx.item()
        img, cl = self.dataset[idx]
        if self.transform:
            img = self.transform(img)
        return img, cl, torch.tensor(0)


if __name__ == '__main__':
    ### code for making imagenet validation data compatiable with ImageFolder!
    '''
    import os
    root = '/mnt/sting/tsgong/WWW/dataset/ImageNet-C/origin/Data/CLS-LOC/val/'
    f = open(root+'LOC_val_solution.csv', 'r')
    i=0
    for l in f:
        if i ==0: # ignore header
            i += 1
            continue
        filename=l.split(',')[0]
        label=l.split(',')[1].split(' ')[0]
        dir = root+label
        ### 1. make dir
        # if not os.path.exists(dir):
        #     os.makedirs(dir)
        # print(os.path.join(root,filename,'.JPEG'))
        ### 2. move files to dir
        print(label)
        if os.path.isfile(os.path.join(root, filename + '.JPEG')):
            os.rename(os.path.join(root, filename + '.JPEG'), os.path.join(dir, filename + '.JPEG'))
        i += 1
    print(i)
    '''

File Path: data_loader/OutDistDataset.py
Content:
import random
import torch.utils.data
import torchvision.datasets as datasets
import torchvision.transforms as transforms
import torch.nn as nn

import time
import numpy as np
from torch.utils.data.dataset import random_split
from torchvision.datasets import ImageFolder

import conf
import torchattacks

from data_loader.CIFAR100Dataset import CIFAR100Dataset
from data_loader.CIFAR10Dataset import CIFAR10Dataset
from data_loader.IMAGENETDataset import ImageNetDataset
from utils.normalize_layer import *


opt10 = conf.CIFAR10Opt
opt100 = conf.CIFAR100Opt
imagenet = conf.IMAGENET_C
mnist = conf.MNISTOpt

device = torch.device("cuda:{:d}".format(conf.args.gpu_idx) if torch.cuda.is_available() else "cpu")
torch.cuda.set_device(conf.args.gpu_idx)  #

OUTDIST_CLASS_IDX = 10000


class OutDistDataset(torch.utils.data.Dataset):  # OOD dataset with base CIFAR10
    outdist_types = ["original", "divide", "repeat", "oneclassrepeat", "cifar100", "cifar100c",
                     "gaussian", "uniform", "mnist", "cifar10", "imagenet"]

    def __init__(self, base="cifar10outdist",
                 domains=None, activities=None,
                 max_source=100, transform='none',
                 outdist=None, outdist_size=None, outdist_class=None):
        st = time.time()
        self.domains = domains
        self.activity = activities
        self.max_source = max_source
        self.outdist = outdist
        self.outdist_size = outdist_size
        self.outdist_class = outdist_class

        self.domain = domains[0]

        self.img_shape = opt10['img_size']
        self.features = None
        self.class_labels = None
        self.domain_labels = None

        self.file_path10 = opt10['file_path']
        self.file_path100 = opt100['file_path']
        self.file_path_imagenet = imagenet['file_path']
        self.file_path_mnist = mnist['file_path']

        assert (base in ["cifar10outdist", "imagenetoutdist", "cifar100outdist"])
        assert (self.outdist in self.outdist_types)
        assert not (self.outdist in ['oneclassrepeat', 'gaussian', 'uniform'] and self.outdist_size is None)
        assert not (self.outdist in ['divide', 'oneclassrepeat'] and self.outdist_class is None)

        if transform == 'src':
            self.is_src = True
        else:
            self.is_src = False

        if base == 'cifar10outdist':
            if self.domain == 'none':
                self.base_dataset = CIFAR10Dataset(domains=['original'], transform=transform)
            else:
                self.base_dataset = CIFAR10Dataset(domains=self.domains, transform=transform)
            self.img_size = 32
            if transform == 'src':
                self.transform = transforms.Compose(
                    [
                        transforms.RandomCrop(32, padding=4),
                        transforms.RandomHorizontalFlip(),
                    ])

            elif transform == 'val':
                self.transform = None
            else:
                raise NotImplementedError
        elif base == 'cifar100outdist':
            if self.domain == 'none':
                self.base_dataset = CIFAR100Dataset(domains=['original'], transform=transform)
            else:
                self.base_dataset = CIFAR100Dataset(domains=self.domains, transform=transform)
            self.img_size = 32
            if transform == 'src':
                self.transform = transforms.Compose(
                    [
                        transforms.RandomCrop(32, padding=4),
                        transforms.RandomHorizontalFlip(),
                    ])

            elif transform == 'val':
                self.transform = None
            else:
                raise NotImplementedError
        elif base == 'imagenetoutdist':
            self.base_dataset = ImageNetDataset(domain=self.domain, transform=transform)
            self.img_size = 224

            if transform == 'src':
                self.transform = transforms.Compose([
                    transforms.RandomResizedCrop(224),
                    transforms.RandomHorizontalFlip(),
                    transforms.ToTensor()
                ])
            elif transform == 'val':
                if self.domain.startswith('original') or self.domain.startswith('test'):
                    self.transform = transforms.Compose([
                        transforms.Resize(256),
                        transforms.CenterCrop(224),
                        transforms.ToTensor()
                    ])
                else:
                    self.transform = transforms.Compose([
                        transforms.CenterCrop(224),
                        transforms.ToTensor()
                    ])

                if self.outdist in ["oneclassrepeat", "divide", "repeat"]:
                    self.base_dataset.load_features()  # imagenet does not originally load features
            else:
                raise NotImplementedError

        else:
            raise NotImplementedError

        self.preprocessing()

    def resample(self, data: np.ndarray, size: int):
        if size == len(data):
            return data
        elif size < len(data):
            return data[random.sample(range(len(data)), size)]
        else:
            remainder = data[random.sample(range(len(data)), size % len(data))]
            repeat = np.tile(data, (int(size/len(data)), 1, 1, 1))
            return np.concatenate((repeat, remainder), axis=0)

    def preprocessing(self):
        outdist_sample = None
            
        if self.outdist == "cifar100": # cifar100
            path100 = f'{self.file_path100}/origin/'
            data100 = np.load(path100 + 'original.npy')
            # change NHWC to NCHW format
            data100 = np.transpose(data100, (0, 3, 1, 2))
            # make it compatible with our models (normalize)
            data100 = data100.astype(np.float32) / 255.0

            if self.outdist_size:
                data100 = self.resample(data100, self.outdist_size)

            tr = transforms.Compose([
                transforms.ToPILImage(),
                transforms.Resize((self.img_size, self.img_size)),
                transforms.ToTensor(),
            ])
            data100 = np.array([tr(torch.Tensor(img)).numpy() for img in data100])

            outdist_sample = data100

        elif self.outdist == "cifar100c": # cifar100c
            path100c = f'{self.file_path100}/corrupted/severity-{self.domains[0][-1]}/'
            data_filename = self.domains[0].split('-')[0] + '.npy'
            data100c = np.load(path100c + data_filename)
            # change NHWC to NCHW format
            data100c = np.transpose(data100c, (0, 3, 1, 2))
            # make it compatible with our models (normalize)
            data100c = data100c.astype(np.float32) / 255.0

            tr = transforms.Compose([
                transforms.ToPILImage(),
                transforms.Resize((self.img_size, self.img_size)),
                transforms.ToTensor(),
            ])
            data100c = np.array([tr(torch.Tensor(img)).numpy() for img in data100c])

            outdist_sample = data100c

        elif self.outdist == "cifar10": # cifar10
            path10 = f'{self.file_path10}/origin/'
            data10 = np.load(path10 + 'original.npy')
            # change NHWC to NCHW format
            data10 = np.transpose(data10, (0, 3, 1, 2))
            # make it compatible with our models (normalize)
            data10 = data10.astype(np.float32) / 255.0

            if self.outdist_size:
                data10 = data10[random.sample(range(len(data10)), self.outdist_size)]

            tr = transforms.Compose([
                transforms.ToPILImage(),
                transforms.Resize((self.img_size, self.img_size)),
                transforms.ToTensor(),
            ])
            data10 = np.array([tr(torch.Tensor(img)).numpy() for img in data10])

            outdist_sample = data10

        elif self.outdist == "imagenet":
            path = f'{self.file_path_imagenet}/origin/Data/CLS-LOC/val/'

            tr = transforms.Compose([
                transforms.Resize((self.img_size, self.img_size)),
                transforms.ToTensor(),
            ])

            features = []

            dataset = ImageFolder(path, transform=tr)
            dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=False, pin_memory=False,
                                                     drop_last=False)
            # transformed_dataset = []
            for b_i, data in enumerate(
                    dataloader):  # must be loaded from dataloader, due to transform in the __getitem__()
                feat, _ = data
                # convert a batch of tensors to list, and then append to our list one by one
                feats = torch.unbind(feat, dim=0)
                for i in range(len(feats)):
                    # transformed_dataset.append((feats[i], cls[i]))
                    features.append(feats[i])

            outdist_sample = np.stack(features)
            if self.outdist_size:
                outdist_sample = outdist_sample[random.sample(range(len(outdist_sample)), self.outdist_size)]

        elif self.outdist == "gaussian": # gauss50k, gauss150k
            gaussian_img = np.random.normal(0, 1, size=(self.outdist_size, 3, self.img_size, self.img_size))
            norm_gaussian_img = np.float32((gaussian_img - np.min(gaussian_img))/np.ptp(gaussian_img))
            outdist_sample = norm_gaussian_img

        elif self.outdist == "repeat":
            outdist_sample = self.base_dataset.features

        elif self.outdist == "uniform": # uniform50
            outdist_sample = np.float32(np.random.random(size=(self.outdist_size, 3, self.img_size, self.img_size)))

        elif self.outdist == "mnist":  # mnist test set
            path_mnist = f'{self.file_path_mnist}/identity/'
            data_mnist = np.load(path_mnist + 'test_images.npy')

            # change NHWC to NCHW format
            data_mnist = np.transpose(data_mnist, (0, 3, 1, 2))
            # make it compatible with our models (normalize)
            data_mnist = data_mnist.astype(np.float32) / 255.0

            if self.outdist_size:
                data_mnist = self.resample(data_mnist, self.outdist_size)

            mnist_transform = transforms.Compose([
                transforms.ToPILImage(),
                transforms.Grayscale(3),
                transforms.Resize((self.img_size, self.img_size)),
                transforms.ToTensor(),
            ])
            data_mnist = np.array([mnist_transform(torch.Tensor(img)).numpy() for img in data_mnist])

            outdist_sample = data_mnist

        elif self.outdist == "original":
            outdist_sample = np.array([])
        else:
            raise NotImplementedError

        if self.outdist == "original" or self.is_src is True:
            self.dataset = self.base_dataset.dataset
        else:
            outdist_dataset = torch.utils.data.TensorDataset(
                torch.from_numpy(outdist_sample),  # resize for resnet
                torch.from_numpy(OUTDIST_CLASS_IDX * np.ones((len(outdist_sample)))),
                torch.from_numpy(np.array(np.zeros((len(outdist_sample))))))

            if self.domain == "none":
                self.dataset = outdist_dataset
            else:
                self.dataset = torch.utils.data.ConcatDataset([outdist_dataset, self.base_dataset.dataset])

    def __len__(self):
        return len(self.dataset)

    def get_num_domains(self):
        return len(self.domains)

    def get_datasets_per_domain(self):
        return self.datasets

    def __getitem__(self, idx):
        if isinstance(idx, torch.Tensor):
            idx = idx.item()

        data = self.dataset[idx]
        if len(data) == 3:
            img, cl, dl = data
        elif len(data) == 2:
            img, cl, dl = data[0], torch.tensor(data[1]), torch.tensor(0)  # avoid errors on torch.stack()
        else:
            raise NotImplementedError

        if int(cl) != int(OUTDIST_CLASS_IDX):  # in-dist data
            if self.transform:
                img = self.transform(img)

        return img, cl, dl

   

if __name__ == '__main__':
    pass

File Path: data_loader/data_loader.py
Content:
from torch.utils.data import DataLoader
import torch
import numpy as np
import time
import math

from .IMAGENETDataset import ImageNetDataset
from .CIFAR10Dataset import CIFAR10Dataset
from .CIFAR100Dataset import CIFAR100Dataset
from .OutDistDataset import OutDistDataset
from .IMAGENETRDataset import ImageNetRDataset

import os
import pickle
import re
import random
import copy

import conf


def keep_order_split(entire_data, train_size, valid_size, test_size):
    # Split the dataset while keeping the original order of it.
    all_indices = [i for i in range(len(entire_data))]

    valid_indices = random.sample(all_indices, valid_size)

    for i in sorted(valid_indices, reverse=True):  # reverse is required
        all_indices.pop(i)

    test_indices = random.sample(all_indices, test_size)

    for i in sorted(test_indices, reverse=True):
        all_indices.pop(i)

    valid_data = torch.utils.data.Subset(entire_data, valid_indices)
    test_data = torch.utils.data.Subset(entire_data, test_indices)
    train_data = torch.utils.data.Subset(entire_data, all_indices)

    return train_data, valid_data, test_data


def split_data(entire_data, valid_split, test_split, train_max_rows, valid_max_rows, test_max_rows):
    valid_size = math.floor(len(entire_data) * valid_split)
    test_size = math.floor(len(entire_data) * test_split)

    train_size = len(entire_data) - valid_size - test_size

    assert (train_size >= 0 and valid_size >= 0 and test_size >= 0)

    train_data, valid_data, test_data = keep_order_split(entire_data, train_size, valid_size, test_size)

    if len(entire_data) > train_max_rows:
        train_data = torch.utils.data.Subset(train_data, range(train_max_rows))
    if len(valid_data) > valid_max_rows:
        valid_data = torch.utils.data.Subset(valid_data, range(valid_max_rows))
    if len(test_data) > test_max_rows:
        test_data = torch.utils.data.Subset(test_data, range(test_max_rows))

    return train_data, valid_data, test_data


def datasets_to_dataloader(datasets, batch_size, concat=True, shuffle=True, drop_last=False):
    if concat:
        data_loader = None
        if len(datasets):
            if type(datasets) is torch.utils.data.dataset.Subset:
                datasets = [datasets]
            if sum([len(dataset) for dataset in datasets]) > 0:  # at least one dataset has data
                data_loader = DataLoader(torch.utils.data.ConcatDataset(datasets), batch_size=batch_size,
                                         shuffle=shuffle, drop_last=drop_last, pin_memory=False)
        return data_loader
    else:
        data_loaders = []
        for dataset in datasets:
            if len(dataset) == 0:
                continue
            else:
                data_loaders.append(DataLoader(dataset, batch_size=batch_size, shuffle=shuffle,
                                               drop_last=drop_last, pin_memory=False))

        return data_loaders


def load_cache(dataset, cond, data_file_path, transform=None):
    try:
        root = './cached_data/'
        dir = root + str(dataset) + '/'
        filename = re.sub("[^a-zA-Z0-9 \n]", '_', str(cond) + '_' + str(data_file_path))
        if transform:
            filename += '_' + transform + '.pkl'
        else:
            filename += '.pkl'
        cache_path = dir + filename

        if os.path.isfile(cache_path):
            print(f'Cache hit:{cache_path}')
            return torch.load(cache_path)
        else:
            print(f'Cache miss:{cache_path}')
            return None
    except:  # RuntimeError, EOFError
        return None


def save_cache(loaded_data, dataset, cond, data_file_path, transform=None):
    root = './cached_data/'
    dir = root + str(dataset) + '/'
    filename = re.sub("[^a-zA-Z0-9 \n]", '_', str(cond) + '_' + str(data_file_path))
    if transform:
        filename += '_' + transform + '.pkl'
    else:
        filename += '.pkl'
    cache_path = dir + filename
    try:
        if not os.path.exists(dir):
            os.makedirs(dir)
    except:
        pass
    return torch.save(loaded_data, cache_path, pickle_protocol=4)


def domain_data_loader(dataset, domains, file_path, batch_size, train_max_rows=np.inf, valid_max_rows=np.inf,
                       test_max_rows=np.inf, valid_split=0, test_split=0, is_src=True,
                       num_source=9999):
    entire_datasets = []
    train_datasets = []

    valid_datasets = []
    test_datasets = []
    st = time.time()

    if domains is not None:
        if domains == 'src':
            processed_domains = conf.args.opt['src_domains']
        elif isinstance(domains, (list,)):
            processed_domains = domains
        else:
            processed_domains = [domains]
    elif is_src:

        if conf.args.validation:
            processed_domains = sorted(
                list(set(conf.args.opt['src_domains']) - set([conf.args.tgt])))  # Leave-one-user-out
        else:
            processed_domains = conf.args.opt['src_domains']
    else:
        if conf.args.validation:
            processed_domains = conf.args.opt['src_domains']
        else:
            processed_domains = conf.args.opt['tgt_domains']

    ##-- load dataset per each domain
    print('Domains:{}'.format(processed_domains))

    if dataset in ['imagenetoutdist', 'cifar10outdist', 'cifar100outdist']:

        cond = processed_domains
        filename = f"{dataset}_{conf.args.outdist}_{conf.args.outdist_size}_{conf.args.outdist_class}_{conf.args.seed}"
        transform = 'src' if is_src else 'val'
        # loaded_data = load_cache(filename, processed_domains,
        #                          file_path, transform=transform)
        #
        # if not loaded_data:
        loaded_data = OutDistDataset(base=dataset, domains=cond, max_source=num_source, transform=transform,
                                    outdist=conf.args.outdist, outdist_size=conf.args.outdist_size, outdist_class=conf.args.outdist_class)
            # save_cache(loaded_data, filename,
            #            processed_domains, file_path, transform=transform)
        train_data = loaded_data
        entire_datasets.append(train_data)

    elif dataset in ['cifar10']:

        cond = processed_domains

        transform = 'src' if is_src else 'val'
        loaded_data = load_cache(dataset, processed_domains, file_path, transform=transform)

        if not loaded_data:
            loaded_data = CIFAR10Dataset(file=file_path, domains=cond, max_source=num_source, transform=transform)
            save_cache(loaded_data, dataset, processed_domains, file_path, transform=transform)

        train_data = loaded_data
        entire_datasets.append(train_data)

    elif dataset in ['cifar100']:

        cond = processed_domains

        transform = 'src' if is_src else 'val'
        loaded_data = load_cache(dataset, processed_domains, file_path, transform=transform)

        if not loaded_data:
            loaded_data = CIFAR100Dataset(file=file_path, domains=cond, max_source=num_source, transform=transform)
            save_cache(loaded_data, dataset, processed_domains, file_path, transform=transform)

        train_data = loaded_data
        entire_datasets.append(train_data)

    elif dataset in ['imagenet']:

        cond = processed_domains
        transform = 'src' if is_src else 'val'

        file_path = os.path.join(file_path, 'imagenet', cond[0], str(5))
        loaded_data = load_cache(dataset, processed_domains, file_path, transform=transform)

        if not loaded_data:
            loaded_data = ImageNetDataset(file=file_path, domain=cond[0], max_source=num_source, transform=transform)
            save_cache(loaded_data, dataset, processed_domains, file_path, transform=transform)

        train_data = loaded_data
        entire_datasets.append(train_data)
    
    elif dataset in ['imagenetR']:

        cond = processed_domains
        transform = 'src' if is_src else 'val'

        loaded_data = load_cache(dataset, processed_domains, file_path, transform=transform)

        if not loaded_data:
            loaded_data = ImageNetRDataset(file=file_path, domain=cond[0], max_source=num_source, transform=transform)
            save_cache(loaded_data, dataset, processed_domains, file_path, transform=transform)

        train_data = loaded_data
        entire_datasets.append(train_data)

    else:
        raise NotImplementedError


    ##-- split each dataset into train, valid, and test
    for train_data in entire_datasets:
        total_len = len(train_data)

        train_data, valid_data, test_data = split_data(train_data, valid_split, test_split, train_max_rows,
                                                       valid_max_rows, test_max_rows)

        train_datasets.append(train_data)
        valid_datasets.append(valid_data)
        test_datasets.append(test_data)

        print('#Multi?:{:d} data_loader len:{:d} Train: {:d}\t# Valid: {:d}\t# Test: {:d}'.format(
            True if domains == ['rest'] else False, total_len, len(train_data), len(valid_data),
            len(test_data)))

    train_datasets = train_datasets[:num_source]
    valid_datasets = valid_datasets[:num_source]
    test_datasets = test_datasets[:num_source]

    print('# Time: {:f} secs'.format(time.time() - st))
    
    if is_src:
        # current support only one dataset
        selected_index = random.sample(list(range(len(train_datasets[0]))), conf.args.num_eval_source)
        eval_src_data_ls = [[],[],[]]
        for index in selected_index:
            eval_src_data_ls[0] += [train_datasets[0][index][0]]
            eval_src_data_ls[1] += [train_datasets[0][index][1]]
            eval_src_data_ls[2] += [train_datasets[0][index][2]]
        
        eval_src_data_ls[0] = torch.stack(eval_src_data_ls[0])
        eval_src_data_ls[1] = torch.stack(eval_src_data_ls[1]) if isinstance(eval_src_data_ls[1][0], torch.Tensor) else torch.tensor(eval_src_data_ls[1])
        eval_src_data_ls[2] = torch.stack(eval_src_data_ls[2]) if isinstance(eval_src_data_ls[2][0], torch.Tensor) else torch.tensor(eval_src_data_ls[2])
    else:
        eval_src_data_ls = None

    if is_src:
        train_data_loader = datasets_to_dataloader(train_datasets, batch_size=batch_size, concat=True,
                                                   drop_last=True,
                                                   shuffle=True)  # Drop_last for avoiding one-sized minibatches for batchnorm layers
    else:
        train_data_loader = datasets_to_dataloader(train_datasets, batch_size=1, concat=True,
                                                   drop_last=False,
                                                   shuffle=False)
    valid_data_loader = datasets_to_dataloader(valid_datasets, batch_size=batch_size, concat=True,
                                               shuffle=False)
    test_data_loader = datasets_to_dataloader(test_datasets, batch_size=batch_size, concat=True, shuffle=False)

    data_loader = {
        'train': train_data_loader,
        'valid': valid_data_loader,
        'test': test_data_loader,
        'num_domains': sum([dataset.dataset.get_num_domains() for dataset in train_datasets]),
    }
    print('num_domains:' + str(data_loader['num_domains']))
    return data_loader, eval_src_data_ls


if __name__ == '__main__':
    pass

File Path: learner/cotta.py
Content:
import copy
from copy import deepcopy
import conf
from .dnn import DNN
from torch.utils.data import DataLoader
from utils import memory, loss_functions, reset_utils

from utils.loss_functions import *
import PIL
from utils import cotta_utils
import torchvision.transforms as transforms

device = torch.device("cuda:{:d}".format(conf.args.gpu_idx) if torch.cuda.is_available() else "cpu")

@torch.jit.script
def softmax_entropy(x, x_ema):# -> torch.Tensor:
    """Entropy of softmax distribution from logits."""
    return -(x_ema.softmax(1) * x.log_softmax(1)).sum(1)

def update_ema_variables(ema_model, model, alpha_teacher):
    for ema_param, param in zip(ema_model.parameters(), model.parameters()):
        ema_param.data[:] = alpha_teacher * ema_param[:].data[:] + (1 - alpha_teacher) * param[:].data[:]
    return ema_model

def get_tta_transforms(gaussian_std: float=0.005, soft=False, clip_inputs=False):
    if conf.args.dataset in ['cifar10', 'cifar100', 'cifar10outdist', 'cifar100outdist']:
        img_shape = (32, 32, 3)
    else:
        img_shape = (224, 224, 3)
    n_pixels = img_shape[0]

    clip_min, clip_max = 0.0, 1.0

    p_hflip = 0.5

    tta_transforms = transforms.Compose([
        cotta_utils.Clip(0.0, 1.0),
        cotta_utils.ColorJitterPro(
            brightness=[0.8, 1.2] if soft else [0.6, 1.4],
            contrast=[0.85, 1.15] if soft else [0.7, 1.3],
            saturation=[0.75, 1.25] if soft else [0.5, 1.5],
            hue=[-0.03, 0.03] if soft else [-0.06, 0.06],
            gamma=[0.85, 1.15] if soft else [0.7, 1.3]
        ),
        transforms.Pad(padding=int(n_pixels / 2), padding_mode='edge'),
        transforms.RandomAffine(
            degrees=[-8, 8] if soft else [-15, 15],
            translate=(1/16, 1/16),
            scale=(0.95, 1.05) if soft else (0.9, 1.1),
            shear=None,
            resample=PIL.Image.BILINEAR,
            fillcolor=None
        ),
        transforms.GaussianBlur(kernel_size=5, sigma=[0.001, 0.25] if soft else [0.001, 0.5]),
        transforms.CenterCrop(size=n_pixels),
        transforms.RandomHorizontalFlip(p=p_hflip),
        cotta_utils.GaussianNoise(0, gaussian_std),
        cotta_utils.Clip(clip_min, clip_max)
    ])
    return tta_transforms


class CoTTA(DNN):
    def __init__(self, *args, **kwargs):
        super(CoTTA, self).__init__(*args, **kwargs)
        
        self.net.train()

        for param in self.net.parameters():  #turn on requires_grad for all
            param.requires_grad = True

        for module in self.net.modules():

            if isinstance(module, nn.BatchNorm1d) or isinstance(module, nn.BatchNorm2d):
                #use of batch stats in train and eval modes: https://github.com/qinenergy/cotta/blob/main/cifar/cotta.py
                if conf.args.use_learned_stats:
                    module.track_running_stats = True
                    module.momentum = conf.args.bn_momentum
                else:
                    module.track_running_stats = False
                    module.running_mean = None
                    module.running_var = None

                module.weight.requires_grad_(True)
                module.bias.requires_grad_(True)

        self.mt = conf.args.ema_factor #0.999 for every dataset
        self.rst = conf.args.restoration_factor #0.01 for all dataset
        self.ap = conf.args.aug_threshold #0.92 for CIFAR10, 0.72 for CIFAR100
        self.episodic = False

        self.src_net_state = copy.deepcopy(self.net.state_dict())
        self.src_net = copy.deepcopy(self.net)
        self.net_not_ema = self.net
        self.net = copy.deepcopy(self.net_not_ema)  # student model
        for param in self.net.parameters():
            param.detach_()
            
        self.transform = get_tta_transforms()

        self.fifo = memory.FIFO(capacity=conf.args.update_every_x)  # required for evaluation
        self.mem_state = self.mem.save_state_dict()
        self.init_reset(self.net, self.optimizer)
                

    def hard_reset(self):
        if self.src_net_state is None or self.optimizer_state is None:
            raise Exception("cannot reset without saved model/optimizer")
        reset_utils.load_model_and_optimizer(self.net_not_ema, self.optimizer, self.src_net_state, self.optimizer_state)

        self.src_net_state = copy.deepcopy(self.net_not_ema.state_dict())
        self.src_net = copy.deepcopy(self.net_not_ema)
        
        net_ema = deepcopy(self.net_not_ema)
        for param in net_ema.parameters():
            param.detach_()

        self.net = net_ema  # set self.net to self.net_ema
        self.net.to(device)
        self.num_reset += 1
        
    def soft_reset(self, net_state, optim_state):
        if self.net_state is None or self.optimizer_state is None:
            raise Exception("cannot reset without saved model/optimizer")
        reset_utils.load_model_and_optimizer(self.net_not_ema, self.optimizer, net_state, optim_state)
        
        net_ema = deepcopy(self.net_not_ema)
        for param in net_ema.parameters():
            param.detach_()

        self.net = net_ema  # set self.net to self.net_ema
        self.net.to(device)
        self.num_reset += 1
        
    def model_inference(self, feats, net=None):
        if net is None:
            net = self.net
        
        # self.net.train()
        # self.src_net.train()

        x = feats
        anchor_prob = torch.nn.functional.softmax(self.src_net(x), dim=1).max(1)[0]
        standard_ema = net(x) if conf.args.opt['indices_in_1k'] == None else net(x)[:, conf.args.opt['indices_in_1k']]

        N = 32
        outputs_emas = []

        # Threshold choice discussed in supplementary
        # enable data augmentation for vision datasets
        if anchor_prob.mean(0) < self.ap:
            for i in range(N):
                outputs_ = net(self.transform(x)).detach() if conf.args.opt['indices_in_1k'] == None else net(self.transform(x)).detach()[:, conf.args.opt['indices_in_1k']]
                outputs_emas.append(outputs_)
            outputs_ema = torch.stack(outputs_emas).mean(0)
        else:
            outputs_ema = standard_ema

        y_logit = outputs_ema
        y_entropy = loss_functions.softmax_entropy(y_logit)
        y_pred_softmax = F.softmax(y_logit, dim=1)
        y_conf = y_pred_softmax.max(1, keepdim=False)[0]
        y_energy = calc_energy(y_logit).cpu()
        y_pred = y_logit.max(1, keepdim=False)[1]
        
        return y_pred, y_conf, y_entropy, y_energy, None, y_pred_softmax, y_logit

    def test_time_adaptation(self, feats):
        if len(feats) == 1:
            self.net.eval()  # avoid BN error
            self.net_not_ema.eval()
            self.src_net.eval()
        else:
            self.net.train()
            self.net_not_ema.train()
            self.src_net.train()

        feats = feats.to(device)
        outputs = self.net_not_ema(feats) if conf.args.opt['indices_in_1k'] == None else self.net_not_ema(feats)[:, conf.args.opt['indices_in_1k']]

        with torch.no_grad():
            anchor_prob = torch.nn.functional.softmax(self.src_net(feats), dim=1).max(1)[0]
            standard_ema = self.net(feats) if conf.args.opt['indices_in_1k'] == None else self.net(feats)[:, conf.args.opt['indices_in_1k']]

        N = 32
        outputs_emas = []

        # Threshold choice discussed in supplementary
        # enable data augmentation for vision datasets
        if anchor_prob.mean(0) < self.ap:
            for i in range(N):
                with torch.no_grad():
                    outputs_ = self.net(self.transform(feats)).detach() if conf.args.opt['indices_in_1k'] == None else self.net(self.transform(feats)).detach()[:, conf.args.opt['indices_in_1k']]
                outputs_emas.append(outputs_)
            outputs_ema = torch.stack(outputs_emas).mean(0)
        else:
            outputs_ema = standard_ema

        # Student update
        self.optimizer.zero_grad()
        loss = (softmax_entropy(outputs, outputs_ema)).mean(0)
        loss.backward()
        self.optimizer.step()

        # Teacher update
        self.net = update_ema_variables(ema_model=self.net, model=self.net_not_ema, alpha_teacher=self.mt)

        # Stochastic restore
        if conf.args.turn_off_reset is False and conf.args.reset_function != 'CoTTA':
            for nm, m in self.net_not_ema.named_modules():
                for npp, p in m.named_parameters():
                    if npp in ['weight', 'bias'] and p.requires_grad:
                        rand = torch.rand(p.shape)
                        mask = (rand < self.rst).float().cuda()
                        with torch.no_grad():
                            p.data = self.src_net_state[f"{nm}.{npp}"] * mask + p * (1. - mask)
        
        return self.net_not_ema, loss.item()  # CoTTA backprops on the student model. No gradient in teacher.

File Path: learner/dnn.py
Content:
from collections import deque
from typing import Union, Tuple, Optional

import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torch.utils.data
from torchvision.transforms.functional import to_pil_image, rotate
from sklearn.metrics import confusion_matrix
from sklearn.metrics import f1_score
from torch.utils.data import DataLoader
from torchvision.transforms.functional import to_pil_image
from tqdm import tqdm
from copy import deepcopy

import conf
from data_loader.OutDistDataset import OUTDIST_CLASS_IDX
from data_loader.data_loader import load_cache, save_cache
from models.ResNet import ResNetDropout50, ResNetDropout18
from utils.augmentation import _augmix_aug
from utils.cotta_utils import get_tta_transforms
from utils import memory
from utils.logging import *
from utils.loss_functions import softmax_entropy, calc_energy, JSD
from utils.memory import FIFO, ConfFIFO, HUS, Uniform, PBRS
from utils.memory_rotta import CSTU
from utils.normalize_layer import *
from utils.sam_optimizer import SAM
from utils import memory_rotta
import utils.reset_utils as reset_utils


device = torch.device("cuda:{:d}".format(conf.args.gpu_idx) if torch.cuda.is_available() else "cpu")
torch.cuda.set_device(
    conf.args.gpu_idx)  # this prevents unnecessary gpu memory allocation to cuda:0 when using estimator

TRAINED = 0
SKIPPED = 1
FINISHED = 2


class DNN():
    def __init__(self, model_, corruption_list_=None):
        self.device = device
        
        if conf.args.dataset in ['cifar10', 'cifar100'] and conf.args.tgt_train_dist == 0:
            self.tgt_train_dist = 4  # Dirichlet is default for non-real-distribution data
        else:
            self.tgt_train_dist = conf.args.tgt_train_dist
            
        ################## Init & prepare model###################
        self.conf_list = []
   
        # Load model
        
        if "pretrained" in conf.args.model:
            pretrained = model_(pretrained=True)
            if conf.args.model == "resnet18_pretrained":
                model = ResNetDropout18()
                model.load_state_dict(pretrained.state_dict())
            elif conf.args.model == "resnet50_pretrained":
                model = ResNetDropout50()
                model.load_state_dict(pretrained.state_dict())
            else:
                raise NotImplementedError
            del pretrained
        else:
            model = model_()

        if 'resnet' in conf.args.model:
            if conf.args.dataset not in ['imagenet', 'imagenetoutdist', 'imagenetR']: # imagenetR keeps predicted classes to 1000
                num_feats = model.fc.in_features
                if conf.args.outdist == "divide":
                    num_class = conf.args.opt['num_class'] - len(conf.args.outdist_class)
                else:
                    num_class = conf.args.opt['num_class']
                model.fc = nn.Linear(num_feats, num_class)  # match class number
            self.net = model
        else:
            self.net = model.Net()

        if conf.args.load_checkpoint_path:  # false if conf.args.load_checkpoint_path==''
            self.load_checkpoint(conf.args.load_checkpoint_path)

        norm_layer = get_normalize_layer(conf.args.dataset)

        if norm_layer:
            self.net = torch.nn.Sequential(norm_layer, self.net)
            
        if conf.args.parallel and torch.cuda.device_count() > 1:
            self.net = nn.DataParallel(self.net)

        self.net.to(device)

        ##########################################################

        # Important: some TTA methods would overwrite this optimizer
        if conf.args.dataset in ['cifar10', 'cifar100', 'cifar10outdist', 'cifar100outdist', 'tinyimagenet', 'imagenet', 'imagenetoutdist', 'imagenetR']:
            self.optimizer = torch.optim.SGD(
                self.net.parameters(),
                conf.args.opt['learning_rate'],
                momentum=conf.args.opt['momentum'],
                weight_decay=conf.args.opt['weight_decay'],
                nesterov=True)
        else:
            self.optimizer = optim.Adam(self.net.parameters(), lr=conf.args.opt['learning_rate'],
                                        weight_decay=conf.args.opt['weight_decay'])

        self.class_criterion = nn.CrossEntropyLoss()
        
        # online learning
        if conf.args.memory_type == 'FIFO':
            self.mem = memory.FIFO(capacity=conf.args.memory_size)
        elif conf.args.memory_type == 'HUS':
            self.mem = memory.HUS(capacity=conf.args.memory_size, threshold=conf.args.high_threshold, num_class=conf.args.opt['num_class'])
        elif conf.args.memory_type == 'CSTU':
            self.mem = memory_rotta.CSTU(capacity=conf.args.memory_size, num_class=conf.args.opt['num_class'],
                                         lambda_t=1, lambda_u=1)  # replace memory with original RoTTA
        elif conf.args.memory_type == 'ConfFIFO':
            self.mem = memory.ConfFIFO(capacity=conf.args.memory_size, threshold=conf.args.high_threshold)

        self.occurred_class = [0 for i in range(conf.args.opt['num_class'])]

        self.fifo = memory.FIFO(conf.args.update_every_x)
        self.previous_train_loss = 0
        self.mem_state = self.mem.save_state_dict()

        self.est_ema_dropout = None

        self.sa_src_net = deepcopy(self.net)
        self.sa_ref_net_1 = None

    def init_json(self, log_path):
        self.write_path = log_path
        self.eval_json = {
            k: [] for k in ['gt', 'accuracy', 'current_accuracy', 'f1_macro', 'distance_l2',
                            'pred', 'pred_outdist', 'pred_total',
                            'confidence', 'confidence_outdist', 'confidence_total',
                            'entropy', 'entropy_outdist', 'entropy_total',
                            'ood_pred', 'ood_gt',
                            'gt_outdist', 'energy', 'energy_outdist',
                            'grad', 'grad_outdist', 'grad_total',
                            'embedding_dist', 'cp_embedding_dist',
                            'src_gt', 'src_pred', 'src_accuracy', 'src_f1_macro', 'src_distance_l2',
                            'src_confidence', 'src_entropy', 'src_energy', 'src_grad', 'src_embedding_dist',
                            'num_reset']
        }
        self.acc_est_json = {
            k: [] for k in ['adv_perturb', 'src_validation', 'gde', 'softmax_score',
                            'est_dropout', 'est_dropout_softmax_mean', 'est_dropout_softmax_std',
                            'aetta', 'est_dropout_avg_entropy']
        }
 
    def set_target_data(self, source_data_loader, source_val_data_loader, target_data_loader, corruption):
        self.source_dataloader = source_data_loader
        self.source_val_dataloader = source_val_data_loader
        self.target_dataloader = target_data_loader

        dataset = conf.args.dataset
        cond = corruption

        filename = f"{dataset}_{conf.args.outdist}_{conf.args.outdist_size}_{conf.args.outdist_class}_{conf.args.seed}_dist{conf.args.tgt_train_dist}"

        if conf.args.tgt_train_dist == 4:
            filename += f"_gamma{conf.args.dirichlet_beta}"
            
        file_path = conf.args.opt['file_path'] + "_target_train_set"

        self.target_train_set = load_cache(filename, cond, file_path, transform=None)

        if not self.target_train_set:
            self.target_data_processing()
            save_cache(self.target_train_set, filename, cond, file_path, transform=None)

        if conf.args.method == 'Src':
            if conf.args.dataset in ['cifar10', 'cifar100', 'cifar10outdist', 'cifar100outdist']:
                self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer,
                                                                            T_max=conf.args.epoch *
                                                                                  len(self.source_dataloader['train']))
        
    def target_data_processing(self):

        features = []
        cl_labels = []
        do_labels = []

        for b_i, (feat, cl, dl) in enumerate(self.target_dataloader['train']):
            #must be loaded from dataloader, due to transform in the __getitem__()
            
            features.append(feat.squeeze(0))
            cl_labels.append(cl.squeeze())
            do_labels.append(dl.squeeze())

        tmp = list(zip(features, cl_labels, do_labels))

        features, cl_labels, do_labels = zip(*tmp)
        features, cl_labels, do_labels = list(features), list(cl_labels), list(do_labels)

        result_feats = []
        result_cl_labels = []
        result_do_labels = []

        tgt_train_dist_ = self.tgt_train_dist
        # real distribution
        if tgt_train_dist_ == 0:
            num_samples = conf.args.nsample if conf.args.nsample < len(features) else len(features)
            for _ in range(num_samples):
                tgt_idx = 0
                result_feats.append(features.pop(tgt_idx))
                result_cl_labels.append(cl_labels.pop(tgt_idx))
                result_do_labels.append(do_labels.pop(tgt_idx))

        # random distribution
        elif tgt_train_dist_ == 1:
            num_samples = conf.args.nsample if conf.args.nsample < len(features) else len(features)
            for _ in range(num_samples):
                tgt_idx = np.random.randint(len(features))
                result_feats.append(features.pop(tgt_idx))
                result_cl_labels.append(cl_labels.pop(tgt_idx))
                result_do_labels.append(do_labels.pop(tgt_idx))

        else:
            raise NotImplementedError

        remainder = len(result_feats) % conf.args.update_every_x  # drop leftover samples
        if remainder == 0:
            pass
        else:
            result_feats = result_feats[:-remainder]
            result_cl_labels = result_cl_labels[:-remainder]
            result_do_labels = result_do_labels[:-remainder]

        try:
            self.target_train_set = (torch.stack(result_feats),
                                     torch.stack(result_cl_labels),
                                     torch.stack(result_do_labels))
        except:
            try:
                self.target_train_set = (torch.stack(result_feats),
                                        result_cl_labels,
                                        torch.stack(result_do_labels))
            except: # for dataset which each image has different shape
                self.target_train_set = (result_feats,
                                        result_cl_labels,
                                        torch.stack(result_do_labels))

    def save_checkpoint(self, epoch, epoch_acc, best_acc, checkpoint_path):
        if isinstance(self.net, nn.Sequential):
            if isinstance(self.net[0],NormalizeLayer):
                cp = self.net[1]
        else:
            cp = self.net

        if isinstance(self.net, nn.DataParallel):
            cp = self.net.module

        torch.save(cp.state_dict(), checkpoint_path)

    def load_checkpoint(self, checkpoint_path):
        self.checkpoint = torch.load(checkpoint_path, map_location=f'cuda:{conf.args.gpu_idx}')
        self.net.load_state_dict(self.checkpoint, strict=True)
        self.net.to(device)

    def get_loss_and_confusion_matrix(self, classifier, criterion, data, label):
        preds_of_data = classifier(data)

        labels = [i for i in range(len(conf.args.opt['classes']))]

        loss_of_data = criterion(preds_of_data, label)
        pred_label = preds_of_data.max(1, keepdim=False)[1]
        cm = confusion_matrix(label.cpu(), pred_label.cpu(), labels=labels)
        return loss_of_data, cm, preds_of_data

    def get_loss_cm_error(self, classifier, criterion, data, label):
        preds_of_data = classifier(data)
        labels = [i for i in range(len(conf.args.opt['classes']))]

        loss_of_data = criterion(preds_of_data, label)
        pred_label = preds_of_data.max(1, keepdim=False)[1]
        assert (len(label) == len(pred_label))
        cm = confusion_matrix(label.cpu(), pred_label.cpu(), labels=labels)
        errors = [0 if label[i] == pred_label[i] else 1 for i in range(len(label))]
        return loss_of_data, cm, errors

    def log_loss_results(self, condition, epoch, loss_avg):

        if condition == 'train_online':
            # print loss
            print('{:s}: [current_sample: {:d}]'.format(
                condition, epoch
            ))
        else:
            # print loss
            print('{:s}: [epoch: {:d}]\tLoss: {:.6f} \t'.format(
                condition, epoch, loss_avg
            ))

        return loss_avg

    def log_accuracy_results(self, condition, suffix, epoch, cm_class):

        assert (condition in ['valid', 'test'])

        class_accuracy = 100.0 * np.sum(np.diagonal(cm_class)) / np.sum(cm_class)

        print('[epoch:{:d}] {:s} {:s} class acc: {:.3f}'.format(epoch, condition, suffix, class_accuracy))

        return class_accuracy

    def train(self, epoch):
        """
        Train the model
        """

        # setup models

        self.net.train()

        class_loss_sum = 0.0

        total_iter = 0

        if conf.args.method in ['Src', 'Src_Tgt']:
            num_iter = len(self.source_dataloader['train'])
            total_iter += num_iter

            for batch_idx, labeled_data in tqdm(enumerate(self.source_dataloader['train']), total=num_iter):
                feats, cls, _ = labeled_data
                feats, cls = feats.to(device), cls.to(device)

                # compute the feature
                preds = self.net(feats)
                class_loss = self.class_criterion(preds, cls)
                class_loss_sum += float(class_loss * feats.size(0))

                self.optimizer.zero_grad()
                class_loss.backward()
                self.optimizer.step()
                if conf.args.dataset in ['cifar10', 'cifar100', 'cifar10outdist', 'cifar100outdist']:
                    self.scheduler.step()

        # Logging
        self.log_loss_results('train', epoch=epoch, loss_avg=class_loss_sum / total_iter)
        avg_loss = class_loss_sum / total_iter
        return avg_loss

    def logger(self, name, value, epoch, condition):

        if not hasattr(self, name + '_log'):
            exec(f'self.{name}_log = []')
            exec(f'self.{name}_file = open(self.write_path + name + ".txt", "w")')

        exec(f'self.{name}_log.append(value)')

        if isinstance(value, torch.Tensor):
            value = value.item()
        write_string = f'{epoch}\t{value}\n'
        exec(f'self.{name}_file.write(write_string)')

    def evaluation(self, epoch, condition):
        # Evaluate with a batch of samples, which is a typical way of evaluation. Used for pre-training or offline eval.

        self.net.eval()

        with torch.no_grad():
            inputs, cls, dls = self.target_train_set
            tgt_inputs = inputs.to(device)
            tgt_cls = cls.to(device)

            preds = self.net(tgt_inputs) if conf.args.opt['indices_in_1k'] == None else self.net(tgt_inputs)[:, conf.args.opt['indices_in_1k']]

            labels = [i for i in range(len(conf.args.opt['classes']))]

            class_loss_of_test_data = self.class_criterion(preds, tgt_cls)
            y_pred = preds.max(1, keepdim=False)[1]
            class_cm_test_data = confusion_matrix(tgt_cls.cpu(), y_pred.cpu(), labels=labels)

        print('{:s}: [epoch : {:d}]\tLoss: {:.6f} \t'.format(
            condition, epoch, class_loss_of_test_data
        ))
        class_accuracy = 100.0 * np.sum(np.diagonal(class_cm_test_data)) / np.sum(class_cm_test_data)
        print('[epoch:{:d}] {:s} {:s} class acc: {:.3f}'.format(epoch, condition, 'test', class_accuracy))

        self.logger('accuracy', class_accuracy, epoch, condition)
        self.logger('loss', class_loss_of_test_data, epoch, condition)

        return class_accuracy, class_loss_of_test_data, class_cm_test_data

    def evaluation_online(self, epoch, current_samples):
        # Evaluate with online samples that come one by one while keeping the order.
        self.net.eval()

        with torch.no_grad():  # we don't log grad here
            # extract each from list of current_sample
            features, cl_labels, do_labels = current_samples
            feats, cls, dls = (torch.stack(features), torch.stack(cl_labels), torch.stack(do_labels))
            self.evaluation_online_body(epoch, current_samples, feats, cls, dls)

    def model_inference(self, feats, net=None, temp=1.0):
        if net is None:
            net = self.net

        net.eval()

        # Normalization layer: self.net[0] / ResNet: self.net[1]
        y_logit = net(feats) if conf.args.opt['indices_in_1k'] == None else net(feats)[:, conf.args.opt['indices_in_1k']]
            
        y_entropy: torch.Tensor = softmax_entropy(y_logit)
        y_pred_softmax: torch.Tensor = F.softmax(y_logit/temp, dim=1)
        y_conf: torch.Tensor = y_pred_softmax.max(1, keepdim=False)[0]
        y_energy: torch.Tensor = calc_energy(y_logit).cpu()
        y_pred: torch.Tensor = y_logit.max(1, keepdim=False)[1]
        
        return y_pred, y_conf, y_entropy, y_energy, None, y_pred_softmax, y_logit
        
    def evaluation_online_body(self, epoch, current_samples, feats, cls, dls):
        # get lists from json
        true_cls_list = self.eval_json['gt']
        pred_cls_list = self.eval_json['pred']
        accuracy_list = self.eval_json['accuracy']
        conf_list = self.eval_json['confidence']
        current_accuracy_list = self.eval_json['current_accuracy']

        num_reset = self.eval_json['num_reset']

        cls = cls.to(torch.int32)  # bugfix when comparing outdist_index
        feats, cls, dls = feats.to(device), cls.to(device), dls.to(device)

        # Inference
        y_pred, y_conf, y_entropy, y_energy, y_embeddings, _, y_logit = self.model_inference(feats)

        if "softmax_score" in conf.args.acc_est_method:
            self.avg_confidence(y_logit)
        
        if "gde" in conf.args.acc_est_method:
            self.agreement(feats, y_pred)
        
        if "src_validation" in conf.args.acc_est_method:
            self.src_validation()

        if "adv_perturb" in conf.args.acc_est_method:
            self.adv(feats)

        if "aetta" in conf.args.acc_est_method:
            self.aetta(feats, y_pred)

        # append values to lists
        current_true_cls_list = [int(c) for c in cls.tolist()]
        true_cls_list += current_true_cls_list
        current_pred_cls_list = [int(c) for c in y_pred.tolist()]
        pred_cls_list += current_pred_cls_list
        conf_list += [float(c) for c in y_conf[cls != OUTDIST_CLASS_IDX].tolist()]

        if len(true_cls_list) > 0:
            current_accuracy = sum(1 for gt, pred in zip(current_true_cls_list, current_pred_cls_list) if gt == pred)\
                               / float(len(current_true_cls_list)) * 100
            current_accuracy_list.append(current_accuracy)
            cumul_accuracy = sum(1 for gt, pred in zip(true_cls_list, pred_cls_list) if gt == pred)\
                             / float(len(true_cls_list)) * 100
            accuracy_list.append(cumul_accuracy)

            self.occurred_class = [0 for i in range(conf.args.opt['num_class'])]

            # epoch: 1~len(self.target_train_set[0])
            progress_checkpoint = [int(i * (len(self.target_train_set[0]) / 100.0)) for i in range(1, 101)]
            for i in range(epoch + 1 - len(current_samples[0]), epoch + 1):  # consider a batch input
                if i in progress_checkpoint:
                    print(
                        f'[Online Eval][NumSample:{i}][Epoch:{progress_checkpoint.index(i) + 1}][Accuracy:{cumul_accuracy}]')
        
        # update self.json file
        self.eval_json = {
            'gt': true_cls_list,
            'pred': pred_cls_list,
            'accuracy': accuracy_list,
            'confidence': conf_list,
            'current_accuracy': current_accuracy_list,
            'num_reset': num_reset,
            
        }
                
    def dump_eval_online_result(self, is_train_offline=False):
        if is_train_offline:
            feats, cls, dls = self.target_train_set
            batchsize = conf.args.opt['batch_size']
            for num_sample in range(0, len(feats), batchsize):
                current_sample = feats[num_sample:num_sample+batchsize], cls[num_sample:num_sample+batchsize], dls[num_sample:num_sample+batchsize]
                self.evaluation_online(num_sample + batchsize,
                                       [list(current_sample[0]), list(current_sample[1]), list(current_sample[2])])

        # logging json files
        json_file = open(self.write_path + 'online_eval.json', 'w')
        json = self.eval_json | self.acc_est_json
        json_subsample = {key: json[key] for key in json.keys() - {'extracted_feat'}}
        json_file.write(to_json(json_subsample))
        json_file.close()

    def validation(self, epoch):
        """
        Validate the performance of the model
        """
        class_accuracy_of_test_data, loss, _ = self.evaluation(epoch, 'valid')

        return class_accuracy_of_test_data, loss

    def test(self, epoch):
        """
        Test the performance of the model
        """
        class_accuracy_of_test_data, loss, cm_class = self.evaluation(epoch, 'test')
        return class_accuracy_of_test_data, loss

    def add_instance_to_memory(self, current_sample, mem):
        with torch.no_grad():
            self.net.eval()

            if isinstance(mem, FIFO):
                mem.add_instance(current_sample)

            else:
                f, c, d = current_sample[0].to(device), current_sample[1].to(device), current_sample[2].to(device)
                y_pred, y_conf, y_entropy, y_energy, y_embeddings, y_pred_softmax, _ = self.model_inference(f.unsqueeze(0))

                if isinstance(mem, ConfFIFO) or isinstance(mem, HUS) or isinstance(mem, Uniform) or isinstance(mem, PBRS):
                    mem.add_instance([f, y_pred.item(), d, y_conf.item()])

                elif isinstance(mem, CSTU):
                    mem.add_instance([f, y_pred.item(), y_entropy.item()])

                else:
                    raise NotImplementedError

    def train_online(self, current_num_sample, add_memory = True, evaluation = True):
        """
        Train the model
        """
        if current_num_sample > len(self.target_train_set[0]):
            return FINISHED

        # Add a sample
        feats, cls, dls = self.target_train_set
        current_sample = feats[current_num_sample - 1], cls[current_num_sample - 1], dls[current_num_sample - 1]
        if add_memory:
            self.add_instance_to_memory(current_sample, self.fifo)  # for batch-based inference
            self.add_instance_to_memory(current_sample, self.mem)  # used for test-time adaptation

        if current_num_sample % conf.args.update_every_x != 0:  # train only when enough samples are collected
            if not (current_num_sample == len(self.target_train_set[0]) and
                    conf.args.update_every_x >= current_num_sample):  # update with entire data
                self.log_loss_results('train_online', epoch=current_num_sample, loss_avg=self.previous_train_loss)
                return SKIPPED

        if evaluation:
            self.evaluation_online(current_num_sample, self.fifo.get_memory())

        if conf.args.no_adapt:  # for ablation
            return TRAINED

        data_loader = self.get_dataloader_for_adaptation()
        if not data_loader:
            return

        for e in range(conf.args.epoch):
            for batch_idx, feats in enumerate(data_loader):
            
                net, loss_item = self.test_time_adaptation(*feats)  # Each TTA algorithms must implement this
                if conf.args.reset_function:
                    self.reset_function(net, loss_item)

        if add_memory and evaluation:
            self.log_loss_results('train_online', epoch=current_num_sample, loss_avg=0)

        return TRAINED

    def get_dataloader_for_adaptation(self) -> Optional[torch.utils.data.DataLoader]:
        if conf.args.memory_type in ['CSTU']:
            feats, _ = self.mem.get_memory()
        else:
            feats, _, _ = self.mem.get_memory()
        feats = torch.stack(feats).to(device)

        if len(feats) == 0:
            return None

        dataset = torch.utils.data.TensorDataset(feats)
        data_loader = DataLoader(dataset, batch_size=conf.args.opt['batch_size'],
                                 shuffle=True, drop_last=False, pin_memory=False)
        return data_loader

    def test_time_adaptation(self, feats) -> Tuple[Optional[torch.nn.Module], Optional[float]]:
        """
        Adapt with input `feats` and return (1) network with gradient and (2) loss value.
        """
        if len(feats) == 1:
            self.net.eval()  # avoid BN error
        else:
            self.net.train()

        if conf.args.method in ['Src']:
            return None, None
        else:
            raise NotImplementedError

    def fgsm_attack(self, x, epsilon, net=None):
        if net is None:
            net = self.net

        # from TIPI paper
        x = x.clone().to(device)
        epsilon = epsilon.to(device)
        delta = torch.zeros_like(x)
        delta.requires_grad = True

        with torch.enable_grad():
            pred = net(x + delta) if conf.args.opt['indices_in_1k'] == None else net(x + delta)[:, conf.args.opt['indices_in_1k']]
            loss = F.kl_div(pred, pred.detach(), reduction='batchmean')
            grad = torch.autograd.grad(loss, [delta])[0]

        delta = delta.detach() + torch.sign(grad.detach())
        delta *= epsilon.view(-1, 1, 1, 1) / torch.linalg.vector_norm(delta, ord=2, dim=(1, 2, 3), keepdim=True)  # l2 norm
        x_adv = torch.clamp(x + delta, 0, 1)

        net.zero_grad()

        return x_adv

    def pgd_attack(self, x, epsilon=8/255, net=None,
                   alpha=2/255, steps=10, random_start=True):
        """ Code from torchattacks library. © Copyright 2020, harrykim. Revision 936e86d6."""
        if net is None:
            net = self.net

        x = x.clone()

        adv_images = x.clone().detach()

        if random_start:
            # Starting at a uniformly random point
            adv_images = adv_images + torch.empty_like(adv_images).uniform_(
                -epsilon, epsilon
            )
            adv_images = torch.clamp(adv_images, min=0, max=1).detach()

        with torch.enable_grad():
            for _ in range(steps):
                adv_images.requires_grad = True
                outputs = net(adv_images) if conf.args.opt['indices_in_1k'] == None else net(adv_images)[:, conf.args.opt['indices_in_1k']]

                cost = F.kl_div(outputs, outputs.detach(), reduction='batchmean')

                # Update adversarial images
                grad = torch.autograd.grad(
                    cost, adv_images, retain_graph=False, create_graph=False
                )[0]

                adv_images = adv_images.detach() + alpha * grad.sign()
                delta = torch.clamp(adv_images - x, min=-epsilon, max=epsilon)
                adv_images = torch.clamp(x + delta, min=0, max=1).detach()

        net.zero_grad()

        return adv_images

    def data_volume_density(self, src, tgt):
        std_prev = torch.std(src, (0, 2, 3))  # reduce except r, g, b
        std_curr = torch.std(tgt, (0, 2, 3))  # reduce except r, g, b
        c_den = (std_curr / std_prev).sum().item() / 3
        return c_den

    def data_distribution_diff(self, src, tgt):
        std_prev = torch.std(src, (0, 2, 3))  # reduce except r, g, b
        std_curr = torch.std(tgt, (0, 2, 3))  # reduce except r, g, b
        c_den = torch.linalg.vector_norm(std_prev - std_curr) / 3
        return c_den + 1  # To fit range [1, )

    def evaluate_consistency_body(self, curr_feats):
        if len(curr_feats) == 0:
            return None, None

        curr_pred, curr_conf, curr_entropy, curr_energy, curr_embeddings, curr_softmax, _ = self.model_inference(curr_feats)

        eps = torch.tensor(1.0 / 255.0).to(device)

        self.sa_src_net.eval()
        curr_feats = self.fgsm_attack(curr_feats, epsilon=eps, net=self.sa_src_net)

        prev_preds, prev_conf, _, _, _, prev_softmax, _ = self.model_inference(curr_feats, net=self.sa_src_net)

        equal_rate = ((prev_preds == curr_pred).sum() / len(curr_pred)).item()
        conf_dist = (torch.linalg.vector_norm(prev_softmax.max() - curr_conf, ord=1) / len(curr_pred)).item()

        equal_rate = equal_rate if not np.isnan(equal_rate) else None
        conf_dist = conf_dist if not np.isnan(conf_dist) else None

        return equal_rate, conf_dist

    def evaluate_dropout(self, feats, net, n_iter=10, dropout=0.5):
        if net is None:
            net = self.net
            
        curr_pred, curr_conf, _, _, _, curr_softmax, _ = self.model_inference(feats, net=net)

        if dropout < 0:
            if conf.args.dataset == "cifar10outdist":
                dropout = 0.4
            elif conf.args.dataset == "cifar100outdist":
                dropout = 0.3
            elif conf.args.dataset == "imagenetoutdist":
                dropout = 0.2
            elif conf.args.dataset == "imagenetR":
                dropout = 0.3
            else:
                raise NotImplementedError

        # Dropout inference sampling
        predictions = []
        with torch.no_grad():
            for _ in range(n_iter):
                pred = net[1]((net[0](feats)), dropout=dropout)  # batch_size, n_classes
                pred = F.softmax(pred, dim=1)
                predictions.append(pred)
        predictions = torch.stack(predictions, dim=1)  # batch_size, n_iter, n_classes
        pred = torch.argmax(predictions, dim=2)
        mean = torch.mean(predictions, dim=1)
        #mean_pred_class = torch.argmax(mean_pred, dim=1)
        std = torch.std(predictions, dim=1)

        conf_mean = mean[:, curr_pred].diagonal()
        conf_std = std[:, curr_pred].diagonal()
        mean_for_curr_pred = conf_mean.mean()
        std_for_curr_pred = conf_std.mean()

        total_avg_softmax = torch.mean(mean, dim=0)
        e_avg = (-total_avg_softmax * torch.log(total_avg_softmax + 1e-6)).sum()

        # Prediction disagreement with dropouts
        match_ratio = (curr_pred.unsqueeze(dim=1).repeat(1, n_iter) == pred).sum(dim=1, dtype=float) / n_iter
        acc = match_ratio.mean()
        return acc.item(), mean_for_curr_pred.item(), std_for_curr_pred.item(), e_avg.item()

    def init_reset(self, net, optimizer):
        self.prev_net = deepcopy(net)
        self.prev_net_state_queue = deque()
        self.prev_feat_queue = deque()
        self.prev_optim_state_queue = deque()
        self.curr_iter = 0
        self.num_reset = 0
        
        self.er_moving_average = None

        self.net_state, self.optimizer_state = reset_utils.copy_model_and_optimizer(net, optimizer)

        if not conf.args.reset_function:
            return
        
        if conf.args.reset_function == "SAR":
            self.ema = None
            
        elif conf.args.reset_function == "CoTTA":
            self.rst = conf.args.restoration_factor
        
        elif conf.args.reset_function == "PETAL":
            self.perc = 0.03  # for CIFAR100-C
            
        elif conf.args.reset_function == "periodic":
            self.count_for_reset = 0
            self.reset_every_x = conf.args.reset_every_x

        elif conf.args.reset_function == "aetta":
            self.reset_memory = []

        else:
            raise NotImplementedError
        
    def hard_reset(self):
        print("reset the model")
        if self.net_state is None or self.optimizer_state is None:
            raise Exception("cannot reset without saved model/optimizer")
        reset_utils.load_model_and_optimizer(self.net, self.optimizer, self.net_state, self.optimizer_state)
        self.num_reset += 1

    def soft_reset(self, net_state, optim_state):
        if self.net_state is None or self.optimizer_state is None:
            raise Exception("cannot reset without saved model/optimizer")
        reset_utils.load_model_and_optimizer(self.net, self.optimizer, net_state, optim_state)
        self.num_reset += 1
        
    def reset_function(self, net=None, loss=None):
        if conf.args.reset_function == "SAR":
            if loss and not np.isnan(loss):
                self.ema = reset_utils.update_ema(self.ema, loss)

            if self.ema is not None and self.ema < 0.2:
                print("ema < 0.2, now reset the model")
                ema = self.ema
                self.hard_reset()
                self.ema = ema

        elif conf.args.reset_function == "CoTTA":
            for nm, m in net.named_modules():
                for npp, p in m.named_parameters():
                    if npp in ['weight', 'bias'] and p.requires_grad:
                        mask = (torch.rand(p.shape) < self.rst).float().cuda()
                        with torch.no_grad():
                            p.data = self.net_state[f"{nm}.{npp}"] * mask + p * (1. - mask)
                            
        elif conf.args.reset_function == "PETAL":
            if net is None:
                return
            self.fisher_dict = {}

            for nm, m in net.named_modules():  # previously used model, but now using self.model
                for npp, p in m.named_parameters():
                    if npp in ['weight', 'bias'] and p.requires_grad:
                        self.fisher_dict[f"{nm}.{npp}"] = p.grad.data.clone().pow(2)
            fisher_list = []
            for name in self.fisher_dict:
                fisher_list.append(self.fisher_dict[name].reshape(-1))
            fisher_flat = torch.cat(fisher_list)
            reset_threshold_PETAL = reset_utils.find_quantile(fisher_flat, self.perc)

            for nm, m in net.named_modules():
                for npp, p in m.named_parameters():
                    if npp in ['weight', 'bias'] and p.requires_grad:
                        # masking makes it restore candidate
                        mask_fish = (self.fisher_dict[f"{nm}.{npp}"] < reset_threshold_PETAL).float().cuda()
                        mask = mask_fish
                        with torch.no_grad():
                            p.data = self.net_state[f"{nm}.{npp}"] * mask + p * (1. - mask)
                            
        elif conf.args.reset_function == "periodic":
            self.count_for_reset += 1
            if self.count_for_reset == self.reset_every_x:
                print(f"reset every {self.reset_every_x}. Now reset")
                self.hard_reset()  # need to implement period of reset
                self.count_for_reset = 0
        
        elif conf.args.reset_function == "aetta":
            acc_preds = self.acc_est_json['aetta']
            self.reset_memory += [acc_preds[-1]]
            if acc_preds[-1] < 20:
                self.hard_reset()
                self.reset_memory = []
            if len(self.reset_memory) >= 10:
                self.reset_memory = self.reset_memory[-10:]
                if sum(self.reset_memory[-5:])/5 + 2 < sum(self.reset_memory[-10:-5])/5:
                    self.hard_reset()
                    self.reset_memory = []

        else:
            raise NotImplementedError

    def avg_confidence(self, y_logit):
        T = 2
        ac_conf = F.softmax(y_logit/T, dim=1).max(1, keepdim=False)[0]
        average_conf = self.acc_est_json[f'softmax_score']
        average_conf += [ac_conf.mean().item()]
        self.acc_est_json[f'softmax_score'] = average_conf
        
    def agreement(self, feats, y_pred):
        if self.sa_ref_net_1 is None:
            self.sa_ref_net_1 = deepcopy(self.net)
            
        self.prev_net_state_queue.appendleft(deepcopy(self.net.state_dict()))
        if len(self.prev_net_state_queue) > 10:
            self.prev_net_state_queue.pop()

        if len(self.prev_net_state_queue) > 1:
            self.sa_ref_net_1.load_state_dict(self.prev_net_state_queue[1], strict=True)
        
        self.sa_ref_net_1.eval() 
        with torch.no_grad():
            agreement = self.acc_est_json['gde']
            ref_y_pred, _, _, _, _, _, _ = self.model_inference(feats, net=self.sa_ref_net_1)
            agreement += [(ref_y_pred == y_pred).float().mean().item()]
            self.acc_est_json['gde'] = agreement

    def src_validation(self):
        src_feats, src_cls, src_dls = self.source_val_dataloader
        src_cls = src_cls.to(torch.int32)  # bugfix when comparing outdist_index
        src_feats, src_cls, src_dls = src_feats.to(device), src_cls.to(device), src_dls.to(device)

        src_accuracy = self.acc_est_json['src_validation']
        src_y_pred, _, _, _, _, _, _ = self.model_inference(src_feats)
        src_accuracy += [(src_y_pred == src_cls).float().mean().item()]
        self.acc_est_json['src_validation'] = src_accuracy

    def adv(self, feats):
        er, _ = self.evaluate_consistency_body(feats)
        self.acc_est_json['adv_perturb'] += [er]

    def aetta(self, feats, y_pred):
        est_acc, mean, std, e_avg = self.evaluate_dropout(feats, self.net, dropout=conf.args.dropout_rate)
        self.acc_est_json['est_dropout'] += [est_acc]
        self.acc_est_json['est_dropout_avg_entropy'] += [e_avg]
        self.acc_est_json['est_dropout_softmax_mean'] += [mean]
        self.acc_est_json['est_dropout_softmax_std'] += [std]

        est_err = 1 - est_acc
        if self.est_ema_dropout is None:
            self.est_ema_dropout = est_err

        if conf.args.dataset == "cifar10outdist":
            MAX_ENTROPY = 2.3026  # cifar10
            N_CLASS = 10
        elif conf.args.dataset == "cifar100outdist":
            MAX_ENTROPY = 4.6052  # cifar100
            N_CLASS = 100
        elif conf.args.dataset == "imagenetR" :
            MAX_ENTROPY = 5.2983  # imagenetR
            N_CLASS = 200
        else:
            MAX_ENTROPY = 6.9078  # imagenet
            N_CLASS = 1000

        updated = est_err / (e_avg / MAX_ENTROPY) ** 3
        updated = max(0., min(1. - 1. / N_CLASS, updated))

        updated = self.est_ema_dropout * 0.6 + updated * 0.4
        self.est_ema_dropout = updated

        self.acc_est_json['aetta'] += [100 * (1. - updated)]

File Path: learner/eata.py
Content:

import conf
from data_loader.CIFAR100Dataset import CIFAR100Dataset
from data_loader.CIFAR10Dataset import CIFAR10Dataset
from data_loader.IMAGENETDataset import ImageNetDataset
from data_loader.IMAGENETRDataset import ImageNetRDataset

from utils.loss_functions import *

device = torch.device("cuda:{:d}".format(conf.args.gpu_idx) if torch.cuda.is_available() else "cpu")

from torch import optim

import conf
from data_loader.OutDistDataset import OutDistDataset
from data_loader.data_loader import datasets_to_dataloader
from utils.reset_utils import copy_model_and_optimizer
from .dnn import DNN
from torch.utils.data import  random_split

from utils.loss_functions import *
from utils import memory


class ETA(DNN):
    # EATA without anti-forgetting
    def __init__(self, model_, corruption_list_):
        super(ETA, self).__init__(model_, corruption_list_)

        configure_model(self.net)

        self.optimizer = optim.SGD(self.net.parameters(),
                                   lr=conf.args.opt['learning_rate'],
                                   momentum=conf.args.opt['momentum'],
                                   weight_decay=conf.args.opt['weight_decay'])

        # self.steps = 1 # SoTTA: replaced to epoch
        # assert self.steps > 0, "EATA requires >= 1 step(s) to forward and update"
        # self.episodic = False  # SoTTA: we don't use episodic

        self.num_samples_update_1 = 0  # number of samples after First filtering, exclude unreliable samples
        self.num_samples_update_2 = 0  # number of samples after Second filtering, exclude both unreliable and redundant samples
        self.e_margin = conf.args.e_margin  # hyper-parameter E_0 (Eqn. 3)
        self.d_margin = conf.args.d_margin  # hyper-parameter \epsilon for consine simlarity thresholding (Eqn. 5)

        self.current_model_probs = None  # the moving average of probability vector (Eqn. 4)

        self.fishers = None  # fisher regularizer items for anti-forgetting, need to be calculated pre model adaptation (Eqn. 9)
        self.fisher_alpha = conf.args.fisher_alpha  # trade-off \beta for two losses (Eqn. 8)

        # note: if the model is never reset, like for continual adaptation,
        # then skipping the state copy would save memory
        self.model_state, self.optimizer_state = copy_model_and_optimizer(self.net, self.optimizer)

        self.fifo = memory.FIFO(capacity=conf.args.update_every_x)  # required for evaluation
        self.mem_state = self.mem.save_state_dict()
        self.init_reset(self.net, self.optimizer)

    def test_time_adaptation(self, feats):
        if len(feats) == 1:
            self.net.eval()  # avoid BN error
        else:
            self.net.train()

        result = forward_and_adapt_eata(feats, self.net,
                                        self.optimizer,
                                        self.fishers,
                                        self.e_margin,
                                        self.current_model_probs,
                                        fisher_alpha=self.fisher_alpha,
                                        num_samples_update=self.num_samples_update_2,
                                        d_margin=self.d_margin)
        outputs, num_counts_2, num_counts_1, updated_probs, loss = result

        self.num_samples_update_2 += num_counts_2
        self.num_samples_update_1 += num_counts_1
        self.reset_model_probs(updated_probs)
        return self.net, loss.item()

    def reset_model_probs(self, probs):
        self.current_model_probs = probs


class EATA(ETA):
    def __init__(self, model_, corruption_list_):
        super(EATA, self).__init__(model_, corruption_list_)

        # only use the first domain for fisher importance calculation
        if conf.args.dataset in ["cifar10outdist", "cifar100outdist", "imagenetoutdist"]:
            fisher_dataset = OutDistDataset(base=conf.args.dataset, domains=[corruption_list_[0]], max_source=9999,
                                            transform='val',
                                            outdist=conf.args.outdist, outdist_size=conf.args.outdist_size,
                                            outdist_class=conf.args.outdist_class)
        elif conf.args.dataset == "cifar10":
            fisher_dataset = CIFAR10Dataset(file="", domains=[corruption_list_[0]], max_source=9999, transform='val')
        elif conf.args.dataset == "cifar100":
            fisher_dataset = CIFAR100Dataset(file="", domains=[corruption_list_[0]], max_source=9999, transform='val')
        elif conf.args.dataset == "imagenet":
            fisher_dataset = ImageNetDataset(file="", domain=corruption_list_[0], max_source=9999, transform='val')
        elif conf.args.dataset == "imagenetR":
            fisher_dataset = ImageNetRDataset(file="", domain=corruption_list_[0], max_source=9999, transform='val')
        else:
            raise NotImplementedError

        fisher_dataset = random_split(fisher_dataset, [conf.args.fisher_size, len(fisher_dataset)-conf.args.fisher_size])[0]
        fisher_loader = datasets_to_dataloader([fisher_dataset], batch_size=64, concat=True, shuffle=True)

        subnet = configure_model(self.net)
        params, param_names = collect_params(subnet)
        ewc_optimizer = torch.optim.SGD(params, 0.001)
        fishers = {}
        train_loss_fn = nn.CrossEntropyLoss().cuda()
        for iter_, (images, targets, domains) in enumerate(fisher_loader, start=1):
            if conf.args.gpu_idx is not None:
                images = images.cuda(conf.args.gpu_idx, non_blocking=True)
            # if torch.cuda.is_available():
            #     targets = targets.cuda(conf.args.gpu_idx, non_blocking=True)
            outputs = subnet(images) if conf.args.opt['indices_in_1k'] == None else subnet(images)[:, conf.args.opt['indices_in_1k']]
            _, targets = outputs.max(1)
            loss = train_loss_fn(outputs, targets)
            loss.backward()
            for name, param in subnet.named_parameters():
                if param.grad is not None:
                    if iter_ > 1:
                        fisher = param.grad.data.clone().detach() ** 2 + fishers[name][0]
                    else:
                        fisher = param.grad.data.clone().detach() ** 2
                    if iter_ == len(fisher_loader):
                        fisher = fisher / iter_
                    fishers.update({name: [fisher, param.data.clone().detach()]})
            ewc_optimizer.zero_grad()
        # logger.info("compute fisher matrices finished")
        del ewc_optimizer
        self.fishers = fishers  # fisher regularizer items for anti-forgetting, need to be calculated pre model adaptation (Eqn. 9)


def collect_params(model):
    """Collect the affine scale + shift parameters from batch norms.
    Walk the model's modules and collect all batch normalization parameters.
    Return the parameters and their names.
    Note: other choices of parameterization are possible!
    """
    params = []
    names = []
    for nm, m in model.named_modules():
        if isinstance(m, nn.BatchNorm2d):
            for np, p in m.named_parameters():
                if np in ['weight', 'bias']:  # weight is scale, bias is shift
                    params.append(p)
                    names.append(f"{nm}.{np}")
    return params, names


def configure_model(model):
    """Configure model for use with eata."""
    # train mode, because eata optimizes the model to minimize entropy
    model.train()
    # disable grad, to (re-)enable only what eata updates
    model.requires_grad_(False)
    # configure norm for eata updates: enable grad + force batch statisics
    for m in model.modules():
        if isinstance(m, nn.BatchNorm2d):
            m.requires_grad_(True)
            # force use of batch stats in train and eval modes
            m.track_running_stats = False
            m.running_mean = None
            m.running_var = None
    return model


@torch.enable_grad()  # ensure grads in possible no grad context for testing
def forward_and_adapt_eata(x, model, optimizer, fishers, e_margin, current_model_probs, fisher_alpha=50.0,
                           d_margin=0.05, scale_factor=2, num_samples_update=0):
    """Forward and adapt model on batch of data.
    Measure entropy of the model prediction, take gradients, and update params.
    Return:
    1. model outputs;
    2. the number of reliable and non-redundant samples;
    3. the number of reliable samples;
    4. the moving average  probability vector over all previous samples
    """
    # forward 
    outputs = model(x) if conf.args.opt['indices_in_1k'] == None else model(x)[:, conf.args.opt['indices_in_1k']]
    # adapt
    entropys = softmax_entropy(outputs)
    # filter unreliable samples
    filter_ids_1 = torch.where(entropys < e_margin)
    ids1 = filter_ids_1
    ids2 = torch.where(ids1[0] > -0.1)
    entropys = entropys[filter_ids_1]
    # filter redundant samples
    if current_model_probs is not None:
        cosine_similarities = F.cosine_similarity(current_model_probs.unsqueeze(dim=0),
                                                  outputs[filter_ids_1].softmax(1), dim=1)
        filter_ids_2 = torch.where(torch.abs(cosine_similarities) < d_margin)
        entropys = entropys[filter_ids_2]
        ids2 = filter_ids_2
        updated_probs = update_model_probs(current_model_probs, outputs[filter_ids_1][filter_ids_2].softmax(1))
    else:
        updated_probs = update_model_probs(current_model_probs, outputs[filter_ids_1].softmax(1))
    coeff = 1 / (torch.exp(entropys.clone().detach() - e_margin))
    # implementation version 1, compute loss, all samples backward (some unselected are masked)
    entropys = entropys.mul(coeff)  # reweight entropy losses for diff. samples
    loss = entropys.mean(0)
    """
    # implementation version 2, compute loss, forward all batch, forward and backward selected samples again.
    # if x[ids1][ids2].size(0) != 0:
    #     loss = softmax_entropy(model(x[ids1][ids2])).mul(coeff).mean(0) # reweight entropy losses for diff. samples
    """
    if fishers is not None:
        ewc_loss = 0
        for name, param in model.named_parameters():
            if name in fishers:
                ewc_loss += fisher_alpha * (fishers[name][0] * (param - fishers[name][1]) ** 2).sum()
        loss += ewc_loss
    optimizer.zero_grad()  # move it here to make PETAL reset works!
    if x[ids1][ids2].size(0) != 0:
        loss.backward()
        optimizer.step()
    # optimizer.zero_grad()
    return outputs, entropys.size(0), filter_ids_1[0].size(0), updated_probs, loss


@torch.jit.script
def softmax_entropy(x: torch.Tensor) -> torch.Tensor:
    """Entropy of softmax distribution from logits."""
    temprature = 1
    x = x / temprature
    x = -(x.softmax(1) * x.log_softmax(1)).sum(1)
    return x


def update_model_probs(current_model_probs, new_probs):
    if current_model_probs is None:
        if new_probs.size(0) == 0:
            return None
        else:
            with torch.no_grad():
                return new_probs.mean(0)
    else:
        if new_probs.size(0) == 0:
            with torch.no_grad():
                return current_model_probs
        else:
            with torch.no_grad():
                return 0.9 * current_model_probs + (1 - 0.9) * new_probs.mean(0)


def check_model(model):
    """Check model for compatability with eata."""
    is_training = model.training
    assert is_training, "eata needs train mode: call model.train()"
    param_grads = [p.requires_grad for p in model.parameters()]
    has_any_params = any(param_grads)
    has_all_params = all(param_grads)
    assert has_any_params, "eata needs params to update: " \
                           "check which require grad"
    assert not has_all_params, "eata should not update all params: " \
                               "check which require grad"
    has_bn = any([isinstance(m, nn.BatchNorm2d) for m in model.modules()])
    assert has_bn, "eata needs normalization for its optimization"

File Path: learner/rotta.py
Content:
from typing import Optional, Tuple

import conf
from .dnn import DNN, TRAINED
from torch.utils.data import DataLoader
import torch.optim as optim

from utils.loss_functions import *
from utils import memory, bn_layers_rotta, memory_rotta, reset_utils
from copy import deepcopy
from utils.custom_transforms import get_tta_transforms
from torch import nn
device = torch.device("cuda:{:d}".format(conf.args.gpu_idx) if torch.cuda.is_available() else "cpu")


class RoTTA(DNN):
    def __init__(self, *args, **kwargs):
        super(RoTTA, self).__init__(*args, **kwargs)

        self.net.requires_grad_(False)
        self.alpha = 0.05
        normlayer_names = []

        for name, sub_module in self.net.named_modules():
            if isinstance(sub_module, nn.BatchNorm1d) or isinstance(sub_module, nn.BatchNorm2d):
                normlayer_names.append(name)

        for name in normlayer_names:
            bn_layer = get_named_submodule(self.net, name)
            if isinstance(bn_layer, nn.BatchNorm1d):
                NewBN = bn_layers_rotta.RobustBN1d
            elif isinstance(bn_layer, nn.BatchNorm2d):
                NewBN = bn_layers_rotta.RobustBN2d
            else:
                raise RuntimeError()

            momentum_bn = NewBN(bn_layer, self.alpha)
            momentum_bn.requires_grad_(True)
            set_named_submodule(self.net, name, momentum_bn)

        params, param_names = self.collect_params(self.net)
        self.optimizer = optim.Adam(params, lr=1e-3, betas=(0.9, 0.999), weight_decay=0.0)

        net_ema = deepcopy(self.net)
        for param in net_ema.parameters():
            param.detach_()

        self.net_not_ema = self.net
        self.net = net_ema  # set self.net to self.net_ema
        self.net.to(device)

        self.nu = 0.001

        self.init_reset(self.net_not_ema, self.optimizer)

    def hard_reset(self):
        if self.net_state is None or self.optimizer_state is None:
            raise Exception("cannot reset without saved model/optimizer")
        reset_utils.load_model_and_optimizer(self.net_not_ema, self.optimizer, self.net_state, self.optimizer_state)

        net_ema = deepcopy(self.net_not_ema)
        for param in net_ema.parameters():
            param.detach_()

        self.net = net_ema  # set self.net to self.net_ema
        self.net.to(device)
        self.num_reset += 1
    
    def soft_reset(self, net_state, optim_state):
        if self.net_state is None or self.optimizer_state is None:
            raise Exception("cannot reset without saved model/optimizer")
        reset_utils.load_model_and_optimizer(self.net_not_ema, self.optimizer, net_state, optim_state)
        
        net_ema = deepcopy(self.net_not_ema)
        for param in net_ema.parameters():
            param.detach_()

        self.net = net_ema  # set self.net to self.net_ema
        self.net.to(device)
        self.num_reset += 1
        
    def set_target_data(self, *args, **kwargs):
        super(RoTTA, self).set_target_data(*args, **kwargs)
        self.transform = get_tta_transforms(tuple(self.target_train_set[0][0].shape[1:]))

    def get_dataloader_for_adaptation(self) -> Optional[torch.utils.data.DataLoader]:
        assert(conf.args.memory_type in ['CSTU'])
        feats, ages = self.mem.get_memory()
        feats = torch.stack(feats).to(device)
        ages = torch.Tensor(ages).to(device)

        if len(feats) == 0:
            return None

        dataset = torch.utils.data.TensorDataset(feats, ages)
        data_loader = DataLoader(dataset, batch_size=conf.args.opt['batch_size'],
                                 shuffle=True, drop_last=False, pin_memory=False)
        return data_loader

    def test_time_adaptation(self, feats, ages=None):
        assert(ages is not None)

        # setup models
        self.net_not_ema.train()
        self.net.train()

        if len(feats) == 1:  # avoid BN error
            self.net_not_ema.eval()
            self.net.eval()

        strong_sup_aug = self.transform(feats)
        ema_sup_out = self.net(feats) if conf.args.opt['indices_in_1k'] == None else self.net(feats)[:, conf.args.opt['indices_in_1k']]
        stu_sup_out = self.net_not_ema(strong_sup_aug) if conf.args.opt['indices_in_1k'] == None else self.net_not_ema(strong_sup_aug)[:, conf.args.opt['indices_in_1k']]
        instance_weight = self.timeliness_reweighting(ages)
        loss = (softmax_entropy_rotta(stu_sup_out, ema_sup_out) * instance_weight).mean()

        if loss is not None:
            self.optimizer.zero_grad()

            loss.backward()

            self.optimizer.step()

        self.net = self.update_ema_variables(self.net, self.net_not_ema, self.nu)

        return self.net_not_ema, loss.item()  # RoTTA backprops on student model. No gradient in teacher.

    def timeliness_reweighting(self, ages):
        if isinstance(ages, list):
            ages = torch.tensor(ages).float().cuda()
        return torch.exp(-ages) / (1 + torch.exp(-ages))

    def update_ema_variables(self, ema_model, model, nu):
        for ema_param, param in zip(ema_model.parameters(), model.parameters()):
            ema_param.data[:] = (1 - nu) * ema_param[:].data[:] + nu * param[:].data[:]
        return ema_model
    
    def collect_params(self, model: nn.Module):
        names = []
        params = []

        for n, p in model.named_parameters():
            if p.requires_grad:
                names.append(n)
                params.append(p)

        return params, names
    
def get_named_submodule(model, sub_name: str):
    names = sub_name.split(".")
    module = model
    for name in names:
        module = getattr(module, name)

    return module


def set_named_submodule(model, sub_name, value):
    names = sub_name.split(".")
    module = model
    for i in range(len(names)):
        if i != len(names) - 1:
            module = getattr(module, names[i])

        else:
            setattr(module, names[i], value)
File Path: learner/sar.py
Content:
from copy import deepcopy

import math

import conf
from utils import memory
from utils.reset_utils import copy_model_and_optimizer, load_model_and_optimizer
from utils.sam_optimizer import sam_collect_params, SAM
from .dnn import DNN
from torch.utils.data import DataLoader

from utils.loss_functions import *

device = torch.device("cuda:{:d}".format(conf.args.gpu_idx) if torch.cuda.is_available() else "cpu")


def update_ema(ema, new_data):
    if ema is None:
        return new_data
    else:
        with torch.no_grad():
            return 0.9 * ema + (1 - 0.9) * new_data


class SAR(DNN):
    def __init__(self, *args, **kwargs):
        super(SAR, self).__init__(*args, **kwargs)

        # turn on grad for BN params only

        self.net.train()

        for param in self.net.parameters():  # initially turn off requires_grad for all
            param.requires_grad = False

        for module in self.net.modules():
            if isinstance(module, nn.BatchNorm1d) or isinstance(module, nn.BatchNorm2d):
                if conf.args.use_learned_stats:
                    module.track_running_stats = True
                    module.momentum = conf.args.bn_momentum
                else:
                    # With below, this module always uses the test batch statistics (no momentum)
                    module.track_running_stats = False
                    module.running_mean = None
                    module.running_var = None

                module.weight.requires_grad_(True)
                module.bias.requires_grad_(True)

            # LayerNorm and GroupNorm for ResNet-GN and Vit-LN models
            # TODO: support use_learned_stats
            if isinstance(module, (nn.LayerNorm, nn.GroupNorm)):
                module.requires_grad_(True)

        params, _ = sam_collect_params(self.net)
        self.optimizer = SAM(params, torch.optim.SGD, lr=conf.args.opt['learning_rate'],
                             momentum=conf.args.opt['momentum'])

        # SAR-specific hyperparameters
        if conf.args.outdist == "divide":
            num_class = conf.args.opt['num_class'] - len(conf.args.outdist_class)
        else:
            num_class = conf.args.opt['num_class']

        self.margin_e0 = 0.4 * math.log(num_class) # math.log(1000)
        self.reset_constant_em = 0.2
        self.ema = None

        self.net_state, self.optimizer_state = copy_model_and_optimizer(self.net, self.optimizer)

        self.fifo = memory.FIFO(capacity=conf.args.update_every_x)  # required for evaluation
        self.mem_state = self.mem.save_state_dict()

        self.init_reset(self.net, self.optimizer)

    def hard_reset(self):
        super(SAR, self).hard_reset()
        if not conf.args.turn_off_reset:
            self.ema = None

    def test_time_adaptation(self, feats):
        if len(feats) == 1:
            self.net.eval()  # avoid BN error
        else:
            self.net.train()

        feats = feats.to(device)

        self.optimizer.zero_grad()

        preds_of_data = self.net(feats) if conf.args.opt['indices_in_1k'] == None else self.net(feats)[:, conf.args.opt['indices_in_1k']]

        # filtering reliable samples/gradients for further adaptation; first time forward
        entropys = softmax_entropy(preds_of_data)
        filter_ids_1 = torch.where(entropys < self.margin_e0)
        entropys = entropys[filter_ids_1]
        loss = entropys.mean(0)


        loss.backward()


        # compute \hat{\epsilon(\Theta)} for first order approximation, Eqn. (4)
        self.optimizer.first_step(zero_grad=True)

        # second time backward, update model weights using gradients at \Theta+\hat{\epsilon(\Theta)}
        entropys2 = softmax_entropy(self.net(feats)) if conf.args.opt['indices_in_1k'] == None else softmax_entropy(self.net(feats)[:, conf.args.opt['indices_in_1k']])

        entropys2 = entropys2[filter_ids_1]
        filter_ids_2 = torch.where(entropys2 < self.margin_e0)
        loss_second = entropys2[filter_ids_2].mean(0)
        


        loss_second.backward()

        self.optimizer.second_step(zero_grad=False)

        if conf.args.turn_off_reset is False and conf.args.reset_function != "SAR":
            if not np.isnan(loss_second.item()):
                self.ema = update_ema(self.ema, loss_second.item())
            if self.ema is not None and self.ema < 0.2:
                print("ema < 0.2, now reset the model")
                ema = self.ema
                self.hard_reset()
                self.ema = ema

        return self.net, loss_second.item()

File Path: learner/sotta.py
Content:
import conf
from utils import reset_utils
from .dnn import DNN
from torch.utils.data import DataLoader
from utils.loss_functions import *
from utils.sam_optimizer import SAM, sam_collect_params


device = torch.device("cuda:{:d}".format(conf.args.gpu_idx) if torch.cuda.is_available() else "cpu")


class SoTTA(DNN):
    def __init__(self, *args, **kwargs):
        super(SoTTA, self).__init__(*args, **kwargs)

        # turn on grad for BN params only

        for param in self.net.parameters():  # initially turn off requires_grad for all
            param.requires_grad = False
        for module in self.net.modules():

            if isinstance(module, nn.BatchNorm1d) or isinstance(module, nn.BatchNorm2d):
                # https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html

                if conf.args.use_learned_stats:
                    module.track_running_stats = True
                    module.momentum = conf.args.bn_momentum
                else:
                    # With below, this module always uses the test batch statistics (no momentum)
                    module.track_running_stats = False
                    module.running_mean = None
                    module.running_var = None

                module.weight.requires_grad_(True)
                module.bias.requires_grad_(True)

            elif isinstance(module, nn.InstanceNorm1d) or isinstance(module, nn.InstanceNorm2d):  # ablation study
                module.weight.requires_grad_(True)
                module.bias.requires_grad_(True)

            elif isinstance(module, nn.LayerNorm):  # language models
                module.weight.requires_grad_(True)
                module.bias.requires_grad_(True)

        if conf.args.sam:
            params, _ = sam_collect_params(self.net)
            self.optimizer = SAM(params, torch.optim.Adam, rho=0.05, lr=conf.args.opt['learning_rate'],
                                 weight_decay=conf.args.opt['weight_decay'])

        self.init_reset(self.net, self.optimizer)

    def test_time_adaptation(self, feats):
        if len(feats) == 1:
            self.net.eval()  # avoid BN error
        else:
            self.net.train()

        loss_fn = HLoss(conf.args.temperature)

        self.net.train()
        feats = feats.to(device)
        preds_of_data = self.net(feats) if conf.args.opt['indices_in_1k'] == None else self.net(feats)[:, conf.args.opt['indices_in_1k']]

        loss_first = loss_fn(preds_of_data)

        self.optimizer.zero_grad()

        loss_first.backward()

        if not isinstance(self.optimizer, SAM):
            self.optimizer.step()
            return self.net, loss_first.item()
        else:
            # compute \hat{\epsilon(\Theta)} for first order approximation, Eqn. (4)
            self.optimizer.first_step(zero_grad=True)

            preds_of_data = self.net(feats) if conf.args.opt['indices_in_1k'] == None else self.net(feats)[:, conf.args.opt['indices_in_1k']]

            # second time backward, update model weights using gradients at \Theta+\hat{\epsilon(\Theta)}
            loss_second = loss_fn(preds_of_data)

            loss_second.backward()

            self.optimizer.second_step(zero_grad=False)
            return self.net, loss_second.item()

File Path: learner/tent.py
Content:
from torch import optim

import conf
from .dnn import DNN
from torch.utils.data import DataLoader

from utils.loss_functions import *
from utils import memory

device = torch.device("cuda:{:d}".format(conf.args.gpu_idx) if torch.cuda.is_available() else "cpu")


class TENT(DNN):
    def __init__(self, *args, **kwargs):
        super(TENT, self).__init__(*args, **kwargs)

        # turn on grad for BN params only

        for param in self.net.parameters():  # initially turn off requires_grad for all
            param.requires_grad = False

        for module in self.net.modules():
            if isinstance(module, nn.BatchNorm1d) or isinstance(module, nn.BatchNorm2d):
                # https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html
                # TENT: force use of batch stats in train and eval modes: https://github.com/DequanWang/tent/blob/master/tent.py
                if conf.args.use_learned_stats:
                    module.track_running_stats = True
                    module.momentum = conf.args.bn_momentum
                else:
                    module.track_running_stats = False
                    module.running_mean = None
                    module.running_var = None

                module.weight.requires_grad_(True)
                module.bias.requires_grad_(True)

        if conf.args.dataset in ['imagenet', 'imagenetoutdist']:  # TENT use SGD for imagenet
            self.optimizer = optim.SGD(self.net.parameters(), lr=conf.args.opt['learning_rate'],
                                       weight_decay=conf.args.opt['weight_decay'])

        else:
            self.optimizer = optim.Adam(self.net.parameters(), lr=conf.args.opt['learning_rate'],
                                        weight_decay=0.0)

        self.fifo = memory.FIFO(capacity=conf.args.update_every_x)  # required for evaluation
        self.mem_state = self.mem.save_state_dict()

        self.init_reset(self.net, self.optimizer)

    def test_time_adaptation(self, feats):
        if len(feats) == 1:
            self.net.eval()  # avoid BN error
        else:
            self.net.train()

        entropy_loss = HLoss()

        preds_of_data = self.net(feats) if conf.args.opt['indices_in_1k'] == None else self.net(feats)[:, conf.args.opt['indices_in_1k']]

        loss = entropy_loss(preds_of_data)

        self.optimizer.zero_grad()


        loss.backward()

        self.optimizer.step()

        return self.net, loss.item()

File Path: main.py
Content:
# -*- coding: utf-8 -*-

import sys
import argparse
import random

import math
import numpy as np
import torch
import time
import os
import conf
from copy import deepcopy


os.environ['TOKENIZERS_PARALLELISM'] = 'false'

# For results reproducibility; would increase GPU memory ~24MiB
# https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility
os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'


def get_path():
    # path = 'log_231026/aapnocof/'
    path = conf.args.log_name
    # path = 'log_231026/'

    # information about used data type
    path += conf.args.dataset + '/'

    # information about used model type

    if conf.args.outdist:
        path += conf.args.method + "_outdist/"
    else:
        path += conf.args.method + '/'

    # information about domain(condition) of training data
    if conf.args.src == ['rest']:
        path += 'src_rest' + '/'
    elif conf.args.src == ['all']:
        path += 'src_all' + '/'
    elif conf.args.src is not None and len(conf.args.src) >= 1:
        path += 'src_' + '_'.join(conf.args.src) + '/'

    if conf.args.tgt:
        if conf.args.outdist:
            path += 'tgt_' + conf.args.tgt + '_{}'.format(conf.args.outdist) + '_{}'.format(
                conf.args.outdist_size) + '_{}/'.format(conf.args.outdist_class)
        else:
            path += 'tgt_' + conf.args.tgt + '/'

    if conf.args.reset_function:
        path += "reset_{}/".format(conf.args.reset_function)

    path += conf.args.log_prefix + '/'

    checkpoint_path = path + 'cp/'
    log_path = path
    result_path = path + '/'

    print('Path:{}'.format(path))
    return result_path, checkpoint_path, log_path


def main():
    ######################################################################
    device = torch.device("cuda:{:d}".format(conf.args.gpu_idx) if torch.cuda.is_available() else "cpu")
    # Assume that we are on a CUDA machine, then this should print a CUDA device:
    print(device)

    ################### Hyperparameters #################
    if 'cifar100' in conf.args.dataset:
        opt = conf.CIFAR100Opt
    elif 'cifar10' in conf.args.dataset:
        opt = conf.CIFAR10Opt
    elif conf.args.dataset in ['imagenet', 'imagenetoutdist']:
        opt = conf.IMAGENET_C
    elif 'imagenetR' in conf.args.dataset:
        opt = conf.IMAGENET_R
    else:
        raise NotImplementedError

    conf.args.opt = opt
    if conf.args.lr:
        opt['learning_rate'] = conf.args.lr
    if conf.args.weight_decay:
        opt['weight_decay'] = conf.args.weight_decay

    model = None
    tokenizer = None  # for language models

    if conf.args.model == "resnet18":
        from models import ResNet
        model = ResNet.ResNet18
    elif conf.args.model == "resnet18_pretrained":
        import torchvision
        model = torchvision.models.resnet18
    elif conf.args.model == "resnet50":
        from models import ResNet
        model = ResNet.ResNet50
    elif conf.args.model == "resnet50_pretrained":
        import torchvision
        model = torchvision.models.resnet50
    elif conf.args.model == "wide_resnet":
        from models import wide_resnet
        model = wide_resnet.WideResNet

    # import modules after setting the seed
    from data_loader import data_loader as data_loader
    from learner.dnn import DNN
    from learner.tent import TENT
    from learner.sotta import SoTTA
    from learner.cotta import CoTTA
    from learner.sar import SAR
    from learner.rotta import RoTTA
    from learner.eata import ETA, EATA

    result_path, checkpoint_path, log_path = get_path()

    ########## Dataset loading ############################

    if conf.args.method == 'Src':
        learner_method = DNN
    elif conf.args.method == 'TENT':
        learner_method = TENT
    elif conf.args.method == 'CoTTA':
        learner_method = CoTTA
    elif conf.args.method == 'SAR':
        learner_method = SAR
    elif conf.args.method == "RoTTA":
        learner_method = RoTTA
    elif conf.args.method == 'SoTTA':
        learner_method = SoTTA
    elif conf.args.method == "EATA":
        learner_method = EATA
    elif conf.args.method == "ETA":
        learner_method = ETA
    else:
        raise NotImplementedError

    corruption_list = []

    # modify for continual adaptation
    if conf.args.tgt == "cont":
        if conf.args.cont_seq not in conf.CONT_SEQUENCE.keys():
            corruption_list_ = conf.CONT_SEQUENCE[0]
            random.shuffle(corruption_list_)
        else:
            corruption_list_ = conf.CONT_SEQUENCE[conf.args.cont_seq]

        corruption_list += corruption_list_
    else:
        corruption_list += [conf.args.tgt]

    learner = learner_method(model, corruption_list)
    original_result_path, original_checkpoint_path, original_log_path = result_path, checkpoint_path, log_path

    for corruption in corruption_list:

        if conf.args.tgt == "cont":
            result_path = original_result_path + corruption + "/"
            checkpoint_path = original_checkpoint_path + corruption + "/"
            log_path = original_log_path + corruption + "/"

        else:
            result_path = original_result_path
            checkpoint_path = original_checkpoint_path
            log_path = original_log_path

        learner.init_json(log_path)
        learner.occurred_class = [0 for i in range(conf.args.opt['num_class'])]

        since = time.time()

        print('##############Source Data Loading...##############')
        set_seed()  # reproducibility
        source_train_data_loader, source_val_data_loader = data_loader.domain_data_loader(conf.args.dataset,
                                                                                          conf.args.src,
                                                                                          conf.args.opt['file_path'],
                                                                                          batch_size=conf.args.opt[
                                                                                              'batch_size'],
                                                                                          valid_split=0,
                                                                                          # to be used for the validation
                                                                                          test_split=0, is_src=True,
                                                                                          num_source=conf.args.num_source)

        print('##############Target Data Loading...##############')
        set_seed()  # reproducibility
        target_data_loader, _ = data_loader.domain_data_loader(conf.args.dataset, corruption,
                                                               conf.args.opt['file_path'],
                                                               batch_size=conf.args.opt['batch_size'],
                                                               valid_split=0,
                                                               test_split=0, is_src=False,
                                                               num_source=conf.args.num_source)

        set_seed()  # reproducibility
        learner.set_target_data(source_train_data_loader, source_val_data_loader, target_data_loader, corruption)

        time_elapsed = time.time() - since
        print('Data Loading Completion time: {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))

        #################### Training #########################     

        since = time.time()

        # make dir if it doesn't exist
        if not os.path.exists(result_path):
            oldumask = os.umask(0)
            os.makedirs(result_path, 0o777)
            os.umask(oldumask)
        if not os.path.exists(checkpoint_path):
            oldumask = os.umask(0)
            os.makedirs(checkpoint_path, 0o777)
            os.umask(oldumask)
        script = ' '.join(sys.argv[1:])

        set_seed()  # reproducibility

        if conf.args.online == False:
            start_epoch = 1
            best_acc = -9999
            best_epoch = -1

            for epoch in range(start_epoch, conf.args.epoch + 1):
                learner.train(epoch)

            learner.save_checkpoint(epoch=0, epoch_acc=-1, best_acc=best_acc,
                                    checkpoint_path=checkpoint_path + 'cp_last.pth.tar')
            learner.dump_eval_online_result(is_train_offline=True)  # eval with final model

            time_elapsed = time.time() - since
            print('Completion time: {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))
            print('Best val Acc: {:4f} at Epoch: {:d}'.format(best_acc, best_epoch))

        elif conf.args.online == True:

            current_num_sample = 1
            num_sample_end = conf.args.nsample
            best_acc = -9999
            best_epoch = -1

            TRAINED = 0
            SKIPPED = 1
            FINISHED = 2

            finished = False

            while not finished and current_num_sample < num_sample_end:

                ret_val = learner.train_online(current_num_sample)

                if ret_val == FINISHED:
                    break
                elif ret_val == SKIPPED:
                    pass
                elif ret_val == TRAINED:
                    pass
                current_num_sample += 1

            if not conf.args.remove_cp:
                learner.save_checkpoint(epoch=0, epoch_acc=-1, best_acc=best_acc,
                                        checkpoint_path=checkpoint_path + 'cp_last.pth.tar')
            learner.dump_eval_online_result()

            time_elapsed = time.time() - since
            print('Completion time: {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))
            print('Best val Acc: {:4f} at Epoch: {:d}'.format(best_acc, best_epoch))

        if conf.args.remove_cp:
            last_path = checkpoint_path + 'cp_last.pth.tar'
            best_path = checkpoint_path + 'cp_best.pth.tar'
            try:
                os.remove(last_path)
                os.remove(best_path)
            except Exception as e:
                pass

def parse_arguments(argv):
    """Command line parse."""

    # Note that 'type=bool' args should be False in default. Any string argument is recognized as "True". Do not give "--bool_arg 0"

    parser = argparse.ArgumentParser()

    ###MANDATORY###

    parser.add_argument('--dataset', type=str, default='',
                        help='Dataset to be used, in [ichar, icsr, dsa, hhar, opportunity, gait, pamap2]')

    parser.add_argument('--model', type=str, default='HHAR_model',
                        help='Which model to use')

    parser.add_argument('--method', type=str, default='',
                        help='specify the method name')

    parser.add_argument('--src', nargs='*', default=None,
                        help='Specify source domains; not passing an arg load default src domains specified in conf.py')
    parser.add_argument('--tgt', type=str, default=None,
                        help='specific target domain; give "src" if you test under src domain')
    parser.add_argument('--gpu_idx', type=int, default=0, help='which gpu to use')

    ###Optional###
    parser.add_argument('--lr', type=float, default=None,
                        help='learning rate to overwrite conf.py')
    parser.add_argument('--weight_decay', type=float, default=None,
                        help='weight_decay to overwrite conf.py')
    parser.add_argument('--seed', type=int, default=0,
                        help='random seed')

    parser.add_argument('--epoch', type=int, default=1,
                        help='How many epochs do you want to use for train')
    parser.add_argument('--load_checkpoint_path', type=str, default='',
                        help='Load checkpoint and train from checkpoint in path?')
    parser.add_argument('--train_max_rows', type=int, default=np.inf,
                        help='How many data do you want to use for train')
    parser.add_argument('--valid_max_rows', type=int, default=np.inf,
                        help='How many data do you want to use for valid')
    parser.add_argument('--test_max_rows', type=int, default=np.inf,
                        help='How many data do you want to use for test')
    parser.add_argument('--nsample', type=int, default=20000000,
                        help='How many samples do you want use for train')
    parser.add_argument('--log_prefix', type=str, default='',
                        help='Prefix of log file path')
    parser.add_argument('--remove_cp', action='store_true',
                        help='Remove checkpoints after evaluation')
    parser.add_argument('--data_gen', action='store_true',
                        help='generate training data with source for training estimator')

    parser.add_argument('--num_source', type=int, default=100,
                        help='number of available sources')
    parser.add_argument('--parallel', type=bool, default=False)
    #### Distribution ####
    parser.add_argument('--tgt_train_dist', type=int, default=1,
                        help='0: real selection'
                             '1: random selection'
                        )
    parser.add_argument('--online', action='store_true', help='training via online learning?')
    parser.add_argument('--update_every_x', type=int, default=1, help='number of target samples used for every update')
    parser.add_argument('--memory_size', type=int, default=1,
                        help='number of previously trained data to be used for training')
    parser.add_argument('--memory_type', type=str, default='FIFO', help='FIFO')

    # CoTTA
    parser.add_argument('--ema_factor', type=float, default=0.999,
                        help='hyperparam for CoTTA')
    parser.add_argument('--restoration_factor', type=float, default=0.01,
                        help='hyperparam for CoTTA')
    parser.add_argument('--aug_threshold', type=float, default=0.92,
                        help='hyperparam for CoTTA')

    # OOD
    parser.add_argument('--outdist', default="original", type=str,
                        help='outdist test data : divide, repeat, oneclassrepeat, cifar100, cifar100c, gaussian, uniform')
    parser.add_argument('--outdist_size', default=None, type=int, help='outdist test data size')
    parser.add_argument('--outdist_class', default=None, nargs="*", type=int, help='outdist target class')

    # SoTTA
    parser.add_argument('--bn_momentum', type=float, default=0.1, help='momentum')
    parser.add_argument('--use_learned_stats', action='store_true', help='Use learned stats')
    parser.add_argument('--temperature', type=float, default=1.0,
                        help='temperature for HLoss')
    parser.add_argument('--loss_scaler', type=float, default=0,
                        help='loss_scaler for entropy_loss')
    parser.add_argument('--validation', action='store_true',
                        help='Use validation data instead of test data for hyperparameter tuning')
    parser.add_argument('--adapt_then_eval', action='store_true',
                        help='Evaluation after adaptation - unrealistic and causing additoinal latency, but common in TTA.')
    parser.add_argument('--no_adapt', action='store_true', help='no adaptation')
    parser.add_argument('--skip_thres', type=int, default=1,
                        help='skip threshold to discard adjustment')

    parser.add_argument('--dummy', action='store_true', default=False, help='do nothing')

    # SAM (currently only supports SoTTA)
    parser.add_argument('--sam', action='store_true', default=False, help='changes Adam to SAM-Adam')

    # eata settings
    parser.add_argument('--fisher_size', default=2000, type=int,
                        help='number of samples to compute fisher information matrix.')
    parser.add_argument('--fisher_alpha', type=float, default=2000.,
                        help='the trade-off between entropy and regularization loss, in Eqn. (8)')
    parser.add_argument('--e_margin', type=float, default=math.log(1000) * 0.40,
                        help='entropy margin E_0 in Eqn. (3) for filtering reliable samples')
    parser.add_argument('--d_margin', type=float, default=0.05,
                        help='\epsilon in Eqn. (5) for filtering redundant samples')

    parser.add_argument('--high_threshold', default=0.99, type=float, help='High confidence threshold')

    parser.add_argument('--reset_function', type=str, default=None,
                        help='reset function for adding Recovery ability to any TTA algorithm')
    
    parser.add_argument('--reset_every_x', default=1, type=int, help='cycle (in batch) of periodic reset')
    
    parser.add_argument('--num_eval_source', default=1000, type=int, help='number of source data used for SrcValidation')

    parser.add_argument('--turn_off_reset', action='store_true', default=False,
                        help="turn off default resetting algorithm, ie SAR and CoTTA")

    parser.add_argument('--acc_est_method', default='', type=str, nargs="*",
                        help='accuracy estimation methods to evaluate')

    parser.add_argument("--dropout_rate", default=-1, type=float, help='dropout rate for dropout inference')

    parser.add_argument('--log_name', type=str, default='log/')
    parser.add_argument('--cont_seq', default=0, type=int, help='switch to various order of cont datastream')
    
    parser.add_argument("--debug", action='store_true', default=False)
    
    return parser.parse_args()


def set_seed():
    torch.manual_seed(conf.args.seed)
    np.random.seed(conf.args.seed)
    random.seed(conf.args.seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    torch.use_deterministic_algorithms(True)


if __name__ == '__main__':
    print('Command:', end='\t')
    print(" ".join(sys.argv))
    conf.args = parse_arguments(sys.argv[1:])
    print(conf.args)
    set_seed()
    if conf.args.debug:
        import debugpy
        debugpy.listen(5678)
        print("wait for debugger")
        debugpy.wait_for_client()
        print("attach")

    main()

File Path: models/ResNet.py
Content:
'''ResNet in PyTorch.
For Pre-activation ResNet, see 'preact_resnet.py'.
Reference:
[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun
    Deep Residual Learning for Image Recognition. arXiv:1512.03385
'''
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision


class BasicBlock(nn.Module):
    expansion = 1

    def __init__(self, in_planes, planes, stride=1):
        super(BasicBlock, self).__init__()
        self.conv1 = nn.Conv2d(
            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(planes)
        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,
                               stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(planes)

        self.shortcut = nn.Sequential()
        if stride != 1 or in_planes != self.expansion*planes:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_planes, self.expansion*planes,
                          kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(self.expansion*planes)
            )

        self.dropout = 0.0

    def forward(self, x):
        out = self.conv1(x)
        out = self.bn1(out)
        out = F.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)
        shortcut = self.shortcut(x)
        out += shortcut
        out = F.relu(out)
        return out


class Bottleneck(nn.Module):
    expansion = 4

    def __init__(self, in_planes, planes, stride=1):
        super(Bottleneck, self).__init__()
        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)
        self.bn1 = nn.BatchNorm2d(planes)
        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,
                               stride=stride, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(planes)
        self.conv3 = nn.Conv2d(planes, self.expansion *
                               planes, kernel_size=1, bias=False)
        self.bn3 = nn.BatchNorm2d(self.expansion*planes)

        self.shortcut = nn.Sequential()
        if stride != 1 or in_planes != self.expansion*planes:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_planes, self.expansion*planes,
                          kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(self.expansion*planes)
            )

        self.dropout = 0.0

    def forward(self, x):
        out = self.conv1(x)
        out = self.bn1(out)
        out = F.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)
        out = F.relu(out)
        out = self.conv3(out)
        out = self.bn3(out)
        shortcut = self.shortcut(x)
        out += shortcut
        out = F.relu(out)
        return out


class ResNet(nn.Module):
    def __init__(self, block, num_blocks, num_classes=10):
        super(ResNet, self).__init__()
        self.in_planes = 64

        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,
                               stride=1, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)
        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)
        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)
        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)
        self.fc = nn.Linear(512*block.expansion, num_classes)

    def _make_layer(self, block, planes, num_blocks, stride):
        strides = [stride] + [1]*(num_blocks-1)
        layers = []
        for stride in strides:
            layers.append(block(self.in_planes, planes, stride))
            self.in_planes = planes * block.expansion
        return nn.Sequential(*layers)

    def forward(self, x, get_embeddings=False, dropout=0.0):
        out = self.conv1(x)
        out = self.bn1(out)
        out = F.relu(out)
        out = self.layer1(out)
        out = F.dropout(out, p=dropout, training=True)
        out = self.layer2(out)
        out = F.dropout(out, p=dropout, training=True)
        out = self.layer3(out)
        out = F.dropout(out, p=dropout, training=True)
        out = self.layer4(out)
        out = F.dropout(out, p=dropout, training=True)
        out = F.avg_pool2d(out, 4)
        embeddings = out.view(out.size(0), -1)
        out = self.fc(embeddings)
        if get_embeddings:
            return out, embeddings
        return out
        


def ResNet18():
    return ResNet(BasicBlock, [2, 2, 2, 2])


def ResNet34():
    return ResNet(BasicBlock, [3, 4, 6, 3])


def ResNet50():
    return ResNet(Bottleneck, [3, 4, 6, 3])


def ResNet101():
    return ResNet(Bottleneck, [3, 4, 23, 3])


def ResNet152():
    return ResNet(Bottleneck, [3, 8, 36, 3])


def test():
    net = ResNet18()
    y = net(torch.randn(1, 3, 32, 32))
    print(y.size())


def ResNetDropout18():
    return ResNetDropout(torchvision.models.resnet.BasicBlock, [2, 2, 2, 2])

def ResNetDropout50():
    return ResNetDropout(torchvision.models.resnet.Bottleneck, [3, 4, 6, 3])


class ResNetDropout(torchvision.models.resnet.ResNet):
    """
    For pretrained ResNet models from Torchvision.
    """
    def __init__(self, block, num_blocks):
        super(ResNetDropout, self).__init__(block, num_blocks)

    def forward(self, x: torch.Tensor, dropout=0.0) -> torch.Tensor:
        # See note [TorchScript super()]
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = F.dropout(x, p=dropout, training=True)
        x = self.layer2(x)
        x = F.dropout(x, p=dropout, training=True)
        x = self.layer3(x)
        x = F.dropout(x, p=dropout, training=True)
        x = self.layer4(x)
        x = F.dropout(x, p=dropout, training=True)

        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.fc(x)

        return x

File Path: models/wide_resnet.py
Content:
import math
import torch
import torch.nn as nn
import torch.nn.functional as F


class BasicBlock(nn.Module):
    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):
        super(BasicBlock, self).__init__()
        self.bn1 = nn.BatchNorm2d(in_planes)
        self.relu1 = nn.ReLU(inplace=True)
        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,
                               padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_planes)
        self.relu2 = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,
                               padding=1, bias=False)
        self.droprate = dropRate
        self.equalInOut = (in_planes == out_planes)
        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,
                                                                padding=0, bias=False) or None

    def forward(self, x):
        if not self.equalInOut:
            x = self.relu1(self.bn1(x))
        else:
            out = self.relu1(self.bn1(x))
        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))
        if self.droprate > 0:
            out = F.dropout(out, p=self.droprate, training=self.training)
        out = self.conv2(out)
        return torch.add(x if self.equalInOut else self.convShortcut(x), out)


class NetworkBlock(nn.Module):
    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):
        super(NetworkBlock, self).__init__()
        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)

    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):
        layers = []
        for i in range(int(nb_layers)):
            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))
        return nn.Sequential(*layers)

    def forward(self, x):
        return self.layer(x)


class WideResNet(nn.Module):
    """ Based on code from https://github.com/yaodongyu/TRADES """
    def __init__(self, depth=28, num_classes=10, widen_factor=10, sub_block1=False, dropRate=0.0, bias_last=True):
        super(WideResNet, self).__init__()
        nChannels = [16, 16 * widen_factor, 32 * widen_factor, 64 * widen_factor]
        assert ((depth - 4) % 6 == 0)
        n = (depth - 4) / 6
        block = BasicBlock
        # 1st conv before any network block
        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,
                               padding=1, bias=False)
        # 1st block
        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)
        if sub_block1:
            # 1st sub-block
            self.sub_block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)
        # 2nd block
        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)
        # 3rd block
        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)
        # global average pooling and classifier
        self.bn1 = nn.BatchNorm2d(nChannels[3])
        self.relu = nn.ReLU(inplace=True)
        self.fc = nn.Linear(nChannels[3], num_classes, bias=bias_last)
        self.nChannels = nChannels[3]

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()
            elif isinstance(m, nn.Linear) and not m.bias is None:
                m.bias.data.zero_()

    def forward(self, x):
        out = self.conv1(x)
        out = self.block1(out)
        out = self.block2(out)
        out = self.block3(out)
        out = self.relu(self.bn1(out))
        out = F.avg_pool2d(out, 8)
        out = out.view(-1, self.nChannels)
        return self.fc(out)


File Path: print_acc.py
Content:
import json
import os
import re
import argparse

import pandas as pd
from multiprocessing import Pool
from functools import partial

from pathlib import Path

# from tabulate import tabulate

CORRUPTION_LIST = ["gaussian_noise", "shot_noise", "impulse_noise", "defocus_blur", "glass_blur", "motion_blur",
                   "zoom_blur", "snow", "frost", "fog", "brightness", "contrast", "elastic_transform", "pixelate",
                   "jpeg_compression"]

# METHOD_LIST = ["Src", "TENT", "PseudoLabel", "BN_Stats", "SAR", "RoTTA", "CoTTA", "LAME", "MEMO", "SoTTA", "EATA"]
METHOD_LIST = ["TENT", "EATA", "SAR", "CoTTA", "RoTTA", "SoTTA"]

BASE_DATASET = "cifar10outdist"

LOG_PREFIX = "eval_results"

SEED_LIST = [0, 1, 2]

DIST = 1

RESET = ""

# TARGET_OUTDIST = ["original", "cifar100", "mnist", "uniform", "repeat"]
TARGET_OUTDIST = ["original"]


def get_avg_online_acc(file_path):
    f = open(file_path)
    json_data = json.load(f)
    f.close()
    return json_data['accuracy'][-1]


def process_path(args, path):
    result = {f"{s}_{t}": pd.DataFrame(columns=CORRUPTION_LIST) for s in args.seed for t in args.outdist}
    method = path.split("/")[-1].replace("_outdist", "")
    for (path, _, _) in os.walk(path):
        for corr in CORRUPTION_LIST:
            for seed in args.seed:
                for outdist in args.outdist:
                    if not args.cont:
                        pattern_of_path = f'.*{corr}.*{outdist}.*/'
                    else:
                        pattern_of_path = f'.*cont_{outdist}.*{args.suffix}.*/'

                    if args.reset:
                        pattern_of_path += f'reset_{args.reset}/'
                    else:
                        if 'reset' in path:
                            continue

                    if method == 'Src':
                        pattern_of_path += f'.*{args.prefix}_.*{seed}.*/'
                    elif 'repeat' in outdist:  # attack
                        if args.dataset in ['cifar10outdist', 'cifar100outdist']:
                            attack = "tta_attack_indiscriminate_num20_step10_eps0.1"
                        elif args.dataset == 'imagenetoutdist':
                            attack = "tta_attack_indiscriminate_num20_step1_eps0.2"
                        else:
                            raise NotImplementedError
                        pattern_of_path += f'{attack}/.*{args.prefix}_.*{seed}_dist{args.dist}.*'
                    else:
                        pattern_of_path += f'{args.prefix}_.*{seed}_dist{args.dist}.*'

                    if args.cont:
                        pattern_of_path += f'{corr}.*'

                    pattern_of_path = re.compile(pattern_of_path)
                    if pattern_of_path.match(path):
                        if not path.endswith('/cp'):  # ignore cp/ dir
                            try:
                                acc = get_avg_online_acc(os.path.join(path, 'online_eval.json'))
                                if not args.cont:
                                    prefix = outdist
                                    path = '/'.join(path.split('/')[:-3])
                                else:
                                    prefix = path.split("/")[-2]
                                    path = '/'.join(path.split('/')[:-2])
                                key = method + "_" + prefix + f"({path})"
                                result[f"{seed}_{outdist}"].loc[key, corr] = float(acc)
                            except Exception as e:
                                pass
    return result


def main(args):
    root = args.root_log + "/" + args.dataset
    paths = [os.path.join(root, f"{method}_outdist") for method in args.method]
    with Pool(processes=len(paths)) as p:
        func = partial(process_path, args)
        results = p.map(func, paths)

    for outdist in args.outdist:
        for seed in args.seed:
            print(f"SEED:{seed}, OUTDIST: {outdist}")
            result = pd.concat([results[i][f"{seed}_{outdist}"] for i in range(len(results))])
            print(result.to_csv())
            result.to_csv(args.save_path + f"/{outdist}_{seed}_{args.dist}.csv")


def parse_arguments():
    """Command line parse."""

    parser = argparse.ArgumentParser()

    parser.add_argument('--dataset', type=str, default=BASE_DATASET,
                        help='Base dataset')

    parser.add_argument('--method', nargs="*", type=str, default=METHOD_LIST,
                        help='Method name')

    parser.add_argument('--seed', nargs="*", type=int, default=SEED_LIST,
                        help='Seed')

    parser.add_argument('--outdist', nargs="*", type=str, default=TARGET_OUTDIST,
                        help='Outdist type')

    parser.add_argument('--prefix', type=str, default=LOG_PREFIX,
                        help='Log prefix')

    parser.add_argument('--dist', type=str, default=DIST,
                        help='Distribution')

    parser.add_argument('--reset', type=str, default=RESET,
                        help='Reset function')

    parser.add_argument('--cont', default=False, action='store_true',
                        help='Continual learning')
    
    parser.add_argument('--root_log', type=str, default="log",
                        help='Reset function')
    
    parser.add_argument('--save_path', type=str, default="csvs",
                        help='Reset function')

    parser.add_argument('--suffix', default="", type=str,
                        help='Suffix for folder name')


    return parser.parse_args()


if __name__ == '__main__':
    args = parse_arguments()
    Path(args.save_path).mkdir(parents=True, exist_ok=True)


    print(
        f"DATASET: {args.dataset}\n"
        f"LOG_PREFIX: {args.prefix}\n"
        f"METHOD: {args.method}\n"
        f"SEED: {args.seed}\n"
        f"OUTDIST: {args.outdist}\n"
        f"DIST: {args.dist}\n"
        f"RESET: {args.reset}\n"
        f"CONTINUAL: {args.cont}\n"
    )

    main(args)

File Path: print_est.py
Content:
import json
import os
import re
import argparse

import numpy as np
import pandas as pd
from multiprocessing import Pool
from functools import partial

CORRUPTION_LIST = ["gaussian_noise", "shot_noise", "impulse_noise", "defocus_blur", "glass_blur", "motion_blur",
                   "zoom_blur", "snow", "frost", "fog", "brightness", "contrast", "elastic_transform", "pixelate",
                   "jpeg_compression"]

METHOD_LIST = ["TENT", "EATA", "SAR", "CoTTA", "RoTTA", "SoTTA"]

BASE_DATASET = "cifar10outdist"

LOG_PREFIX = "eval_results"

SEED_LIST = [0, 1, 2]

DIST = 1

RESET = ""

TARGET_OUTDIST = ["original"]


def get_avg_online_acc(file_path, target):
    with open(file_path) as f:
        json_data = json.load(f)

    to_compare = np.array(json_data[target], dtype=float)
    accuracy = np.array(json_data["current_accuracy"], dtype=float)

    if target != "aetta":
        to_compare *= 100

    mae = np.nanmean(np.abs(accuracy - to_compare))

    return accuracy[-1], mae


def process_path(args, path):
    result = {f"{s}_{t}": pd.DataFrame(columns=CORRUPTION_LIST) for s in args.seed for t in args.outdist}
    method = path.split("/")[-1].replace("_outdist", "")
    for (path, _, _) in os.walk(path):
        for corr in CORRUPTION_LIST:
            for seed in args.seed:
                for outdist in args.outdist:
                    if not args.cont:
                        pattern_of_path = f'.*{corr}.*{outdist}.*/'
                    else:
                        pattern_of_path = f'.*cont_{outdist}.*/'

                    if args.reset:
                        pattern_of_path += f'reset_{args.reset}/'
                    else:
                        if 'reset' in path:
                            continue

                    if method == "SoTTA":
                        if args.dataset == "cifar100outdist":
                            suffix = "_mt0.2_HUS_ht0.66_lr0.001"  # SoTTA
                        elif args.dataset == "cifar10outdist":
                            suffix = "_mt0.2_HUS_ht0.99_lr0.001"  # SoTTA
                        else:
                            suffix = "_mt0.2_HUS_ht0.33_lr0.001"
                    elif method == "RoTTA":
                        suffix = "_mt0.05_CSTU"  # RoTTA
                    else:
                        suffix = ""

                    pattern_of_path += f'{args.prefix}_{seed}_dist{args.dist}{suffix}{args.suffix}'

                    if args.cont:
                        pattern_of_path += f'/{corr}.*'

                    pattern_of_path = re.compile(pattern_of_path)
                    if pattern_of_path.match(path):
                        if not path.endswith('/cp'):  # ignore cp/ dir
                            try:
                                acc, mae = get_avg_online_acc(os.path.join(path, 'online_eval.json'), args.target)
                                if not args.cont:
                                    prefix = outdist
                                    path = path.split('/')[-1]
                                else:
                                    prefix = path.split("/")[-2]
                                    path = '/'.join(path.split('/')[:-2])
                                key = method + "_" + prefix + f"({path})"
                                result[f"{seed}_{outdist}"].loc[key, corr] = float(mae)
                            except Exception as e:
                                pass
    return result


def main(args):
    root = args.log_name + args.dataset
    paths = [os.path.join(root, f"{method}_outdist") for method in args.method]
    with Pool(processes=len(paths)) as p:
        func = partial(process_path, args)
        results = p.map(func, paths)

    for outdist in args.outdist:
        for seed in args.seed:
            print(f"SEED:{seed}, OUTDIST: {outdist}")
            result = pd.concat([results[i][f"{seed}_{outdist}"] for i in range(len(results))]).astype(float).round(3)
            print(result.to_csv())


def parse_arguments():
    """Command line parse."""

    parser = argparse.ArgumentParser()

    parser.add_argument('--dataset', type=str, default=BASE_DATASET,
                        help='Base dataset')

    parser.add_argument('--method', nargs="*", type=str, default=METHOD_LIST,
                        help='Method name')

    parser.add_argument('--seed', nargs="*", type=int, default=SEED_LIST,
                        help='Seed')

    parser.add_argument('--outdist', nargs="*", type=str, default=TARGET_OUTDIST,
                        help='Outdist type')

    parser.add_argument('--prefix', type=str, default=LOG_PREFIX,
                        help='Log prefix')

    parser.add_argument('--dist', type=str, default=DIST,
                        help='Distribution')

    parser.add_argument('--reset', type=str, default=RESET,
                        help='Reset function')

    parser.add_argument('--cont', default=False, action='store_true',
                        help='Continual learning')

    parser.add_argument('--suffix', default="", type=str,
                        help='Suffix for folder name')

    parser.add_argument('--target', default="", type=str,
                        help='Target key to calculate MAE. Example: aetta, softmax_score, gde, src_validation, adv_perturb')

    parser.add_argument('--log_name', default="log/", type=str,
                        help='Name of logging directory')


    return parser.parse_args()


if __name__ == '__main__':
    args = parse_arguments()

    print(
        f"DATASET: {args.dataset}\n"
        f"LOG_PREFIX: {args.prefix}\n"
        f"METHOD: {args.method}\n"
        f"SEED: {args.seed}\n"
        f"OUTDIST: {args.outdist}\n"
        f"DIST: {args.dist}\n"
        f"RESET: {args.reset}\n"
        f"CONTINUAL: {args.cont}\n"
    )

    main(args)

File Path: process_cifar.py
Content:
import os
import sys
import numpy as np
import pickle

severities = [1, 2, 3, 4, 5]
corruptions = ["shot_noise", "motion_blur", "snow", "pixelate", "gaussian_noise", "defocus_blur", "brightness", "fog", \
               "zoom_blur", "frost", "glass_blur", "impulse_noise", "contrast", "jpeg_compression", "elastic_transform"]

def ensure_dir(file_path):
    directory = os.path.dirname(file_path)
    if not os.path.exists(directory):
        os.makedirs(directory)

def reshape(data):
    # original data shape: (N, 3072)
    # reshape the vector into height * weight * channel format
    nchw = data.reshape((data.shape[0], 3, 32, 32))
    nhwc = np.transpose(nchw, (0, 2, 3, 1))
    return nhwc

def get_dirnames(dataset):
    if dataset == "cifar-10c":
        cor_dirname = "CIFAR-10-C"
        org_dirname = "cifar-10-batches-py"
    if dataset == "cifar-100c":
        cor_dirname = "CIFAR-100-C"
        org_dirname = "cifar-100-python"
    return cor_dirname, org_dirname

def load_data(filename):
    with open(filename, 'rb') as f:
        d = pickle.load(f, encoding='bytes')
    return d

def process_corrupted_data(cor_dir):
    '''
    process the downloaded data and save the results into the dedicated directories.
    for cifar-10-c or cifar-100-c, we parse data according to the severity label and save each in the corresponding directory.
    e.g., data of severity level 1 with corruption type 'fog' is saved as "./dataset/corrupted/severity-1/fog.npy"
    cor_dir: directory of corrupted dataset.
    '''
    os.chdir(cor_dir)

    label_all = np.load("labels.npy")

    print("python: processing data...")
    for i, corruption in enumerate(corruptions):
        corruption_file_name = corruption + ".npy"
        data_all = np.load(corruption_file_name)
        for severity in severities:
            data = data_all[(severity - 1) * 10000 : severity * 10000]
            label = label_all[(severity - 1) * 10000 : severity * 10000]
            new_data_dir = "./corrupted/severity-"+str(severity)+"/"+corruption+".npy"
            ensure_dir(new_data_dir)
            np.save(new_data_dir, data)

            if i == 0:
                new_label_dir = "./corrupted/severity-"+str(severity)+"/labels.npy"
                np.save(new_label_dir, label)

def process_original_data(org_dir, dataset):
    '''
    process the downloaded data and save the results into the dedicated directories.
    for cifar 10,
        we read all five batches of train data, concatenate them into a single dataset and save it to the "origin" directory.
        we read a test batch and save it in each severity level directories in 'corrupted' directory.
        e.g., "./dataset/corrupted/severity-1/test.npy"
    for cifar 100,
        we read a train data and save it to the "origin" directory.
        we read a test data and save it in each severity level directories in 'corrupted' directory.
        e.g., "./dataset/corrupted/severity-1/test.npy"
    org_dir: directory of origin dataset.
    dataset: dataset type, "cifar-10c" or "cifar-100c".
    '''
    os.chdir(org_dir)

    if dataset == "cifar-10c":

        # 1. load train data
        files = ["data_batch_1", "data_batch_2", "data_batch_3", "data_batch_4", "data_batch_5"]
        data_list = []
        label_list = []

        for filename in files:
            data_dict = load_data(filename)
            batch_data = data_dict[b'data']
            batch_label = np.asarray(data_dict[b'labels'])
            reshaped_data = reshape(batch_data) # reshape data

            # append data and label to the predefined list
            data_list.append(reshaped_data)
            label_list.append(batch_label)

        # concat data and labels
        data = np.concatenate(np.asarray(data_list), axis=0)
        label = np.concatenate(np.asarray(label_list), axis=0)

        # 2. load test data
        test_file = "test_batch"
        test_data_dict = load_data(test_file)
        test_data = test_data_dict[b'data']
        test_data = reshape(test_data) # reshape data

    else:  # dataset == "cifar-100c"
        # 1. load train data
        data_dict = load_data("train")
        data = data_dict[b'data']
        label = np.asarray(data_dict[b'fine_labels'])
        data = reshape(data) # reshape data

        # 2. load test data
        test_data_dict = load_data("test")
        test_data = test_data_dict[b'data']
        test_data = reshape(test_data) # reshape data

    # save train data
    org_data_dir = f'{cor_dir}/origin'
    if not os.path.exists(org_data_dir):
        os.makedirs(org_data_dir)

    np.save(f"{org_data_dir}/original.npy", data)
    np.save(f"{org_data_dir}/labels.npy", label)

    # save test data in each severity directories in 'corrupted' directory
    for severity in severities:
        save_data_dir = f'{cor_dir}/corrupted/severity-{severity}/test.npy'
        ensure_dir(save_data_dir)
        np.save(save_data_dir, test_data)

    # for severity-all directory, match the data shape
    save_data_dir = f'{cor_dir}/corrupted/severity-all/test.npy'
    ensure_dir(save_data_dir)
    test_data_ = np.concatenate([test_data for i in range(len(severities))], axis=0)
    np.save(save_data_dir, test_data_)


if __name__=="__main__":
    # get directory names to save data
    dataset = sys.argv[1]
    cor_dirname, org_dirname = get_dirnames(dataset)

    # get full directories
    home_dir = os.getcwd()
    cor_dir = f'{home_dir}/dataset/{cor_dirname}'
    org_dir = f'{home_dir}/dataset/{org_dirname}'

    process_corrupted_data(cor_dir) # process corrupted data and save to the dedicated directory
    process_original_data(org_dir, dataset) # process original data and save to the dedicated directory





File Path: utils/augmentation.py
Content:
import numpy as np
import torch
import torch.nn as nn

from PIL import ImageOps, Image
from torchvision import transforms


## https://github.com/google-research/augmix

def _augmix_aug(x_orig, m=None, n_aug=7):
    x_orig = preaugment(x_orig)
    x_processed = preprocess(x_orig)
    w = np.float32(np.random.dirichlet([1.0, 1.0, 1.0]))
    m = np.float32(np.random.beta(1.0, 1.0))
    # m = np.float32(np.random.beta(10.0, 1.0))

    mix = torch.zeros_like(x_processed)
    for i in range(3):
        x_aug = x_orig.copy()
        for _ in range(np.random.randint(1, 4)):
            x_aug = np.random.choice(augmentations)(x_aug, 1.0)
        mix += w[i] * preprocess(x_aug)
    mix = m * x_processed + (1 - m) * mix
    return mix


def autocontrast(pil_img, level=None):
    return ImageOps.autocontrast(pil_img)

def equalize(pil_img, level=None):
    return ImageOps.equalize(pil_img)

def rotate(pil_img, level):
    degrees = int_parameter(rand_lvl(level), 30)
    if np.random.uniform() > 0.5:
        degrees = -degrees
    return pil_img.rotate(degrees, resample=Image.BILINEAR, fillcolor=128)

def solarize(pil_img, level):
    level = int_parameter(rand_lvl(level), 256)
    return ImageOps.solarize(pil_img, 256 - level)

def shear_x(pil_img, level):
    level = float_parameter(rand_lvl(level), 0.3)
    if np.random.uniform() > 0.5:
        level = -level
    return pil_img.transform((32, 32), Image.AFFINE, (1, level, 0, 0, 1, 0), resample=Image.BILINEAR, fillcolor=128)

def shear_y(pil_img, level):
    level = float_parameter(rand_lvl(level), 0.3)
    if np.random.uniform() > 0.5:
        level = -level
    return pil_img.transform((32, 32), Image.AFFINE, (1, 0, 0, level, 1, 0), resample=Image.BILINEAR, fillcolor=128)

def translate_x(pil_img, level):
    level = int_parameter(rand_lvl(level), 32 / 3)
    if np.random.random() > 0.5:
        level = -level
    return pil_img.transform((32, 32), Image.AFFINE, (1, 0, level, 0, 1, 0), resample=Image.BILINEAR, fillcolor=128)

def translate_y(pil_img, level):
    level = int_parameter(rand_lvl(level), 32 / 3)
    if np.random.random() > 0.5:
        level = -level
    return pil_img.transform((32, 32), Image.AFFINE, (1, 0, 0, 0, 1, level), resample=Image.BILINEAR, fillcolor=128)

def posterize(pil_img, level):
    level = int_parameter(rand_lvl(level), 4)
    return ImageOps.posterize(pil_img, 4 - level)


def int_parameter(level, maxval):
    """Helper function to scale `val` between 0 and maxval .
    Args:
    level: Level of the operation that will be between [0, `PARAMETER_MAX`].
    maxval: Maximum value that the operation can have. This will be scaled
      to level/PARAMETER_MAX.
    Returns:
    An int that results from scaling `maxval` according to `level`.
    """
    return int(level * maxval / 10)

def float_parameter(level, maxval):
    """Helper function to scale `val` between 0 and maxval .
    Args:
    level: Level of the operation that will be between [0, `PARAMETER_MAX`].
    maxval: Maximum value that the operation can have. This will be scaled
      to level/PARAMETER_MAX.
    Returns:
    A float that results from scaling `maxval` according to `level`.
    """
    return float(level) * maxval / 10.

def rand_lvl(n):
    return np.random.uniform(low=0.1, high=n)


augmentations = [
    autocontrast,
    equalize,
    rotate,
    solarize,
    shear_x,
    shear_y,
    translate_x,
    translate_y,
    posterize
    # lambda x: rotate(x, 1),
    # lambda x: solarize(x, 1),
    # lambda x: shear_x(x, 1),
    # lambda x: shear_y(x, 1),
    # lambda x: translate_x(x, 1),
    # lambda x: translate_y(x, 1),
    # lambda x: posterize(x, 1),
]

mean = [0.5, 0.5, 0.5]
std = [0.5, 0.5, 0.5]
preprocess = transforms.Compose([
    transforms.ToTensor(),
    # transforms.Normalize(mean, std)
])
preaugment = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(),
])
File Path: utils/bn_layers_rotta.py
Content:
import torch
import torch.nn as nn
from copy import deepcopy


class MomentumBN(nn.Module):
    def __init__(self, bn_layer: nn.BatchNorm2d, momentum):
        super().__init__()
        self.num_features = bn_layer.num_features
        self.momentum = momentum
        if bn_layer.track_running_stats and bn_layer.running_var is not None and bn_layer.running_mean is not None:
            self.register_buffer("source_mean", deepcopy(bn_layer.running_mean))
            self.register_buffer("source_var", deepcopy(bn_layer.running_var))
            self.source_num = bn_layer.num_batches_tracked
        self.weight = deepcopy(bn_layer.weight)
        self.bias = deepcopy(bn_layer.bias)

        self.register_buffer("target_mean", torch.zeros_like(self.source_mean))
        self.register_buffer("target_var", torch.ones_like(self.source_var))
        self.eps = bn_layer.eps

        self.current_mu = None
        self.current_sigma = None

    def forward(self, x):
        raise NotImplementedError


class RobustBN1d(MomentumBN):
    def forward(self, x):
        if self.training:
            b_var, b_mean = torch.var_mean(x, dim=0, unbiased=False, keepdim=False)  # (C,)
            mean = (1 - self.momentum) * self.source_mean + self.momentum * b_mean
            var = (1 - self.momentum) * self.source_var + self.momentum * b_var
            self.source_mean, self.source_var = deepcopy(mean.detach()), deepcopy(var.detach())
            mean, var = mean.view(1, -1), var.view(1, -1)
        else:
            mean, var = self.source_mean.view(1, -1), self.source_var.view(1, -1)

        x = (x - mean) / torch.sqrt(var + self.eps)
        weight = self.weight.view(1, -1)
        bias = self.bias.view(1, -1)

        return x * weight + bias


class RobustBN2d(MomentumBN):
    def forward(self, x):
        if self.training:
            b_var, b_mean = torch.var_mean(x, dim=[0, 2, 3], unbiased=False, keepdim=False)  # (C,)
            mean = (1 - self.momentum) * self.source_mean + self.momentum * b_mean
            var = (1 - self.momentum) * self.source_var + self.momentum * b_var
            self.source_mean, self.source_var = deepcopy(mean.detach()), deepcopy(var.detach())
            mean, var = mean.view(1, -1, 1, 1), var.view(1, -1, 1, 1)
        else:
            mean, var = self.source_mean.view(1, -1, 1, 1), self.source_var.view(1, -1, 1, 1)

        x = (x - mean) / torch.sqrt(var + self.eps)
        weight = self.weight.view(1, -1, 1, 1)
        bias = self.bias.view(1, -1, 1, 1)

        return x * weight + bias

File Path: utils/cotta_utils.py
Content:
# KATANA: Simple Post-Training Robustness Using Test Time Augmentations
# https://arxiv.org/pdf/2109.08191v1.pdf
import PIL
import torch
import torchvision.transforms.functional as F
from torchvision.transforms import ColorJitter, Compose, Lambda
from numpy import random


import torchvision.transforms as transforms


def get_tta_transforms(gaussian_std: float=0.005, soft=False, img_shape=None):
    n_pixels = img_shape[0]

    clip_min, clip_max = 0.0, 1.0

    p_hflip = 0.5

    tta_transforms = transforms.Compose([
        Clip(0.0, 1.0),
        ColorJitterPro(
            brightness=[0.8, 1.2] if soft else [0.6, 1.4],
            contrast=[0.85, 1.15] if soft else [0.7, 1.3],
            saturation=[0.75, 1.25] if soft else [0.5, 1.5],
            hue=[-0.03, 0.03] if soft else [-0.06, 0.06],
            gamma=[0.85, 1.15] if soft else [0.7, 1.3]
        ),
        transforms.Pad(padding=int(n_pixels / 2), padding_mode='edge'),
        transforms.RandomAffine(
            degrees=[-8, 8] if soft else [-15, 15],
            translate=(1/16, 1/16),
            scale=(0.95, 1.05) if soft else (0.9, 1.1),
            shear=None,
            resample=PIL.Image.BILINEAR,
            fillcolor=None
        ),
        transforms.GaussianBlur(kernel_size=5, sigma=[0.001, 0.25] if soft else [0.001, 0.5]),
        transforms.CenterCrop(size=n_pixels),
        transforms.RandomHorizontalFlip(p=p_hflip),
        GaussianNoise(0, gaussian_std),
        Clip(clip_min, clip_max)
    ])
    return tta_transforms

class GaussianNoise(torch.nn.Module):
    def __init__(self, mean=0., std=1.):
        super().__init__()
        self.std = std
        self.mean = mean

    def forward(self, img):
        noise = torch.randn(img.size()) * self.std + self.mean
        noise = noise.to(img.device)
        return img + noise

    def __repr__(self):
        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)

class Clip(torch.nn.Module):
    def __init__(self, min_val=0., max_val=1.):
        super().__init__()
        self.min_val = min_val
        self.max_val = max_val

    def forward(self, img):
        return torch.clip(img, self.min_val, self.max_val)

    def __repr__(self):
        return self.__class__.__name__ + '(min_val={0}, max_val={1})'.format(self.min_val, self.max_val)

class ColorJitterPro(ColorJitter):
    """Randomly change the brightness, contrast, saturation, and gamma correction of an image."""

    def __init__(self, brightness=0, contrast=0, saturation=0, hue=0, gamma=0):
        super().__init__(brightness, contrast, saturation, hue)
        self.gamma = self._check_input(gamma, 'gamma')

    @staticmethod
    @torch.jit.unused
    def get_params(brightness, contrast, saturation, hue, gamma):
        """Get a randomized transform to be applied on image.

        Arguments are same as that of __init__.

        Returns:
            Transform which randomly adjusts brightness, contrast and
            saturation in a random order.
        """
        transforms = []

        if brightness is not None:
            brightness_factor = random.uniform(brightness[0], brightness[1])
            transforms.append(Lambda(lambda img: F.adjust_brightness(img, brightness_factor)))

        if contrast is not None:
            contrast_factor = random.uniform(contrast[0], contrast[1])
            transforms.append(Lambda(lambda img: F.adjust_contrast(img, contrast_factor)))

        if saturation is not None:
            saturation_factor = random.uniform(saturation[0], saturation[1])
            transforms.append(Lambda(lambda img: F.adjust_saturation(img, saturation_factor)))

        if hue is not None:
            hue_factor = random.uniform(hue[0], hue[1])
            transforms.append(Lambda(lambda img: F.adjust_hue(img, hue_factor)))

        if gamma is not None:
            gamma_factor = random.uniform(gamma[0], gamma[1])
            transforms.append(Lambda(lambda img: F.adjust_gamma(img, gamma_factor)))

        random.shuffle(transforms)
        transform = Compose(transforms)

        return transform

    def forward(self, img):
        """
        Args:
            img (PIL Image or Tensor): Input image.

        Returns:
            PIL Image or Tensor: Color jittered image.
        """
        fn_idx = torch.randperm(5)
        for fn_id in fn_idx:
            if fn_id == 0 and self.brightness is not None:
                brightness = self.brightness
                brightness_factor = torch.tensor(1.0).uniform_(brightness[0], brightness[1]).item()
                img = F.adjust_brightness(img, brightness_factor)

            if fn_id == 1 and self.contrast is not None:
                contrast = self.contrast
                contrast_factor = torch.tensor(1.0).uniform_(contrast[0], contrast[1]).item()
                img = F.adjust_contrast(img, contrast_factor)

            if fn_id == 2 and self.saturation is not None:
                saturation = self.saturation
                saturation_factor = torch.tensor(1.0).uniform_(saturation[0], saturation[1]).item()
                img = F.adjust_saturation(img, saturation_factor)

            if fn_id == 3 and self.hue is not None:
                hue = self.hue
                hue_factor = torch.tensor(1.0).uniform_(hue[0], hue[1]).item()
                img = F.adjust_hue(img, hue_factor)

            if fn_id == 4 and self.gamma is not None:
                gamma = self.gamma
                gamma_factor = torch.tensor(1.0).uniform_(gamma[0], gamma[1]).item()
                img = img.clamp(1e-8, 1.0)  # to fix Nan values in gradients, which happens when applying gamma
                                            # after contrast
                img = F.adjust_gamma(img, gamma_factor)

        return img

    def __repr__(self):
        format_string = self.__class__.__name__ + '('
        format_string += 'brightness={0}'.format(self.brightness)
        format_string += ', contrast={0}'.format(self.contrast)
        format_string += ', saturation={0}'.format(self.saturation)
        format_string += ', hue={0})'.format(self.hue)
        format_string += ', gamma={0})'.format(self.gamma)
        return format_string

File Path: utils/custom_transforms.py
Content:
import torch
import torchvision.transforms.functional as F
from torchvision.transforms import ColorJitter, Compose, Lambda
from numpy import random
import PIL
import torchvision.transforms as transforms


def get_tta_transforms(input_shape, gaussian_std: float=0.005, soft=False):
    img_shape = (input_shape[0],input_shape[1], 3)
    n_pixels = img_shape[0]

    clip_min, clip_max = 0.0, 1.0

    p_hflip = 0.5

    tta_transforms = transforms.Compose([
        Clip(0.0, 1.0),
        ColorJitterPro(
            brightness=[0.8, 1.2] if soft else [0.6, 1.4],
            contrast=[0.85, 1.15] if soft else [0.7, 1.3],
            saturation=[0.75, 1.25] if soft else [0.5, 1.5],
            hue=[-0.03, 0.03] if soft else [-0.06, 0.06],
            gamma=[0.85, 1.15] if soft else [0.7, 1.3]
        ),
        transforms.Pad(padding=int(n_pixels / 2), padding_mode='edge'),
        transforms.RandomAffine(
            degrees=[-8, 8] if soft else [-15, 15],
            translate=(1/16, 1/16),
            scale=(0.95, 1.05) if soft else (0.9, 1.1),
            shear=None,
            resample=PIL.Image.BILINEAR,
            fillcolor=None
        ),
        transforms.GaussianBlur(kernel_size=5, sigma=[0.001, 0.25] if soft else [0.001, 0.5]),
        transforms.CenterCrop(size=n_pixels),
        transforms.RandomHorizontalFlip(p=p_hflip),
        GaussianNoise(0, gaussian_std),
        Clip(clip_min, clip_max)
    ])
    return tta_transforms


class GaussianNoise(torch.nn.Module):
    def __init__(self, mean=0., std=1.):
        super().__init__()
        self.std = std
        self.mean = mean

    def forward(self, img):
        noise = torch.randn(img.size()) * self.std + self.mean
        noise = noise.to(img.device)
        return img + noise

    def __repr__(self):
        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)


class Clip(torch.nn.Module):
    def __init__(self, min_val=0., max_val=1.):
        super().__init__()
        self.min_val = min_val
        self.max_val = max_val

    def forward(self, img):
        return torch.clip(img, self.min_val, self.max_val)

    def __repr__(self):
        return self.__class__.__name__ + '(min_val={0}, max_val={1})'.format(self.min_val, self.max_val)


class ColorJitterPro(ColorJitter):
    """Randomly change the brightness, contrast, saturation, and gamma correction of an image."""

    def __init__(self, brightness=0, contrast=0, saturation=0, hue=0, gamma=0):
        super().__init__(brightness, contrast, saturation, hue)
        self.gamma = self._check_input(gamma, 'gamma')

    @staticmethod
    @torch.jit.unused
    def get_params(brightness, contrast, saturation, hue, gamma):
        """Get a randomized transform to be applied on image.

        Arguments are same as that of __init__.

        Returns:
            Transform which randomly adjusts brightness, contrast and
            saturation in a random order.
        """
        transforms = []

        if brightness is not None:
            brightness_factor = random.uniform(brightness[0], brightness[1])
            transforms.append(Lambda(lambda img: F.adjust_brightness(img, brightness_factor)))

        if contrast is not None:
            contrast_factor = random.uniform(contrast[0], contrast[1])
            transforms.append(Lambda(lambda img: F.adjust_contrast(img, contrast_factor)))

        if saturation is not None:
            saturation_factor = random.uniform(saturation[0], saturation[1])
            transforms.append(Lambda(lambda img: F.adjust_saturation(img, saturation_factor)))

        if hue is not None:
            hue_factor = random.uniform(hue[0], hue[1])
            transforms.append(Lambda(lambda img: F.adjust_hue(img, hue_factor)))

        if gamma is not None:
            gamma_factor = random.uniform(gamma[0], gamma[1])
            transforms.append(Lambda(lambda img: F.adjust_gamma(img, gamma_factor)))

        random.shuffle(transforms)
        transform = Compose(transforms)

        return transform

    def forward(self, img):
        """
        Args:
            img (PIL Image or Tensor): Input image.

        Returns:
            PIL Image or Tensor: Color jittered image.
        """
        fn_idx = torch.randperm(5)
        for fn_id in fn_idx:
            if fn_id == 0 and self.brightness is not None:
                brightness = self.brightness
                brightness_factor = torch.tensor(1.0).uniform_(brightness[0], brightness[1]).item()
                img = F.adjust_brightness(img, brightness_factor)

            if fn_id == 1 and self.contrast is not None:
                contrast = self.contrast
                contrast_factor = torch.tensor(1.0).uniform_(contrast[0], contrast[1]).item()
                img = F.adjust_contrast(img, contrast_factor)

            if fn_id == 2 and self.saturation is not None:
                saturation = self.saturation
                saturation_factor = torch.tensor(1.0).uniform_(saturation[0], saturation[1]).item()
                img = F.adjust_saturation(img, saturation_factor)

            if fn_id == 3 and self.hue is not None:
                hue = self.hue
                hue_factor = torch.tensor(1.0).uniform_(hue[0], hue[1]).item()
                img = F.adjust_hue(img, hue_factor)

            if fn_id == 4 and self.gamma is not None:
                gamma = self.gamma
                gamma_factor = torch.tensor(1.0).uniform_(gamma[0], gamma[1]).item()
                img = img.clamp(1e-8, 1.0)  # to fix Nan values in gradients, which happens when applying gamma
                                            # after contrast
                img = F.adjust_gamma(img, gamma_factor)

        return img

    def __repr__(self):
        format_string = self.__class__.__name__ + '('
        format_string += 'brightness={0}'.format(self.brightness)
        format_string += ', contrast={0}'.format(self.contrast)
        format_string += ', saturation={0}'.format(self.saturation)
        format_string += ', hue={0})'.format(self.hue)
        format_string += ', gamma={0})'.format(self.gamma)
        return format_string

File Path: utils/dataaux.py
Content:
import os
from typing import Tuple
# from PIL import Image
import numpy as np

import torch
import torchvision.transforms as transforms
import torchvision.datasets as datasets

# from data.hoi_dataset import BongardDataset
try:
    from torchvision.transforms import InterpolationMode
    BICUBIC = InterpolationMode.BICUBIC
except ImportError:
    BICUBIC = Image.BICUBIC


from PIL import Image, ImageOps, ImageEnhance

# ImageNet code should change this value
IMAGE_SIZE = 224


def int_parameter(level, maxval):
  """Helper function to scale `val` between 0 and maxval .

  Args:
    level: Level of the operation that will be between [0, `PARAMETER_MAX`].
    maxval: Maximum value that the operation can have. This will be scaled to
      level/PARAMETER_MAX.

  Returns:
    An int that results from scaling `maxval` according to `level`.
  """
  return int(level * maxval / 10)


def float_parameter(level, maxval):
  """Helper function to scale `val` between 0 and maxval.

  Args:
    level: Level of the operation that will be between [0, `PARAMETER_MAX`].
    maxval: Maximum value that the operation can have. This will be scaled to
      level/PARAMETER_MAX.

  Returns:
    A float that results from scaling `maxval` according to `level`.
  """
  return float(level) * maxval / 10.


def sample_level(n):
  return np.random.uniform(low=0.1, high=n)


def autocontrast(pil_img, _):
  return ImageOps.autocontrast(pil_img)


def equalize(pil_img, _):
  return ImageOps.equalize(pil_img)


def posterize(pil_img, level):
  level = int_parameter(sample_level(level), 4)
  return ImageOps.posterize(pil_img, 4 - level)


def rotate(pil_img, level):
  degrees = int_parameter(sample_level(level), 30)
  if np.random.uniform() > 0.5:
    degrees = -degrees
  return pil_img.rotate(degrees, resample=Image.BILINEAR)


def solarize(pil_img, level):
  level = int_parameter(sample_level(level), 256)
  return ImageOps.solarize(pil_img, 256 - level)


def shear_x(pil_img, level):
  level = float_parameter(sample_level(level), 0.3)
  if np.random.uniform() > 0.5:
    level = -level
  return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),
                           Image.AFFINE, (1, level, 0, 0, 1, 0),
                           resample=Image.BILINEAR)


def shear_y(pil_img, level):
  level = float_parameter(sample_level(level), 0.3)
  if np.random.uniform() > 0.5:
    level = -level
  return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),
                           Image.AFFINE, (1, 0, 0, level, 1, 0),
                           resample=Image.BILINEAR)


def translate_x(pil_img, level):
  level = int_parameter(sample_level(level), IMAGE_SIZE / 3)
  if np.random.random() > 0.5:
    level = -level
  return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),
                           Image.AFFINE, (1, 0, level, 0, 1, 0),
                           resample=Image.BILINEAR)


def translate_y(pil_img, level):
  level = int_parameter(sample_level(level), IMAGE_SIZE / 3)
  if np.random.random() > 0.5:
    level = -level
  return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),
                           Image.AFFINE, (1, 0, 0, 0, 1, level),
                           resample=Image.BILINEAR)


# operation that overlaps with ImageNet-C's test set
def color(pil_img, level):
    level = float_parameter(sample_level(level), 1.8) + 0.1
    return ImageEnhance.Color(pil_img).enhance(level)


# operation that overlaps with ImageNet-C's test set
def contrast(pil_img, level):
    level = float_parameter(sample_level(level), 1.8) + 0.1
    return ImageEnhance.Contrast(pil_img).enhance(level)


# operation that overlaps with ImageNet-C's test set
def brightness(pil_img, level):
    level = float_parameter(sample_level(level), 1.8) + 0.1
    return ImageEnhance.Brightness(pil_img).enhance(level)


# operation that overlaps with ImageNet-C's test set
def sharpness(pil_img, level):
    level = float_parameter(sample_level(level), 1.8) + 0.1
    return ImageEnhance.Sharpness(pil_img).enhance(level)


augmentations = [
    autocontrast, equalize, posterize, rotate, solarize, shear_x, shear_y,
    translate_x, translate_y
]

augmentations_all = [
    autocontrast, equalize, posterize, rotate, solarize, shear_x, shear_y,
    translate_x, translate_y, color, contrast, brightness, sharpness
]

# AugMix Transforms
def get_preaugment():
    return transforms.Compose([
            transforms.RandomResizedCrop(IMAGE_SIZE),
            transforms.RandomHorizontalFlip(),
        ])

def augmix(image, preprocess, aug_list, severity=1):
    preaugment = get_preaugment()
    x_orig = preaugment(image)
    x_processed = preprocess(x_orig)
    if len(aug_list) == 0:
        return x_processed
    w = np.float32(np.random.dirichlet([1.0, 1.0, 1.0]))
    m = np.float32(np.random.beta(1.0, 1.0))

    mix = torch.zeros_like(x_processed)
    for i in range(3):
        x_aug = x_orig.copy()
        for _ in range(np.random.randint(1, 4)):
            x_aug = np.random.choice(aug_list)(x_aug, severity)
        mix += w[i] * preprocess(x_aug)
    mix = m * x_processed + (1 - m) * mix
    return mix


class AugMixAugmenter(object):
    def __init__(self, base_transform, preprocess, n_views=2, augmix=False, 
                    severity=1):
        self.base_transform = base_transform
        self.preprocess = preprocess
        self.n_views = n_views
        if augmix:
            self.aug_list = augmentations
        else:
            self.aug_list = []
        self.severity = severity
        
    def __call__(self, x):
        image = self.preprocess(self.base_transform(x))
        views = [augmix(x, self.preprocess, self.aug_list, self.severity) for _ in range(self.n_views)]
        return [image] + views




File Path: utils/logging.py
Content:

import numpy as np

# https://stackoverflow.com/questions/10097477/python-json-array-newlines
def to_json(o, level=0, indent=3, space=" ", newline="\n"):
    INDENT = indent
    SPACE = space
    NEWLINE = newline

    ret = ""
    if isinstance(o, dict):
        ret += "{" + NEWLINE
        comma = ""
        for k, v in o.items():
            ret += comma
            comma = ",\n"
            ret += SPACE * INDENT * (level + 1)
            ret += '"' + str(k) + '":' + SPACE
            ret += to_json(v, level + 1)

        ret += NEWLINE + SPACE * INDENT * level + "}"
    elif isinstance(o, str):
        ret += '"' + o + '"'
    elif isinstance(o, list):
        ret += "[" + ",".join([to_json(e, level + 1) for e in o]) + "]"
    # Tuples are interpreted as lists
    elif isinstance(o, tuple):
        ret += "[" + ",".join(to_json(e, level + 1) for e in o) + "]"
    elif isinstance(o, bool):
        ret += "true" if o else "false"
    elif isinstance(o, int):
        ret += str(o)
    elif isinstance(o, float):
        ret += '%.7g' % o
    elif isinstance(o, np.float32):
        ret += '%.7g' % o
    elif isinstance(o, np.ndarray) and np.issubdtype(o.dtype, np.integer):
        ret += "[" + ','.join(map(str, o.flatten().tolist())) + "]"
    elif isinstance(o, np.ndarray) and np.issubdtype(o.dtype, np.inexact):
        ret += "[" + ','.join(map(lambda x: '%.7g' % x, o.flatten().tolist())) + "]"
    elif o is None:
        ret += 'null'
    else:
        raise TypeError("Unknown type '%s' for json serialization" % str(type(o)))
    return ret

File Path: utils/loss_functions.py
Content:
import torch
from torch import nn
import torch.nn.functional as F
import numpy as np


# https://discuss.pytorch.org/t/calculating-the-entropy-loss/14510
# but there is a bug in the original code: it sums up the entropy over a batch. so I take mean instead of sum
class HLoss(nn.Module):
    def __init__(self, temp_factor=1.0):
        super(HLoss, self).__init__()
        self.temp_factor = temp_factor

    def forward(self, x):
        softmax = F.softmax(x / self.temp_factor, dim=1)
        entropy = (-softmax * torch.log(softmax + 1e-6)).sum(dim=1)
        b = entropy.mean()

        return b


@torch.jit.script
def calc_energy(x: torch.Tensor, temp_factor: float = 1.0) -> torch.Tensor:
    return temp_factor * torch.logsumexp(x / temp_factor, dim=1)


class EnergyLoss(nn.Module):
    def __init__(self, temp_factor=1.0):
        super(EnergyLoss, self).__init__()
        self.temp_factor = temp_factor

    def forward(self, x):
        e = calc_energy(x, self.temp_factor)
        # energy = 1.0 / torch.linalg.vector_norm(6.0 - energy, 2)
        e = 1.0 / e.mean()
        return e


class JSDLoss(nn.Module):
    def __init__(self):
        super(JSDLoss, self).__init__()
        self.kl = nn.KLDivLoss(reduction='batchnorm', log_target=True)

    def forward(self, p: torch.tensor, q: torch.tensor):
        p = F.softmax(p, dim=1)
        q = F.softmax(q, dim=1)
        p, q = p.view(-1, p.size(-1)), q.view(-1, q.size(-1))
        m = (0.5 * (p + q)).log()
        return 0.5 * (self.kl(m, p.log()) + self.kl(m, q.log()))


def marginal_entropy(outputs):
    logits = outputs - outputs.logsumexp(dim=-1, keepdim=True)
    avg_logits = logits.logsumexp(dim=0) - np.log(logits.shape[0])
    min_real = torch.finfo(avg_logits.dtype).min
    avg_logits = torch.clamp(avg_logits, min=min_real)
    return -(avg_logits * torch.exp(avg_logits)).sum(dim=-1), avg_logits


@torch.jit.script
def softmax_entropy(x: torch.Tensor) -> torch.Tensor:
    """Entropy of softmax distribution from logits."""
    softmax = x.softmax(1)
    return -(softmax * torch.log(softmax + 1e-6)).sum(1)

@torch.jit.script
def softmax_entropy_rotta(x, x_ema):
    return -(x_ema.softmax(1) * x.log_softmax(1)).sum(1)


def JSD(p: torch.tensor, q: torch.tensor):
    p = F.softmax(p, dim=1)
    q = F.softmax(q, dim=1)
    p, q = p.view(-1, p.size(-1)), q.view(-1, q.size(-1))
    m = (0.5 * (p + q)).log()
    return torch.sum(0.5 * (F.kl_div(m, p.log(), reduction='none', log_target=True) +
                            F.kl_div(m, q.log(), reduction='none', log_target=True)), dim=1)


File Path: utils/memory.py
Content:
import random

import numpy as np
import torch

import conf

device = torch.device("cuda:{:d}".format(conf.args.gpu_idx) if torch.cuda.is_available() else "cpu")
torch.cuda.set_device(
    conf.args.gpu_idx)  # this prevents unnecessary gpu memory allocation to cuda:0 when using estimator


class FIFO:
    def __init__(self, capacity):
        self.data = [[], [], []]
        self.capacity = capacity
        pass

    def set_memory(self, state_dict):  # for tta_attack
        self.data = [ls[:] for ls in state_dict['data']]
        if 'capacity' in state_dict.keys():
            self.capacity = state_dict['capacity']

    def save_state_dict(self):
        dic = {}
        dic['data'] = [ls[:] for ls in self.data]
        dic['capacity'] = self.capacity
        return dic

    def get_memory(self):
        return self.data

    def get_occupancy(self):
        return len(self.data[0])

    def add_instance(self, instance):
        assert (len(instance) == 3)

        if self.get_occupancy() >= self.capacity:
            self.remove_instance()

        for i, dim in enumerate(self.data):
            dim.append(instance[i])

    def remove_instance(self):
        for dim in self.data:
            dim.pop(0)
        pass

    def reset(self):
        self.data = [[], [], []]


class HUS:
    def __init__(self, capacity, threshold=None, num_class=None):
        self.data = [[[], [], [], []] for _ in
                     range(num_class)]  # feat, pseudo_cls, domain, conf
        self.counter = [0] * num_class
        self.marker = [''] * num_class
        self.capacity = capacity
        self.threshold = threshold
        self.num_class = num_class

    def set_memory(self, state_dict):  # for tta_attack
        self.data = [[l[:] for l in ls] for ls in state_dict['data']]
        self.counter = state_dict['counter'][:]
        self.marker = state_dict['marker'][:]
        self.capacity = state_dict['capacity']
        self.threshold = state_dict['threshold']
        self.num_class = state_dict['num_class']

    def save_state_dict(self):
        dic = {}
        dic['data'] = [[l[:] for l in ls] for ls in self.data]
        dic['counter'] = self.counter[:]
        dic['marker'] = self.marker[:]
        dic['capacity'] = self.capacity
        dic['threshold'] = self.threshold
        dic['num_class'] = self.num_class

        return dic

    def print_class_dist(self):
        print(self.get_occupancy_per_class())

    def print_real_class_dist(self):
        occupancy_per_class = [0] * self.num_class
        for i, data_per_cls in enumerate(self.data):
            for cls in data_per_cls[3]:
                occupancy_per_class[cls] += 1
        print(occupancy_per_class)

    def get_memory(self):
        data = self.data

        tmp_data = [[], [], []]
        for data_per_cls in data:
            feats, cls, dls, _ = data_per_cls
            tmp_data[0].extend(feats)
            tmp_data[1].extend(cls)
            tmp_data[2].extend(dls)

        return tmp_data

    def get_occupancy(self):
        occupancy = 0
        for data_per_cls in self.data:
            occupancy += len(data_per_cls[0])
        return occupancy

    def get_occupancy_per_class(self):
        occupancy_per_class = [0] * self.num_class
        for i, data_per_cls in enumerate(self.data):
            occupancy_per_class[i] = len(data_per_cls[0])
        return occupancy_per_class

    def add_instance(self, instance):
        assert (len(instance) == 4)
        cls = instance[1]
        self.counter[cls] += 1
        is_add = True

        if self.threshold is not None and instance[3] < self.threshold:
            is_add = False
        elif self.get_occupancy() >= self.capacity:
            is_add = self.remove_instance(cls)

        if is_add:
            for i, dim in enumerate(self.data[cls]):
                dim.append(instance[i])

    def get_largest_indices(self):
        occupancy_per_class = self.get_occupancy_per_class()
        max_value = max(occupancy_per_class)
        largest_indices = []
        for i, oc in enumerate(occupancy_per_class):
            if oc == max_value:
                largest_indices.append(i)
        return largest_indices

    def get_average_confidence(self):
        conf_list = []
        for i, data_per_cls in enumerate(self.data):
            for confidence in data_per_cls[3]:
                conf_list.append(confidence)
        if len(conf_list) > 0:
            return np.average(conf_list)
        else:
            return 0

    def get_target_index(self, data):
        return random.randrange(0, len(data))

    def remove_instance(self, cls):
        largest_indices = self.get_largest_indices()
        if cls not in largest_indices:  # instance is stored in the place of another instance that belongs to the largest class
            largest = random.choice(largest_indices)  # select only one largest class
            tgt_idx = self.get_target_index(self.data[largest][0])
            for dim in self.data[largest]:
                dim.pop(tgt_idx)
        else:  # replaces a randomly selected stored instance of the same class
            tgt_idx = self.get_target_index(self.data[cls][0])
            for dim in self.data[cls]:
                dim.pop(tgt_idx)
        return True

    def reset_value(self, feats, cls, aux):
        self.data = [[[], [], [], []] for _ in range(self.num_class)]  # feat, pseudo_cls, domain, conf

        for i in range(len(feats)):
            tgt_idx = cls[i]
            self.data[tgt_idx][0].append(feats[i])
            self.data[tgt_idx][1].append(cls[i])
            self.data[tgt_idx][2].append(0)
            self.data[tgt_idx][3].append(aux[i])

    def reset(self):
        self.data = [[[], [], [], []] for _ in range(self.num_class)]  # feat, pseudo_cls, domain, conf


class ConfFIFO:
    def __init__(self, capacity, threshold):
        self.data = [[], [], [], []]
        self.capacity = capacity
        self.threshold = threshold
        pass

    def set_memory(self, state_dict):  # for tta_attack
        self.data = [ls[:] for ls in state_dict['data']]
        self.threshold = state_dict['threshold']
        if 'capacity' in state_dict.keys():
            self.capacity = state_dict['capacity']

    def save_state_dict(self):
        dic = {}
        dic['data'] = [ls[:] for ls in self.data]
        dic['capacity'] = self.capacity
        dic['threshold'] = self.threshold
        return dic

    def get_memory(self):
        return self.data[:3]

    def get_occupancy(self):
        return len(self.data[0])

    def add_instance(self, instance):
        assert (len(instance) == 4)

        if instance[3] < self.threshold:
            return

        if self.get_occupancy() >= self.capacity:
            self.remove_instance()

        for i, dim in enumerate(self.data):
            dim.append(instance[i])

    def remove_instance(self):
        for dim in self.data:
            dim.pop(0)
        pass

    def reset_value(self, feats, cls, aux):
        self.data = [[], [], [], []]

    def reset(self):
        self.data = [[], [], [], []]


class ReplayMemory:
    def __init__(self, batch_size, interval):
        self.batch_size = batch_size
        self.interval = interval
        self.features = None
        self.pseudo_labels = None
        self.confidences = None

    def get_memory(self):
        return self.features, self.pseudo_labels, self.confidences

    def pop_memory(self):
        target_size = [self.batch_size, len(self.features) - self.batch_size]
        feats, self.features = torch.split(self.features, target_size)
        pls, self.pseudo_labels = torch.split(self.pseudo_labels, target_size)
        confs, self.confidences = torch.split(self.confidences, target_size)
        return feats, pls, confs

    def add_instance(self, instance):
        """
        Assumes incoming features and pseudo_labels are in shape of (B, ...) and (B, N)
        """
        assert (len(instance) == 3)  # features, pseudo_labels
        self.features = torch.cat((self.features, instance[0])) if self.features is not None else instance[0]
        self.pseudo_labels = torch.cat((self.pseudo_labels, instance[1])) if self.pseudo_labels is not None else instance[1]
        self.confidences = torch.cat((self.confidences, instance[2])) if self.confidences is not None else instance[2]

    def reset(self):
        self.features = None
        self.pseudo_labels = None
        self.confidences = None


class Uniform:
    def __init__(self, capacity, num_class = None):
        self.data = [[[], [], [], []] for _ in
                     range(num_class)]  # feat, pseudo_cls, domain, conf
        self.counter = [0] * num_class
        self.marker = [''] * num_class
        self.capacity = capacity
        self.threshold = 0.0
        self.num_class = num_class

    def set_memory(self, state_dict):  # for tta_attack
        self.data = [[l[:] for l in ls] for ls in state_dict['data']]
        self.counter = state_dict['counter'][:]
        self.marker = state_dict['marker'][:]
        self.capacity = state_dict['capacity']
        self.threshold = state_dict['threshold']
        self.num_class = state_dict['num_class']
    def save_state_dict(self):
        dic = {}
        dic['data'] = [[l[:] for l in ls] for ls in self.data]
        dic['counter'] = self.counter[:]
        dic['marker'] = self.marker[:]
        dic['capacity'] = self.capacity
        dic['threshold'] = self.threshold
        dic['num_class'] = self.num_class

        return dic

    def print_class_dist(self):
        print(self.get_occupancy_per_class())

    def print_real_class_dist(self):
        occupancy_per_class = [0] * self.num_class
        for i, data_per_cls in enumerate(self.data):
            for cls in data_per_cls[3]:
                occupancy_per_class[cls] += 1
        print(occupancy_per_class)

    def get_memory(self):
        data = self.data

        tmp_data = [[], [], []]
        for data_per_cls in data:
            feats, cls, dls, _ = data_per_cls
            tmp_data[0].extend(feats)
            tmp_data[1].extend(cls)
            tmp_data[2].extend(dls)

        return tmp_data

    def get_occupancy(self):
        occupancy = 0
        for data_per_cls in self.data:
            occupancy += len(data_per_cls[0])
        return occupancy

    def get_occupancy_per_class(self):
        occupancy_per_class = [0] * self.num_class
        for i, data_per_cls in enumerate(self.data):
            occupancy_per_class[i] = len(data_per_cls[0])
        return occupancy_per_class

    def add_instance(self, instance):
        assert (len(instance) == 4)
        cls = instance[1]
        self.counter[cls] += 1
        is_add = True

        if self.threshold is not None and instance[3] < self.threshold:
            is_add = False
        elif self.get_occupancy() >= self.capacity:
            is_add = self.remove_instance(cls)

        if is_add:
            for i, dim in enumerate(self.data[cls]):
                dim.append(instance[i])

    def get_largest_indices(self):
        occupancy_per_class = self.get_occupancy_per_class()
        max_value = max(occupancy_per_class)
        largest_indices = []
        for i, oc in enumerate(occupancy_per_class):
            if oc == max_value:
                largest_indices.append(i)
        return largest_indices

    def get_average_confidence(self):
        conf_list = []
        for i, data_per_cls in enumerate(self.data):
            for confidence in data_per_cls[3]:
                conf_list.append(confidence)
        if len(conf_list) > 0:
            return np.average(conf_list)
        else:
            return 0

    def get_target_index(self, data):
        return random.randrange(0, len(data))

    def remove_instance(self, cls):
        largest_indices = self.get_largest_indices()
        if cls not in largest_indices:  # instance is stored in the place of another instance that belongs to the largest class
            largest = random.choice(largest_indices)  # select only one largest class
            tgt_idx = self.get_target_index(self.data[largest][0])
            for dim in self.data[largest]:
                dim.pop(tgt_idx)
        else:  # replaces a randomly selected stored instance of the same class
            tgt_idx = self.get_target_index(self.data[cls][0])
            for dim in self.data[cls]:
                dim.pop(tgt_idx)
        return True

    def reset_value(self, feats, cls, aux):
        self.data = [[[], [], [], []] for _ in range(self.num_class)]  # feat, pseudo_cls, domain, conf

        for i in range(len(feats)):
            tgt_idx = cls[i]
            self.data[tgt_idx][0].append(feats[i])
            self.data[tgt_idx][1].append(cls[i])
            self.data[tgt_idx][2].append(0)
            self.data[tgt_idx][3].append(aux[i])

    def reset(self):
        self.data = [[[], [], [], []] for _ in range(self.num_class)]  # feat, pseudo_cls, domain, conf

class PBRS():

    def __init__(self, capacity, num_class=None):
        self.data = [[[], [], []] for _ in range(num_class)] #feat, pseudo_cls, domain, cls, loss
        self.counter = [0] * num_class
        self.marker = [''] * num_class
        self.capacity = capacity
        self.num_class = num_class

    def reset(self):
        self.data = [[[], [], []] for _ in range(self.num_class)] #feat, pseudo_cls, domain, cls, loss

    def print_class_dist(self):

        print(self.get_occupancy_per_class())
    def print_real_class_dist(self):

        occupancy_per_class = [0] * self.num_class
        for i, data_per_cls in enumerate(self.data):
            for cls in data_per_cls[3]:
                occupancy_per_class[cls] +=1
        print(occupancy_per_class)

    def get_memory(self):

        data = self.data

        tmp_data = [[], [], []]
        for data_per_cls in data:
            feats, cls, dls = data_per_cls
            tmp_data[0].extend(feats)
            tmp_data[1].extend(cls)
            tmp_data[2].extend(dls)

        return tmp_data

    def get_occupancy(self):
        occupancy = 0
        for data_per_cls in self.data:
            occupancy += len(data_per_cls[0])
        return occupancy

    def get_occupancy_per_class(self):
        occupancy_per_class = [0] * self.num_class
        for i, data_per_cls in enumerate(self.data):
            occupancy_per_class[i] = len(data_per_cls[0])
        return occupancy_per_class

    def update_loss(self, loss_list):
        for data_per_cls in self.data:
            feats, cls, dls, _, losses = data_per_cls
            for i in range(len(losses)):
                losses[i] = loss_list.pop(0)

    def add_instance(self, instance):
        assert (len(instance) == 4)
        cls = instance[1]
        self.counter[cls] += 1
        is_add = True

        if self.get_occupancy() >= self.capacity:
            is_add = self.remove_instance(cls)

        if is_add:
            for i, dim in enumerate(self.data[cls]):
                dim.append(instance[i])

    def get_largest_indices(self):

        occupancy_per_class = self.get_occupancy_per_class()
        max_value = max(occupancy_per_class)
        largest_indices = []
        for i, oc in enumerate(occupancy_per_class):
            if oc == max_value:
                largest_indices.append(i)
        return largest_indices

    def remove_instance(self, cls):
        largest_indices = self.get_largest_indices()
        if cls not in largest_indices: #  instance is stored in the place of another instance that belongs to the largest class
            largest = random.choice(largest_indices)  # select only one largest class
            tgt_idx = random.randrange(0, len(self.data[largest][0]))  # target index to remove
            for dim in self.data[largest]:
                dim.pop(tgt_idx)
        else:# replaces a randomly selected stored instance of the same class
            m_c = self.get_occupancy_per_class()[cls]
            n_c = self.counter[cls]
            u = random.uniform(0, 1)
            if u <= m_c / n_c:
                tgt_idx = random.randrange(0, len(self.data[cls][0]))  # target index to remove
                for dim in self.data[cls]:
                    dim.pop(tgt_idx)
            else:
                return False
        return True

File Path: utils/memory_rotta.py
Content:
import random
import copy
import torch
import torch.nn.functional as F
import numpy as np
import math
from copy import deepcopy

class MemoryItem:
    def __init__(self, data=None, uncertainty=0, age=0):
        self.data = data
        self.uncertainty = uncertainty
        self.age = age

    def increase_age(self):
        if not self.empty():
            self.age += 1

    def get_data(self):
        return self.data, self.uncertainty, self.age

    def empty(self):
        return self.data == "empty"


class CSTU:
    def __init__(self, capacity, num_class, lambda_t=1.0, lambda_u=1.0):
        self.capacity = capacity
        self.num_class = num_class
        self.per_class = self.capacity / self.num_class
        self.lambda_t = lambda_t
        self.lambda_u = lambda_u

        self.data: list[list[MemoryItem]] = [[] for _ in range(self.num_class)]

    def reset(self):
        self.data: list[list[MemoryItem]] = [[] for _ in range(self.num_class)]
    
    def set_memory(self, state_dict): # for tta_attack
        self.capacity = state_dict['capacity']
        self.num_class = state_dict['num_class']
        self.per_class = state_dict['per_class']
        self.lambda_t = state_dict['lambda_t']
        self.lambda_u = state_dict['lambda_u']
        self.data = [ls[:] for ls in state_dict['data']]

    def save_state_dict(self):
        dic = {}
        dic['capacity'] = self.capacity
        dic['num_class'] = self.num_class
        dic['per_class'] = self.per_class
        dic['lambda_t'] = self.lambda_t
        dic['lambda_u'] = self.lambda_u
        dic['data'] = [ls[:] for ls in self.data]

        return dic

    def get_occupancy(self):
        occupancy = 0
        for data_per_cls in self.data:
            occupancy += len(data_per_cls)
        return occupancy

    def per_class_dist(self):
        per_class_occupied = [0] * self.num_class
        for cls, class_list in enumerate(self.data):
            per_class_occupied[cls] = len(class_list)

        return per_class_occupied

    def add_instance(self, instance):
        assert (len(instance) == 3)
        x, prediction, uncertainty = instance
        new_item = MemoryItem(data=x, uncertainty=uncertainty, age=0)
        new_score = self.heuristic_score(0, uncertainty)
        if self.remove_instance(prediction, new_score):
            self.data[prediction].append(new_item)
        self.add_age()

    def remove_instance(self, cls, score):
        class_list = self.data[cls]
        class_occupied = len(class_list)
        all_occupancy = self.get_occupancy()
        if all_occupancy < self.capacity:
            return True
        if class_occupied < self.per_class:
            majority_classes = self.get_majority_classes()
            return self.remove_from_classes(majority_classes, score)
        else:
            return self.remove_from_classes([cls], score)

    def remove_from_classes(self, classes: list[int], score_base):
        max_class = None
        max_index = None
        max_score = None
        for cls in classes:
            for idx, item in enumerate(self.data[cls]):
                uncertainty = item.uncertainty
                age = item.age
                score = self.heuristic_score(age=age, uncertainty=uncertainty)
                if max_score is None or score >= max_score:
                    max_score = score
                    max_index = idx
                    max_class = cls

        if max_class is not None:
            if max_score > score_base:
                self.data[max_class].pop(max_index)
                return True
            else:
                return False
        else:
            return True

    def get_majority_classes(self):
        per_class_dist = self.per_class_dist()
        max_occupied = max(per_class_dist)
        classes = []
        for i, occupied in enumerate(per_class_dist):
            if occupied == max_occupied:
                classes.append(i)

        return classes

    def heuristic_score(self, age, uncertainty):
        return self.lambda_t * 1 / (1 + math.exp(-age / self.capacity)) + self.lambda_u * uncertainty / math.log(self.num_class)

    def add_age(self):
        for class_list in self.data:
            for item in class_list:
                item.increase_age()
        return

    def get_memory(self):
        tmp_data = []
        tmp_age = []

        for class_list in self.data:
            for item in class_list:
                tmp_data.append(item.data)
                tmp_age.append(item.age)

        tmp_age = [x / self.capacity for x in tmp_age]

        return tmp_data, tmp_age


File Path: utils/my_transforms.py
Content:
# KATANA: Simple Post-Training Robustness Using Test Time Augmentations
# https://arxiv.org/pdf/2109.08191v1.pdf
import torch
import torchvision.transforms.functional as F
from torchvision.transforms import ColorJitter, Compose, Lambda
from numpy import random

class GaussianNoise(torch.nn.Module):
    def __init__(self, mean=0., std=1.):
        super().__init__()
        self.std = std
        self.mean = mean

    def forward(self, img):
        noise = torch.randn(img.size()) * self.std + self.mean
        noise = noise.to(img.device)
        return img + noise

    def __repr__(self):
        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)

class Clip(torch.nn.Module):
    def __init__(self, min_val=0., max_val=1.):
        super().__init__()
        self.min_val = min_val
        self.max_val = max_val

    def forward(self, img):
        return torch.clip(img, self.min_val, self.max_val)

    def __repr__(self):
        return self.__class__.__name__ + '(min_val={0}, max_val={1})'.format(self.min_val, self.max_val)

class ColorJitterPro(ColorJitter):
    """Randomly change the brightness, contrast, saturation, and gamma correction of an image."""

    def __init__(self, brightness=0, contrast=0, saturation=0, hue=0, gamma=0):
        super().__init__(brightness, contrast, saturation, hue)
        self.gamma = self._check_input(gamma, 'gamma')

    @staticmethod
    @torch.jit.unused
    def get_params(brightness, contrast, saturation, hue, gamma):
        """Get a randomized transform to be applied on image.

        Arguments are same as that of __init__.

        Returns:
            Transform which randomly adjusts brightness, contrast and
            saturation in a random order.
        """
        transforms = []

        if brightness is not None:
            brightness_factor = random.uniform(brightness[0], brightness[1])
            transforms.append(Lambda(lambda img: F.adjust_brightness(img, brightness_factor)))

        if contrast is not None:
            contrast_factor = random.uniform(contrast[0], contrast[1])
            transforms.append(Lambda(lambda img: F.adjust_contrast(img, contrast_factor)))

        if saturation is not None:
            saturation_factor = random.uniform(saturation[0], saturation[1])
            transforms.append(Lambda(lambda img: F.adjust_saturation(img, saturation_factor)))

        if hue is not None:
            hue_factor = random.uniform(hue[0], hue[1])
            transforms.append(Lambda(lambda img: F.adjust_hue(img, hue_factor)))

        if gamma is not None:
            gamma_factor = random.uniform(gamma[0], gamma[1])
            transforms.append(Lambda(lambda img: F.adjust_gamma(img, gamma_factor)))

        random.shuffle(transforms)
        transform = Compose(transforms)

        return transform

    def forward(self, img):
        """
        Args:
            img (PIL Image or Tensor): Input image.

        Returns:
            PIL Image or Tensor: Color jittered image.
        """
        fn_idx = torch.randperm(5)
        for fn_id in fn_idx:
            if fn_id == 0 and self.brightness is not None:
                brightness = self.brightness
                brightness_factor = torch.tensor(1.0).uniform_(brightness[0], brightness[1]).item()
                img = F.adjust_brightness(img, brightness_factor)

            if fn_id == 1 and self.contrast is not None:
                contrast = self.contrast
                contrast_factor = torch.tensor(1.0).uniform_(contrast[0], contrast[1]).item()
                img = F.adjust_contrast(img, contrast_factor)

            if fn_id == 2 and self.saturation is not None:
                saturation = self.saturation
                saturation_factor = torch.tensor(1.0).uniform_(saturation[0], saturation[1]).item()
                img = F.adjust_saturation(img, saturation_factor)

            if fn_id == 3 and self.hue is not None:
                hue = self.hue
                hue_factor = torch.tensor(1.0).uniform_(hue[0], hue[1]).item()
                img = F.adjust_hue(img, hue_factor)

            if fn_id == 4 and self.gamma is not None:
                gamma = self.gamma
                gamma_factor = torch.tensor(1.0).uniform_(gamma[0], gamma[1]).item()
                img = img.clamp(1e-8, 1.0)  # to fix Nan values in gradients, which happens when applying gamma
                                            # after contrast
                img = F.adjust_gamma(img, gamma_factor)

        return img

    def __repr__(self):
        format_string = self.__class__.__name__ + '('
        format_string += 'brightness={0}'.format(self.brightness)
        format_string += ', contrast={0}'.format(self.contrast)
        format_string += ', saturation={0}'.format(self.saturation)
        format_string += ', hue={0})'.format(self.hue)
        format_string += ', gamma={0})'.format(self.gamma)
        return format_string

File Path: utils/normalize_layer.py
Content:
import torch

_CIFAR10_MEAN = [0.4914, 0.4822, 0.4465]
_CIFAR10_STDDEV = [0.2471, 0.2435, 0.2616]

_CIFAR100_MEAN = [0.5071, 0.4865, 0.4409]
_CIFAR100_STDDEV = [0.2673, 0.2564, 0.2762]

_IMAGENET_MEAN = [0.485, 0.456, 0.406]
_IMAGENET_STDDEV = [0.229, 0.224, 0.225]

class NormalizeLayer(torch.nn.Module):
    """Standardize the channels of a batch of images by subtracting the dataset mean
      and dividing by the dataset standard deviation.
      """

    def __init__(self, means, sds):
        """
        :param means: the channel means
        :param sds: the channel standard deviations
        """
        super(NormalizeLayer, self).__init__()
        self.register_buffer(
            'mu', torch.tensor(means).view(-1, 1, 1))
        self.register_buffer(
            'sigma', torch.tensor(sds).view(-1, 1, 1))

    def forward(self, input: torch.tensor):
        return (input - self.mu) / self.sigma


def get_normalize_layer(dataset):
    """Return the dataset's normalization layer"""
    if dataset in ["cifar10", "cifar10outdist"]:
        return NormalizeLayer(_CIFAR10_MEAN, _CIFAR10_STDDEV)
    elif dataset in ["cifar100", "cifar100outdist"]:
        return NormalizeLayer(_CIFAR100_MEAN, _CIFAR100_STDDEV)
    elif dataset in ['imagenet', 'imagenetoutdist', 'imagenetR']:
        return NormalizeLayer(_IMAGENET_MEAN, _IMAGENET_STDDEV)
    else:
        return None


def get_normalize_std(dataset):
    """Return the dataset's normalization layer"""
    if dataset in ["cifar10", "cifar10outdist"]:
        return _CIFAR10_STDDEV
    elif dataset in ["cifar100", "cifar100outdist"]:
        return _CIFAR100_MEAN, _CIFAR100_STDDEV
    elif dataset in ['imagenet', 'imagenetoutdist', 'imagenetR']:
        return _IMAGENET_MEAN, _IMAGENET_STDDEV
    else:
        return None

File Path: utils/reset_utils.py
Content:
import torch
from copy import deepcopy


def load_model_and_optimizer(model, optimizer, model_state, optimizer_state):
    """Restore the model and optimizer states from copies."""
    model.load_state_dict(model_state, strict=True)
    optimizer.load_state_dict(optimizer_state)


def copy_model_and_optimizer(model, optimizer):
    """Copy the model and optimizer states for resetting after adaptation."""
    model_state = deepcopy(model.state_dict())
    optimizer_state = deepcopy(optimizer.state_dict())
    return model_state, optimizer_state


def update_ema(ema, new_data):
    if ema is None:
        return new_data
    else:
        with torch.no_grad():
            return 0.9 * ema + (1 - 0.9) * new_data


def find_quantile(arr, perc):
    arr_sorted = torch.sort(arr).values
    frac_idx = perc * (len(arr_sorted) - 1)
    frac_part = frac_idx - int(frac_idx)
    low_idx = int(frac_idx)
    high_idx = low_idx + 1
    quant = arr_sorted[low_idx] + (arr_sorted[high_idx] - arr_sorted[low_idx]) * frac_part  # linear interpolation

    return quant

File Path: utils/sam_optimizer.py
Content:
"""
from https://github.com/davda54/sam
"""

import torch
from torch import nn


def sam_collect_params(model):
    """Collect the affine scale + shift parameters from norm layers.
    Walk the model's modules and collect all normalization parameters.
    Return the parameters and their names.
    Note: other choices of parameterization are possible!
    """
    params = []
    names = []
    for nm, m in model.named_modules():
        # skip top layers for adaptation: layer4 for ResNets and blocks9-11 for Vit-Base
        if 'layer4' in nm:
            continue
        if 'blocks.9' in nm:
            continue
        if 'blocks.10' in nm:
            continue
        if 'blocks.11' in nm:
            continue
        if 'norm.' in nm:
            continue
        if nm in ['norm']:
            continue

        if isinstance(m, (nn.BatchNorm2d, nn.LayerNorm, nn.GroupNorm)):
            for np, p in m.named_parameters():
                if np in ['weight', 'bias']:  # weight is scale, bias is shift
                    params.append(p)
                    names.append(f"{nm}.{np}")

    return params, names


class SAM(torch.optim.Optimizer):
    def __init__(self, params, base_optimizer, rho=0.05, adaptive=False, **kwargs):
        assert rho >= 0.0, f"Invalid rho, should be non-negative: {rho}"

        defaults = dict(rho=rho, adaptive=adaptive, **kwargs)
        super(SAM, self).__init__(params, defaults)

        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)
        # print(self.base_optimizer, self.param_groups, **kwargs)
        self.param_groups = self.base_optimizer.param_groups
        self.defaults.update(self.base_optimizer.defaults)

    @torch.no_grad()
    def first_step(self, zero_grad=False):
        grad_norm = self._grad_norm()
        for group in self.param_groups:
            scale = group["rho"] / (grad_norm + 1e-12)

            for p in group["params"]:
                if p.grad is None: continue
                self.state[p]["old_p"] = p.data.clone()
                e_w = (torch.pow(p, 2) if group["adaptive"] else 1.0) * p.grad * scale.to(p)
                p.add_(e_w)  # climb to the local maximum "w + e(w)"

        if zero_grad: self.zero_grad()

    @torch.no_grad()
    def second_step(self, zero_grad=False):
        for group in self.param_groups:
            for p in group["params"]:
                if p.grad is None: continue
                p.data = self.state[p]["old_p"]  # get back to "w" from "w + e(w)"

        self.base_optimizer.step()  # do the actual "sharpness-aware" update

        if zero_grad: self.zero_grad()

    @torch.no_grad()
    def step(self, closure=None):
        assert closure is not None, "Sharpness Aware Minimization requires closure, but it was not provided"
        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass

        self.first_step(zero_grad=True)
        closure()
        self.second_step()

    def _grad_norm(self):
        shared_device = self.param_groups[0]["params"][0].device  # put everything on the same device, in case of model parallelism
        norm = torch.norm(
                    torch.stack([
                        ((torch.abs(p) if group["adaptive"] else 1.0) * p.grad).norm(p=2).to(shared_device)
                        for group in self.param_groups for p in group["params"]
                        if p.grad is not None
                    ]),
                    p=2
               )
        return norm

    def load_state_dict(self, state_dict):
        super().load_state_dict(state_dict)
        self.base_optimizer.param_groups = self.param_groups

Output:
{
    "experimental_code": "def evaluate_dropout(self, feats, net, n_iter=10, dropout=0.5):\n    if net is None:\n        net = self.net\n        \n    curr_pred, curr_conf, _, _, _, curr_softmax, _ = self.model_inference(feats, net=net)\n\n    if dropout < 0:\n        if conf.args.dataset == \"cifar10outdist\":\n            dropout = 0.4\n        elif conf.args.dataset == \"cifar100outdist\":\n            dropout = 0.3\n        elif conf.args.dataset == \"imagenetoutdist\":\n            dropout = 0.2\n        elif conf.args.dataset == \"imagenetR\":\n            dropout = 0.3\n        else:\n            raise NotImplementedError\n\n    # Dropout inference sampling\n    predictions = []\n    with torch.no_grad():\n        for _ in range(n_iter):\n            pred = net[1]((net[0](feats)), dropout=dropout)  # batch_size, n_classes\n            pred = F.softmax(pred, dim=1)\n            predictions.append(pred)\n    predictions = torch.stack(predictions, dim=1)  # batch_size, n_iter, n_classes\n    pred = torch.argmax(predictions, dim=2)\n    mean = torch.mean(predictions, dim=1)\n    #mean_pred_class = torch.argmax(mean_pred, dim=1)\n    std = torch.std(predictions, dim=1)\n\n    conf_mean = mean[:, curr_pred].diagonal()\n    conf_std = std[:, curr_pred].diagonal()\n    mean_for_curr_pred = conf_mean.mean()\n    std_for_curr_pred = conf_std.mean()\n\n    total_avg_softmax = torch.mean(mean, dim=0)\n    e_avg = (-total_avg_softmax * torch.log(total_avg_softmax + 1e-6)).sum()\n\n    # Prediction disagreement with dropouts\n    match_ratio = (curr_pred.unsqueeze(dim=1).repeat(1, n_iter) == pred).sum(dim=1, dtype=float) / n_iter\n    acc = match_ratio.mean()\n    return acc.item(), mean_for_curr_pred.item(), std_for_curr_pred.item(), e_avg.item()\n\ndef aetta(self, feats, y_pred):\n    est_acc, mean, std, e_avg = self.evaluate_dropout(feats, self.net, dropout=conf.args.dropout_rate)\n    self.acc_est_json['est_dropout'] += [est_acc]\n    self.acc_est_json['est_dropout_avg_entropy'] += [e_avg]\n    self.acc_est_json['est_dropout_softmax_mean'] += [mean]\n    self.acc_est_json['est_dropout_softmax_std'] += [std]\n\n    est_err = 1 - est_acc\n    if self.est_ema_dropout is None:\n        self.est_ema_dropout = est_err\n\n    if conf.args.dataset == \"cifar10outdist\":\n        MAX_ENTROPY = 2.3026  # cifar10\n        N_CLASS = 10\n    elif conf.args.dataset == \"cifar100outdist\":\n        MAX_ENTROPY = 4.6052  # cifar100\n        N_CLASS = 100\n    elif conf.args.dataset == \"imagenetR\" :\n        MAX_ENTROPY = 5.2983  # imagenetR\n        N_CLASS = 200\n    else: # imagenet\n        MAX_ENTROPY = 6.9078\n        N_CLASS = 1000\n\n    updated = est_err / (e_avg / MAX_ENTROPY) ** 3\n    updated = max(0., min(1. - 1. / N_CLASS, updated))\n\n    updated = self.est_ema_dropout * 0.6 + updated * 0.4\n    self.est_ema_dropout = updated\n\n    self.acc_est_json['aetta'] += [100 * (1. - updated)]",
    "experimental_info": "AETTA's methodology is implemented in the `aetta` and `evaluate_dropout` functions. The core idea is to estimate the test error using Prediction Disagreement with Dropouts (PDD) and the Entropy of Batch-aggregated Softmax values from Dropout inferences (Eavg).\n\n**1. Prediction Disagreement with Dropouts (PDD) and Eavg Calculation (`evaluate_dropout` function):**\n*   **Number of Dropout Inferences (N):** 10 iterations are performed.\n*   **Dropout Rate:** The dropout probability varies based on the dataset:\n    *   0.4 for CIFAR-10-C/OutDist\n    *   0.3 for CIFAR-100-C/OutDist and ImageNet-R\n    *   0.2 for ImageNet-C/OutDist\n*   `e_avg` (Eavg) is calculated as the sum of `-(total_avg_softmax * torch.log(total_avg_softmax + 1e-6))`.\n*   `est_acc` (agreement rate) is calculated as the mean of `match_ratio`, where `match_ratio` is the element-wise agreement between the current prediction and predictions from dropout inferences.\n*   `est_err` (PDD) is then derived as `1 - est_acc`.\n\n**2. Robust Confidence-Prediction Calibration (scaling constant 'b') and Error Estimation (`aetta` function):**\n*   **Maximum Entropy (Emax) and Number of Classes (N_CLASS):** These constants are defined based on the dataset:\n    *   CIFAR-10-C/OutDist: Emax = 2.3026, N_CLASS = 10\n    *   CIFAR-100-C/OutDist: Emax = 4.6052, N_CLASS = 100\n    *   ImageNet-R: Emax = 5.2983, N_CLASS = 200\n    *   ImageNet-C/OutDist: Emax = 6.9078, N_CLASS = 1000\n*   **Scaling Constant 'b':** The estimated error (`updated`) is approximated as `est_err / (e_avg / MAX_ENTROPY) ** 3`. This implies that the exponent `α` for `b = (Eavg / Emax)^(-α)` is `3` (since `ErrDT(h) ≈ b PDDDT(h)` and `est_err` is `PDDDT(h)`).\n*   **Clamping:** The `updated` estimated error is clamped between `0` and `1 - 1/N_CLASS`.\n*   **Exponential Moving Average (EMA):** An EMA is applied to stabilize the error estimation. The update rule is `updated = self.est_ema_dropout * 0.6 + updated * 0.4`, meaning the current estimate has a weight of `0.4` and the previous EMA has a weight of `0.6`.\n\n**3. Reset Mechanism (when `conf.args.reset_function` is \"aetta\"):**\n*   The model performs a hard reset if the estimated accuracy (`100 * (1. - updated)`) falls below 20%.\n*   Additionally, if the average of the last 5 estimated accuracies (from a window of the last 10 samples) is more than 2 percentage points lower than the average of the preceding 5 estimated accuracies in that window, a hard reset is triggered. This indicates a significant drop in performance."
}
